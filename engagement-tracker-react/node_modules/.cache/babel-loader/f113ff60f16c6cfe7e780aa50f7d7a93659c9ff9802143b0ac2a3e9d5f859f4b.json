{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, Slice, slice_util, util } from '@tensorflow/tfjs-core';\nimport { sliceImplCPU } from '../kernel_utils/shared';\nimport { SliceProgram } from '../slice_gpu';\nimport { SlicePackedProgram } from '../slice_packed_gpu';\nfunction shallowSlice(x, begin, size, backend) {\n  const xTexData = backend.texData.get(x.dataId);\n  const t = backend.makeTensorInfo(size, x.dtype);\n  const newTexData = backend.texData.get(t.dataId);\n  // Copy texture data from the original tensor.\n  Object.assign(newTexData, xTexData);\n  newTexData.complexParentRefCount = 0;\n  newTexData.refCount = 1;\n  newTexData.shape = size;\n  newTexData.dtype = x.dtype;\n  let flatOffset = slice_util.computeFlatOffset(begin, util.computeStrides(x.shape));\n  if (xTexData.slice) {\n    // We are slicing an already sliced tensor, so we have to accumulate\n    // the offset.\n    flatOffset += xTexData.slice.flatOffset;\n  }\n  newTexData.slice = {\n    flatOffset,\n    // Point to the original dataId, which is used to do ref counting.\n    origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId\n  };\n  // Increase the ref count for that data bucket.\n  const refCount = backend.dataRefCount.get(newTexData.slice.origDataId) || 1;\n  backend.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);\n  return t;\n}\nexport function slice(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    begin,\n    size\n  } = attrs;\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n  if (util.sizeFromShape($size) === 0) {\n    return backend.makeTensorInfo($size, x.dtype, []);\n  }\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgl doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string') {\n    const xTexData = backend.texData.get(x.dataId);\n    const outValues = sliceImplCPU(xTexData.values, $begin, $size, x.shape, x.dtype);\n    return backend.makeTensorInfo($size, x.dtype, outValues);\n  }\n  const {\n    isPacked\n  } = backend.texData.get(x.dataId);\n  const isContinous = slice_util.isSliceContinous(x.shape, $begin, $size);\n  if (isPacked || !isContinous) {\n    const program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ? new SlicePackedProgram($size) : new SliceProgram($size);\n    const customSetup = program.getCustomSetupFunc($begin);\n    return backend.runWebGLProgram(program, [x], x.dtype, customSetup);\n  }\n  backend.uploadToGPU(x.dataId);\n  return shallowSlice(x, $begin, $size, backend);\n}\nexport const sliceConfig = {\n  kernelName: Slice,\n  backendName: 'webgl',\n  kernelFunc: slice\n};","map":{"version":3,"names":["env","Slice","slice_util","util","sliceImplCPU","SliceProgram","SlicePackedProgram","shallowSlice","x","begin","size","backend","xTexData","texData","get","dataId","t","makeTensorInfo","dtype","newTexData","Object","assign","complexParentRefCount","refCount","shape","flatOffset","computeFlatOffset","computeStrides","slice","origDataId","dataRefCount","set","args","inputs","attrs","$begin","$size","parseSliceParams","assertParamsValid","sizeFromShape","shouldExecuteOnCPU","outValues","values","isPacked","isContinous","isSliceContinous","program","getBool","customSetup","getCustomSetupFunc","runWebGLProgram","uploadToGPU","sliceConfig","kernelName","backendName","kernelFunc"],"sources":["C:\\Users\\reddy\\Documents\\Projects\\Engagement Tracker\\engagement-tracker-react\\node_modules\\@tensorflow\\tfjs-backend-webgl\\src\\kernels\\Slice.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env, KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {sliceImplCPU} from '../kernel_utils/shared';\nimport {SliceProgram} from '../slice_gpu';\nimport {SlicePackedProgram} from '../slice_packed_gpu';\n\nfunction shallowSlice(\n    x: TensorInfo, begin: number[], size: number[], backend: MathBackendWebGL) {\n  const xTexData = backend.texData.get(x.dataId);\n  const t = backend.makeTensorInfo(size, x.dtype);\n  const newTexData = backend.texData.get(t.dataId);\n  // Copy texture data from the original tensor.\n  Object.assign(newTexData, xTexData);\n  newTexData.complexParentRefCount = 0;\n  newTexData.refCount = 1;\n  newTexData.shape = size;\n  newTexData.dtype = x.dtype;\n  let flatOffset =\n      slice_util.computeFlatOffset(begin, util.computeStrides(x.shape));\n  if (xTexData.slice) {\n    // We are slicing an already sliced tensor, so we have to accumulate\n    // the offset.\n    flatOffset += xTexData.slice.flatOffset;\n  }\n  newTexData.slice = {\n    flatOffset,\n    // Point to the original dataId, which is used to do ref counting.\n    origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId\n  };\n\n  // Increase the ref count for that data bucket.\n  const refCount = backend.dataRefCount.get(newTexData.slice.origDataId) || 1;\n  backend.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);\n  return t;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendWebGL, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  if (util.sizeFromShape($size) === 0) {\n    return backend.makeTensorInfo($size, x.dtype, []);\n  }\n\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgl doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string') {\n    const xTexData = backend.texData.get(x.dataId);\n    const outValues = sliceImplCPU(\n        xTexData.values as TypedArray, $begin, $size, x.shape, x.dtype);\n    return backend.makeTensorInfo($size, x.dtype, outValues);\n  }\n\n  const {isPacked} = backend.texData.get(x.dataId);\n  const isContinous = slice_util.isSliceContinous(x.shape, $begin, $size);\n  if (isPacked || !isContinous) {\n    const program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n        new SlicePackedProgram($size) :\n        new SliceProgram($size);\n    const customSetup = program.getCustomSetupFunc($begin);\n    return backend.runWebGLProgram(program, [x], x.dtype, customSetup);\n  }\n  backend.uploadToGPU(x.dataId);\n  return shallowSlice(x, $begin, $size, backend);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'webgl',\n  kernelFunc: slice as {} as KernelFunc\n};\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,GAAG,EAA4BC,KAAK,EAAEC,UAAU,EAAmDC,IAAI,QAAO,uBAAuB;AAG7I,SAAQC,YAAY,QAAO,wBAAwB;AACnD,SAAQC,YAAY,QAAO,cAAc;AACzC,SAAQC,kBAAkB,QAAO,qBAAqB;AAEtD,SAASC,YAAYA,CACjBC,CAAa,EAAEC,KAAe,EAAEC,IAAc,EAAEC,OAAyB;EAC3E,MAAMC,QAAQ,GAAGD,OAAO,CAACE,OAAO,CAACC,GAAG,CAACN,CAAC,CAACO,MAAM,CAAC;EAC9C,MAAMC,CAAC,GAAGL,OAAO,CAACM,cAAc,CAACP,IAAI,EAAEF,CAAC,CAACU,KAAK,CAAC;EAC/C,MAAMC,UAAU,GAAGR,OAAO,CAACE,OAAO,CAACC,GAAG,CAACE,CAAC,CAACD,MAAM,CAAC;EAChD;EACAK,MAAM,CAACC,MAAM,CAACF,UAAU,EAAEP,QAAQ,CAAC;EACnCO,UAAU,CAACG,qBAAqB,GAAG,CAAC;EACpCH,UAAU,CAACI,QAAQ,GAAG,CAAC;EACvBJ,UAAU,CAACK,KAAK,GAAGd,IAAI;EACvBS,UAAU,CAACD,KAAK,GAAGV,CAAC,CAACU,KAAK;EAC1B,IAAIO,UAAU,GACVvB,UAAU,CAACwB,iBAAiB,CAACjB,KAAK,EAAEN,IAAI,CAACwB,cAAc,CAACnB,CAAC,CAACgB,KAAK,CAAC,CAAC;EACrE,IAAIZ,QAAQ,CAACgB,KAAK,EAAE;IAClB;IACA;IACAH,UAAU,IAAIb,QAAQ,CAACgB,KAAK,CAACH,UAAU;;EAEzCN,UAAU,CAACS,KAAK,GAAG;IACjBH,UAAU;IACV;IACAI,UAAU,EAAEjB,QAAQ,CAACgB,KAAK,IAAIhB,QAAQ,CAACgB,KAAK,CAACC,UAAU,IAAIrB,CAAC,CAACO;GAC9D;EAED;EACA,MAAMQ,QAAQ,GAAGZ,OAAO,CAACmB,YAAY,CAAChB,GAAG,CAACK,UAAU,CAACS,KAAK,CAACC,UAAU,CAAC,IAAI,CAAC;EAC3ElB,OAAO,CAACmB,YAAY,CAACC,GAAG,CAACZ,UAAU,CAACS,KAAK,CAACC,UAAU,EAAEN,QAAQ,GAAG,CAAC,CAAC;EACnE,OAAOP,CAAC;AACV;AAEA,OAAM,SAAUY,KAAKA,CACjBI,IAAyE;EAE3E,MAAM;IAACC,MAAM;IAAEtB,OAAO;IAAEuB;EAAK,CAAC,GAAGF,IAAI;EACrC,MAAM;IAACxB;EAAC,CAAC,GAAGyB,MAAM;EAClB,MAAM;IAACxB,KAAK;IAAEC;EAAI,CAAC,GAAGwB,KAAK;EAE3B,MAAM,CAACC,MAAM,EAAEC,KAAK,CAAC,GAAGlC,UAAU,CAACmC,gBAAgB,CAAC7B,CAAC,EAAEC,KAAK,EAAEC,IAAI,CAAC;EACnER,UAAU,CAACoC,iBAAiB,CAAC9B,CAAC,EAAE2B,MAAM,EAAEC,KAAK,CAAC;EAE9C,IAAIjC,IAAI,CAACoC,aAAa,CAACH,KAAK,CAAC,KAAK,CAAC,EAAE;IACnC,OAAOzB,OAAO,CAACM,cAAc,CAACmB,KAAK,EAAE5B,CAAC,CAACU,KAAK,EAAE,EAAE,CAAC;;EAGnD;EACA;EACA;EACA;EACA;EACA;EACA,IAAIP,OAAO,CAAC6B,kBAAkB,CAAC,CAAChC,CAAC,CAAC,CAAC,IAAIA,CAAC,CAACU,KAAK,KAAK,QAAQ,EAAE;IAC3D,MAAMN,QAAQ,GAAGD,OAAO,CAACE,OAAO,CAACC,GAAG,CAACN,CAAC,CAACO,MAAM,CAAC;IAC9C,MAAM0B,SAAS,GAAGrC,YAAY,CAC1BQ,QAAQ,CAAC8B,MAAoB,EAAEP,MAAM,EAAEC,KAAK,EAAE5B,CAAC,CAACgB,KAAK,EAAEhB,CAAC,CAACU,KAAK,CAAC;IACnE,OAAOP,OAAO,CAACM,cAAc,CAACmB,KAAK,EAAE5B,CAAC,CAACU,KAAK,EAAEuB,SAAS,CAAC;;EAG1D,MAAM;IAACE;EAAQ,CAAC,GAAGhC,OAAO,CAACE,OAAO,CAACC,GAAG,CAACN,CAAC,CAACO,MAAM,CAAC;EAChD,MAAM6B,WAAW,GAAG1C,UAAU,CAAC2C,gBAAgB,CAACrC,CAAC,CAACgB,KAAK,EAAEW,MAAM,EAAEC,KAAK,CAAC;EACvE,IAAIO,QAAQ,IAAI,CAACC,WAAW,EAAE;IAC5B,MAAME,OAAO,GAAG9C,GAAG,EAAE,CAAC+C,OAAO,CAAC,6BAA6B,CAAC,GACxD,IAAIzC,kBAAkB,CAAC8B,KAAK,CAAC,GAC7B,IAAI/B,YAAY,CAAC+B,KAAK,CAAC;IAC3B,MAAMY,WAAW,GAAGF,OAAO,CAACG,kBAAkB,CAACd,MAAM,CAAC;IACtD,OAAOxB,OAAO,CAACuC,eAAe,CAACJ,OAAO,EAAE,CAACtC,CAAC,CAAC,EAAEA,CAAC,CAACU,KAAK,EAAE8B,WAAW,CAAC;;EAEpErC,OAAO,CAACwC,WAAW,CAAC3C,CAAC,CAACO,MAAM,CAAC;EAC7B,OAAOR,YAAY,CAACC,CAAC,EAAE2B,MAAM,EAAEC,KAAK,EAAEzB,OAAO,CAAC;AAChD;AAEA,OAAO,MAAMyC,WAAW,GAAiB;EACvCC,UAAU,EAAEpD,KAAK;EACjBqD,WAAW,EAAE,OAAO;EACpBC,UAAU,EAAE3B;CACb"},"metadata":{},"sourceType":"module","externalDependencies":[]}