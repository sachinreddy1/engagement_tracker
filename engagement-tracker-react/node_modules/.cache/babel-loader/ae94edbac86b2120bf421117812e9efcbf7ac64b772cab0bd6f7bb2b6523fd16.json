{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const EPSILON_FLOAT32 = 1e-7;\nexport const EPSILON_FLOAT16 = 1e-4;\n/** Convenient class for storing tensor-related data. */\nexport class DataStorage {\n  constructor(backend, dataMover) {\n    this.backend = backend;\n    this.dataMover = dataMover;\n    this.data = new WeakMap();\n    this.dataIdsCount = 0;\n  }\n  get(dataId) {\n    if (!this.data.has(dataId)) {\n      this.dataMover.moveData(this.backend, dataId);\n    }\n    return this.data.get(dataId);\n  }\n  set(dataId, value) {\n    this.dataIdsCount++;\n    this.data.set(dataId, value);\n  }\n  has(dataId) {\n    return this.data.has(dataId);\n  }\n  delete(dataId) {\n    this.dataIdsCount--;\n    return this.data.delete(dataId);\n  }\n  numDataIds() {\n    return this.dataIdsCount;\n  }\n}\n/**\n * The interface that defines the kernels that should be implemented when\n * adding a new backend. New backends don't need to implement every one of the\n * methods, this can be done gradually (throw an error for unimplemented\n * methods).\n */\nexport class KernelBackend {\n  /**\n   * Decrease the complex ref count for the dataId, this is useful for WebGL\n   * backend to keep the real and imag components of the complex tensor in sync\n   * with the engine. WASM and node do not have internal ref count, they will\n   * use on the default implementation.\n   * @param dataId\n   */\n  decComplexRef(dataId) {\n    return;\n  }\n  time(f) {\n    return notYetImplemented('time');\n  }\n  read(dataId) {\n    return notYetImplemented('read');\n  }\n  readSync(dataId) {\n    return notYetImplemented('readSync');\n  }\n  numDataIds() {\n    return notYetImplemented('numDataIds');\n  }\n  disposeData(dataId) {\n    return notYetImplemented('disposeData');\n  }\n  write(values, shape, dtype) {\n    return notYetImplemented('write');\n  }\n  move(dataId, values, shape, dtype) {\n    return notYetImplemented('move');\n  }\n  memory() {\n    return notYetImplemented('memory');\n  }\n  /** Returns the highest precision for floats in bits (e.g. 16 or 32) */\n  floatPrecision() {\n    return notYetImplemented('floatPrecision');\n  }\n  /** Returns the smallest representable number.  */\n  epsilon() {\n    return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;\n  }\n  batchMatMul(a, b, transposeA, transposeB) {\n    return notYetImplemented('batchMatMul');\n  }\n  fusedBatchMatMul(_ref) {\n    let {\n      a,\n      b,\n      transposeA,\n      transposeB,\n      bias,\n      activation,\n      preluActivationWeights\n    } = _ref;\n    return notYetImplemented('fusedBatchMatMul');\n  }\n  slice(x, begin, size) {\n    return notYetImplemented('slice');\n  }\n  stridedSlice(x, begin, end, strides) {\n    return notYetImplemented('stridedSlice');\n  }\n  unstack(x, axis) {\n    return notYetImplemented('unstack');\n  }\n  reverse(a, axis) {\n    return notYetImplemented('reverse');\n  }\n  concat(tensors, axis) {\n    return notYetImplemented('concat');\n  }\n  neg(a) {\n    return notYetImplemented('neg');\n  }\n  add(a, b) {\n    return notYetImplemented('add');\n  }\n  addN(tensors) {\n    return notYetImplemented('addN');\n  }\n  subtract(a, b) {\n    return notYetImplemented('subtract');\n  }\n  multiply(a, b) {\n    return notYetImplemented('multiply');\n  }\n  realDivide(a, b) {\n    return notYetImplemented('realDivide');\n  }\n  floorDiv(a, b) {\n    return notYetImplemented('floorDiv');\n  }\n  sum(x, axes) {\n    return notYetImplemented('sum');\n  }\n  prod(x, axes) {\n    return notYetImplemented('prod');\n  }\n  unsortedSegmentSum(x, segmentIds, numSegments) {\n    return notYetImplemented('unsortedSegmentSum');\n  }\n  argMin(x, axis) {\n    return notYetImplemented('argMin');\n  }\n  argMax(x, axis) {\n    return notYetImplemented('argMax');\n  }\n  equal(a, b) {\n    return notYetImplemented('equal');\n  }\n  notEqual(a, b) {\n    return notYetImplemented('notEqual');\n  }\n  less(a, b) {\n    return notYetImplemented('less');\n  }\n  lessEqual(a, b) {\n    return notYetImplemented('lessEqual');\n  }\n  greater(a, b) {\n    return notYetImplemented('greater');\n  }\n  greaterEqual(a, b) {\n    return notYetImplemented('greaterEqual');\n  }\n  logicalNot(a) {\n    return notYetImplemented('logicalNot');\n  }\n  logicalAnd(a, b) {\n    return notYetImplemented('logicalAnd');\n  }\n  logicalOr(a, b) {\n    return notYetImplemented('logicalOr');\n  }\n  where(condition) {\n    return notYetImplemented('where');\n  }\n  select(condition, a, b) {\n    return notYetImplemented('select');\n  }\n  topk(x, k, sorted) {\n    return notYetImplemented('topk');\n  }\n  min(x, axes) {\n    return notYetImplemented('min');\n  }\n  minimum(a, b) {\n    return notYetImplemented('minimum');\n  }\n  mod(a, b) {\n    return notYetImplemented('mod');\n  }\n  max(x, axes) {\n    return notYetImplemented('max');\n  }\n  maximum(a, b) {\n    return notYetImplemented('maximum');\n  }\n  all(x, axes) {\n    return notYetImplemented('all');\n  }\n  any(x, axes) {\n    return notYetImplemented('any');\n  }\n  squaredDifference(a, b) {\n    return notYetImplemented('squaredDifference');\n  }\n  ceil(x) {\n    return notYetImplemented('ceil');\n  }\n  floor(x) {\n    return notYetImplemented('floor');\n  }\n  round(x) {\n    return notYetImplemented('round');\n  }\n  sign(x) {\n    return notYetImplemented('sign');\n  }\n  isNaN(x) {\n    return notYetImplemented('isNaN');\n  }\n  isInf(x) {\n    return notYetImplemented('isInf');\n  }\n  isFinite(x) {\n    return notYetImplemented('isFinite');\n  }\n  pow(a, b) {\n    return notYetImplemented('pow');\n  }\n  exp(x) {\n    return notYetImplemented('exp');\n  }\n  expm1(x) {\n    return notYetImplemented('expm1');\n  }\n  softmax(x, dim) {\n    return notYetImplemented('softmax');\n  }\n  log(x) {\n    return notYetImplemented('log');\n  }\n  log1p(x) {\n    return notYetImplemented('log1p');\n  }\n  sqrt(x) {\n    return notYetImplemented('sqrt');\n  }\n  rsqrt(x) {\n    return notYetImplemented('rsqrt');\n  }\n  square(x) {\n    return notYetImplemented('square');\n  }\n  reciprocal(x) {\n    return notYetImplemented('reciprocal');\n  }\n  relu(x) {\n    return notYetImplemented('relu');\n  }\n  relu6(x) {\n    return notYetImplemented('relu6');\n  }\n  prelu(x, a) {\n    return notYetImplemented('prelu');\n  }\n  elu(x) {\n    return notYetImplemented('elu');\n  }\n  eluDer(dy, y) {\n    return notYetImplemented('eluDer');\n  }\n  selu(x) {\n    return notYetImplemented('selu');\n  }\n  int(x) {\n    return notYetImplemented('int');\n  }\n  clip(x, min, max) {\n    return notYetImplemented('clip');\n  }\n  abs(x) {\n    return notYetImplemented('abs');\n  }\n  complexAbs(x) {\n    return notYetImplemented('complexAbs');\n  }\n  sigmoid(x) {\n    return notYetImplemented('sigmoid');\n  }\n  softplus(x) {\n    return notYetImplemented('softplus');\n  }\n  sin(x) {\n    return notYetImplemented('sin');\n  }\n  cos(x) {\n    return notYetImplemented('cos');\n  }\n  tan(x) {\n    return notYetImplemented('tan');\n  }\n  asin(x) {\n    return notYetImplemented('asin');\n  }\n  acos(x) {\n    return notYetImplemented('acos');\n  }\n  atan(x) {\n    return notYetImplemented('atan');\n  }\n  atan2(a, b) {\n    return notYetImplemented('atan2');\n  }\n  sinh(x) {\n    return notYetImplemented('sinh');\n  }\n  cosh(x) {\n    return notYetImplemented('cosh');\n  }\n  tanh(x) {\n    return notYetImplemented('tanh');\n  }\n  asinh(x) {\n    return notYetImplemented('asinh');\n  }\n  acosh(x) {\n    return notYetImplemented('acosh');\n  }\n  atanh(x) {\n    return notYetImplemented('atanh');\n  }\n  erf(x) {\n    return notYetImplemented('erf');\n  }\n  step(x, alpha) {\n    return notYetImplemented('step');\n  }\n  fusedConv2d(_ref2) {\n    let {\n      input,\n      filter,\n      convInfo,\n      bias,\n      activation,\n      preluActivationWeights\n    } = _ref2;\n    return notYetImplemented('fusedConv2d');\n  }\n  conv2d(x, filter, convInfo) {\n    return notYetImplemented('conv2d');\n  }\n  conv2dDerInput(dy, filter, convInfo) {\n    return notYetImplemented('conv2dDerInput');\n  }\n  conv2dDerFilter(x, dY, convInfo) {\n    return notYetImplemented('conv2dDerFilter');\n  }\n  fusedDepthwiseConv2D(_ref3) {\n    let {\n      input,\n      filter,\n      convInfo,\n      bias,\n      activation,\n      preluActivationWeights\n    } = _ref3;\n    return notYetImplemented('fusedDepthwiseConv2D');\n  }\n  depthwiseConv2D(input, filter, convInfo) {\n    return notYetImplemented('depthwiseConv2D');\n  }\n  depthwiseConv2DDerInput(dy, filter, convInfo) {\n    return notYetImplemented('depthwiseConv2DDerInput');\n  }\n  depthwiseConv2DDerFilter(x, dY, convInfo) {\n    return notYetImplemented('depthwiseConv2DDerFilter');\n  }\n  conv3d(x, filter, convInfo) {\n    return notYetImplemented('conv3d');\n  }\n  conv3dDerInput(dy, filter, convInfo) {\n    return notYetImplemented('conv3dDerInput');\n  }\n  conv3dDerFilter(x, dY, convInfo) {\n    return notYetImplemented('conv3dDerFilter');\n  }\n  maxPool(x, convInfo) {\n    return notYetImplemented('maxPool');\n  }\n  maxPoolBackprop(dy, x, y, convInfo) {\n    return notYetImplemented('maxPoolBackprop');\n  }\n  avgPool(x, convInfo) {\n    return notYetImplemented('avgPool');\n  }\n  avgPoolBackprop(dy, x, convInfo) {\n    return notYetImplemented('avgPoolBackprop');\n  }\n  avgPool3d(x, convInfo) {\n    return notYetImplemented('avgPool3d');\n  }\n  avgPool3dBackprop(dy, x, convInfo) {\n    return notYetImplemented('avgPool3dBackprop');\n  }\n  maxPool3d(x, convInfo) {\n    return notYetImplemented('maxPool3d');\n  }\n  maxPool3dBackprop(dy, x, y, convInfo) {\n    return notYetImplemented('maxPool3dBackprop');\n  }\n  reshape(x, shape) {\n    return notYetImplemented('reshape');\n  }\n  cast(x, dtype) {\n    return notYetImplemented('cast');\n  }\n  tile(x, reps) {\n    return notYetImplemented('tile');\n  }\n  pad(x, paddings, constantValue) {\n    return notYetImplemented('pad');\n  }\n  transpose(x, perm) {\n    return notYetImplemented('transpose');\n  }\n  gather(x, indices, axis) {\n    let batchDims = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n    return notYetImplemented('gather');\n  }\n  gatherND(x, indices) {\n    return notYetImplemented('gatherND');\n  }\n  scatterND(indices, updates, shape) {\n    return notYetImplemented('scatterND');\n  }\n  batchToSpaceND(x, blockShape, crops) {\n    return notYetImplemented('batchToSpaceND');\n  }\n  spaceToBatchND(x, blockShape, paddings) {\n    return notYetImplemented('spaceToBatchND');\n  }\n  resizeBilinear(x, newHeight, newWidth, alignCorners, halfPixelCenters) {\n    return notYetImplemented('resizeBilinear');\n  }\n  resizeBilinearBackprop(dy, x, alignCorners) {\n    return notYetImplemented('resizeBilinearBackprop');\n  }\n  resizeNearestNeighbor(x, newHEight, newWidth, alignCorners, halfPixelCenters) {\n    return notYetImplemented('resizeNearestNeighbor');\n  }\n  resizeNearestNeighborBackprop(dy, x, alignCorners) {\n    return notYetImplemented('resizeNearestNeighborBackprop');\n  }\n  batchNorm(x, mean, variance, offset, scale, varianceEpsilon) {\n    return notYetImplemented('batchNorm');\n  }\n  localResponseNormalization4D(x, radius, bias, alpha, beta) {\n    return notYetImplemented('localResponseNormalization4D');\n  }\n  LRNGrad(dy, inputImage, outputImage, radius, bias, alpha, beta) {\n    return notYetImplemented('LRNGrad');\n  }\n  multinomial(logits, normalized, numSamples, seed) {\n    return notYetImplemented('multinomial');\n  }\n  oneHot(indices, depth, onValue, offValue) {\n    return notYetImplemented('oneHot');\n  }\n  cumsum(x, axis, exclusive, reverse) {\n    return notYetImplemented('cumsum');\n  }\n  nonMaxSuppression(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n    return notYetImplemented('nonMaxSuppression');\n  }\n  fft(x) {\n    return notYetImplemented('fft');\n  }\n  ifft(x) {\n    return notYetImplemented('ifft');\n  }\n  complex(real, imag) {\n    return notYetImplemented('complex');\n  }\n  real(input) {\n    return notYetImplemented('real');\n  }\n  imag(input) {\n    return notYetImplemented('imag');\n  }\n  cropAndResize(image, boxes, boxIndex, cropSize, method, extrapolationValue) {\n    return notYetImplemented('cropAndResize');\n  }\n  depthToSpace(x, blockSize, dataFormat) {\n    return notYetImplemented('depthToSpace');\n  }\n  // Aligns with the \"SplitV\" kernel in TensorFlow.\n  split(value, sizeSplits, axis) {\n    return notYetImplemented('split');\n  }\n  sparseToDense(sparseIndices, sparseValues, outputShape, defaultValue) {\n    return notYetImplemented('sparseToDense');\n  }\n  diag(x) {\n    return notYetImplemented('diag');\n  }\n  fill(shape, value, dtype) {\n    return notYetImplemented('fill');\n  }\n  onesLike(x) {\n    return notYetImplemented('onesLike');\n  }\n  zerosLike(x) {\n    return notYetImplemented('zerosLike');\n  }\n  linspace(start, stop, num) {\n    return notYetImplemented('linspace');\n  }\n  dispose() {\n    return notYetImplemented('dispose');\n  }\n}\nfunction notYetImplemented(kernelName) {\n  throw new Error(\"'\".concat(kernelName, \"' not yet implemented or not found in the registry. \") + \"This kernel may not be supported by the tfjs backend you have chosen\");\n}","map":{"version":3,"names":["EPSILON_FLOAT32","EPSILON_FLOAT16","DataStorage","constructor","backend","dataMover","data","WeakMap","dataIdsCount","get","dataId","has","moveData","set","value","delete","numDataIds","KernelBackend","decComplexRef","time","f","notYetImplemented","read","readSync","disposeData","write","values","shape","dtype","move","memory","floatPrecision","epsilon","batchMatMul","a","b","transposeA","transposeB","fusedBatchMatMul","_ref","bias","activation","preluActivationWeights","slice","x","begin","size","stridedSlice","end","strides","unstack","axis","reverse","concat","tensors","neg","add","addN","subtract","multiply","realDivide","floorDiv","sum","axes","prod","unsortedSegmentSum","segmentIds","numSegments","argMin","argMax","equal","notEqual","less","lessEqual","greater","greaterEqual","logicalNot","logicalAnd","logicalOr","where","condition","select","topk","k","sorted","min","minimum","mod","max","maximum","all","any","squaredDifference","ceil","floor","round","sign","isNaN","isInf","isFinite","pow","exp","expm1","softmax","dim","log","log1p","sqrt","rsqrt","square","reciprocal","relu","relu6","prelu","elu","eluDer","dy","y","selu","int","clip","abs","complexAbs","sigmoid","softplus","sin","cos","tan","asin","acos","atan","atan2","sinh","cosh","tanh","asinh","acosh","atanh","erf","step","alpha","fusedConv2d","_ref2","input","filter","convInfo","conv2d","conv2dDerInput","conv2dDerFilter","dY","fusedDepthwiseConv2D","_ref3","depthwiseConv2D","depthwiseConv2DDerInput","depthwiseConv2DDerFilter","conv3d","conv3dDerInput","conv3dDerFilter","maxPool","maxPoolBackprop","avgPool","avgPoolBackprop","avgPool3d","avgPool3dBackprop","maxPool3d","maxPool3dBackprop","reshape","cast","tile","reps","pad","paddings","constantValue","transpose","perm","gather","indices","batchDims","arguments","length","undefined","gatherND","scatterND","updates","batchToSpaceND","blockShape","crops","spaceToBatchND","resizeBilinear","newHeight","newWidth","alignCorners","halfPixelCenters","resizeBilinearBackprop","resizeNearestNeighbor","newHEight","resizeNearestNeighborBackprop","batchNorm","mean","variance","offset","scale","varianceEpsilon","localResponseNormalization4D","radius","beta","LRNGrad","inputImage","outputImage","multinomial","logits","normalized","numSamples","seed","oneHot","depth","onValue","offValue","cumsum","exclusive","nonMaxSuppression","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","fft","ifft","complex","real","imag","cropAndResize","image","boxIndex","cropSize","method","extrapolationValue","depthToSpace","blockSize","dataFormat","split","sizeSplits","sparseToDense","sparseIndices","sparseValues","outputShape","defaultValue","diag","fill","onesLike","zerosLike","linspace","start","stop","num","dispose","kernelName","Error"],"sources":["C:\\Users\\reddy\\Documents\\Projects\\Engagement Tracker\\engagement-tracker-react\\node_modules\\@tensorflow\\tfjs-core\\src\\backends\\backend.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Conv2DInfo, Conv3DInfo} from '../ops/conv_util';\nimport {FusedBatchMatMulConfig, FusedConv2DConfig} from '../ops/fused_types';\nimport {Backend, DataId, Scalar, Tensor, Tensor1D, Tensor2D, Tensor3D, Tensor4D, Tensor5D} from '../tensor';\nimport {BackendValues, DataType, Rank, ShapeMap} from '../types';\n\nexport const EPSILON_FLOAT32 = 1e-7;\nexport const EPSILON_FLOAT16 = 1e-4;\n\n// Required information for all backends.\nexport interface BackendTimingInfo {\n  kernelMs: number|{error: string};\n  getExtraProfileInfo?(): string;  // a field for additional timing information\n                                   // e.g. packing / unpacking for WebGL backend\n}\n\nexport interface TensorStorage {\n  read(dataId: DataId): Promise<BackendValues>;\n  readSync(dataId: DataId): BackendValues;\n  disposeData(dataId: DataId): void;\n  write(values: BackendValues, shape: number[], dtype: DataType): DataId;\n  move(dataId: DataId, values: BackendValues, shape: number[], dtype: DataType):\n      void;\n  memory(): {unreliable: boolean;};  // Backend-specific information.\n  /** Returns number of data ids currently in the storage. */\n  numDataIds(): number;\n}\n\n/** Convenient class for storing tensor-related data. */\nexport class DataStorage<T> {\n  private data = new WeakMap<DataId, T>();\n  private dataIdsCount = 0;\n\n  constructor(private backend: KernelBackend, private dataMover: DataMover) {}\n\n  get(dataId: DataId) {\n    if (!this.data.has(dataId)) {\n      this.dataMover.moveData(this.backend, dataId);\n    }\n    return this.data.get(dataId);\n  }\n\n  set(dataId: DataId, value: T): void {\n    this.dataIdsCount++;\n    this.data.set(dataId, value);\n  }\n\n  has(dataId: DataId): boolean {\n    return this.data.has(dataId);\n  }\n\n  delete(dataId: DataId): boolean {\n    this.dataIdsCount--;\n    return this.data.delete(dataId);\n  }\n\n  numDataIds(): number {\n    return this.dataIdsCount;\n  }\n}\n\nexport interface DataMover {\n  /**\n   * To be called by backends whenever they see a dataId that they don't own.\n   * Upon calling this method, the mover will fetch the tensor from another\n   * backend and register it with the current active backend.\n   */\n  moveData(backend: KernelBackend, dataId: DataId): void;\n}\n\nexport interface BackendTimer {\n  time(f: () => void): Promise<BackendTimingInfo>;\n}\n\n/**\n * The interface that defines the kernels that should be implemented when\n * adding a new backend. New backends don't need to implement every one of the\n * methods, this can be done gradually (throw an error for unimplemented\n * methods).\n */\nexport class KernelBackend implements TensorStorage, Backend, BackendTimer {\n  /**\n   * Decrease the complex ref count for the dataId, this is useful for WebGL\n   * backend to keep the real and imag components of the complex tensor in sync\n   * with the engine. WASM and node do not have internal ref count, they will\n   * use on the default implementation.\n   * @param dataId\n   */\n  decComplexRef(dataId: DataId): void {\n    return;\n  }\n  time(f: () => void): Promise<BackendTimingInfo> {\n    return notYetImplemented('time');\n  }\n  read(dataId: object): Promise<BackendValues> {\n    return notYetImplemented('read');\n  }\n  readSync(dataId: object): BackendValues {\n    return notYetImplemented('readSync');\n  }\n  numDataIds(): number {\n    return notYetImplemented('numDataIds');\n  }\n  disposeData(dataId: object): void {\n    return notYetImplemented('disposeData');\n  }\n  write(values: BackendValues, shape: number[], dtype: DataType): DataId {\n    return notYetImplemented('write');\n  }\n  move(dataId: DataId, values: BackendValues, shape: number[], dtype: DataType):\n      void {\n    return notYetImplemented('move');\n  }\n  memory(): {unreliable: boolean; reasons?: string[]} {\n    return notYetImplemented('memory');\n  }\n  /** Returns the highest precision for floats in bits (e.g. 16 or 32) */\n  floatPrecision(): 16|32 {\n    return notYetImplemented('floatPrecision');\n  }\n  /** Returns the smallest representable number.  */\n  epsilon(): number {\n    return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;\n  }\n\n  batchMatMul(\n      a: Tensor3D, b: Tensor3D, transposeA: boolean,\n      transposeB: boolean): Tensor3D {\n    return notYetImplemented('batchMatMul');\n  }\n\n  fusedBatchMatMul(\n      {a, b, transposeA, transposeB, bias, activation, preluActivationWeights}:\n          FusedBatchMatMulConfig): Tensor3D {\n    return notYetImplemented('fusedBatchMatMul');\n  }\n\n  slice<T extends Tensor>(x: T, begin: number[], size: number[]): T {\n    return notYetImplemented('slice');\n  }\n  stridedSlice<T extends Tensor>(\n      x: T, begin: number[], end: number[], strides: number[]): T {\n    return notYetImplemented('stridedSlice');\n  }\n  unstack(x: Tensor, axis: number): Tensor[] {\n    return notYetImplemented('unstack');\n  }\n  reverse<T extends Tensor>(a: T, axis: number[]): T {\n    return notYetImplemented('reverse');\n  }\n\n  concat(tensors: Tensor[], axis: number): Tensor {\n    return notYetImplemented('concat');\n  }\n\n  neg<T extends Tensor>(a: T): T {\n    return notYetImplemented('neg');\n  }\n\n  add(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('add');\n  }\n  addN<T extends Tensor>(tensors: T[]): T {\n    return notYetImplemented('addN');\n  }\n  subtract(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('subtract');\n  }\n  multiply(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('multiply');\n  }\n  realDivide(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('realDivide');\n  }\n  floorDiv(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('floorDiv');\n  }\n\n  sum(x: Tensor, axes: number[]): Tensor {\n    return notYetImplemented('sum');\n  }\n  prod(x: Tensor, axes: number[]): Tensor {\n    return notYetImplemented('prod');\n  }\n\n  unsortedSegmentSum<T extends Tensor>(\n      x: T, segmentIds: Tensor1D, numSegments: number): Tensor {\n    return notYetImplemented('unsortedSegmentSum');\n  }\n\n  argMin(x: Tensor, axis: number): Tensor {\n    return notYetImplemented('argMin');\n  }\n  argMax(x: Tensor, axis: number): Tensor {\n    return notYetImplemented('argMax');\n  }\n\n  equal(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('equal');\n  }\n  notEqual(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('notEqual');\n  }\n\n  less(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('less');\n  }\n  lessEqual(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('lessEqual');\n  }\n\n  greater(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('greater');\n  }\n  greaterEqual(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('greaterEqual');\n  }\n\n  logicalNot<T extends Tensor>(a: T): T {\n    return notYetImplemented('logicalNot');\n  }\n  logicalAnd(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('logicalAnd');\n  }\n  logicalOr(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('logicalOr');\n  }\n\n  where(condition: Tensor): Tensor2D {\n    return notYetImplemented('where');\n  }\n  select(condition: Tensor, a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('select');\n  }\n\n  topk<T extends Tensor>(x: T, k: number, sorted: boolean): [T, T] {\n    return notYetImplemented('topk');\n  }\n\n  min(x: Tensor, axes: number[]): Tensor {\n    return notYetImplemented('min');\n  }\n  minimum(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('minimum');\n  }\n\n  mod(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('mod');\n  }\n\n  max(x: Tensor, axes: number[]): Tensor {\n    return notYetImplemented('max');\n  }\n  maximum(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('maximum');\n  }\n\n  all(x: Tensor, axes: number[]): Tensor {\n    return notYetImplemented('all');\n  }\n  any(x: Tensor, axes: number[]): Tensor {\n    return notYetImplemented('any');\n  }\n\n  squaredDifference(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('squaredDifference');\n  }\n\n  ceil<T extends Tensor>(x: T): T {\n    return notYetImplemented('ceil');\n  }\n  floor<T extends Tensor>(x: T): T {\n    return notYetImplemented('floor');\n  }\n  round<T extends Tensor>(x: T): T {\n    return notYetImplemented('round');\n  }\n\n  sign<T extends Tensor>(x: T): T {\n    return notYetImplemented('sign');\n  }\n\n  isNaN<T extends Tensor>(x: T): T {\n    return notYetImplemented('isNaN');\n  }\n  isInf<T extends Tensor>(x: T): T {\n    return notYetImplemented('isInf');\n  }\n  isFinite<T extends Tensor>(x: T): T {\n    return notYetImplemented('isFinite');\n  }\n\n  pow<T extends Tensor>(a: T, b: Tensor): T {\n    return notYetImplemented('pow');\n  }\n  exp<T extends Tensor>(x: T): T {\n    return notYetImplemented('exp');\n  }\n  expm1<T extends Tensor>(x: T): T {\n    return notYetImplemented('expm1');\n  }\n  softmax<T extends Tensor>(x: T, dim: number): T {\n    return notYetImplemented('softmax');\n  }\n  log<T extends Tensor>(x: T): T {\n    return notYetImplemented('log');\n  }\n  log1p<T extends Tensor>(x: T): T {\n    return notYetImplemented('log1p');\n  }\n  sqrt<T extends Tensor>(x: T): T {\n    return notYetImplemented('sqrt');\n  }\n  rsqrt<T extends Tensor>(x: T): T {\n    return notYetImplemented('rsqrt');\n  }\n  square<T extends Tensor>(x: T): T {\n    return notYetImplemented('square');\n  }\n  reciprocal<T extends Tensor>(x: T): T {\n    return notYetImplemented('reciprocal');\n  }\n  relu<T extends Tensor>(x: T): T {\n    return notYetImplemented('relu');\n  }\n  relu6<T extends Tensor>(x: T): T {\n    return notYetImplemented('relu6');\n  }\n  prelu<T extends Tensor>(x: T, a: T): T {\n    return notYetImplemented('prelu');\n  }\n  elu<T extends Tensor>(x: T): T {\n    return notYetImplemented('elu');\n  }\n  eluDer<T extends Tensor>(dy: T, y: T): T {\n    return notYetImplemented('eluDer');\n  }\n  selu<T extends Tensor>(x: T): T {\n    return notYetImplemented('selu');\n  }\n  int<T extends Tensor>(x: T): T {\n    return notYetImplemented('int');\n  }\n\n  clip<T extends Tensor>(x: T, min: number, max: number): T {\n    return notYetImplemented('clip');\n  }\n\n  abs<T extends Tensor>(x: T): T {\n    return notYetImplemented('abs');\n  }\n  complexAbs<T extends Tensor>(x: T): T {\n    return notYetImplemented('complexAbs');\n  }\n\n  sigmoid<T extends Tensor>(x: T): T {\n    return notYetImplemented('sigmoid');\n  }\n\n  softplus<T extends Tensor>(x: T): T {\n    return notYetImplemented('softplus');\n  }\n\n  sin<T extends Tensor>(x: T): T {\n    return notYetImplemented('sin');\n  }\n  cos<T extends Tensor>(x: T): T {\n    return notYetImplemented('cos');\n  }\n  tan<T extends Tensor>(x: T): T {\n    return notYetImplemented('tan');\n  }\n\n  asin<T extends Tensor>(x: T): T {\n    return notYetImplemented('asin');\n  }\n  acos<T extends Tensor>(x: T): T {\n    return notYetImplemented('acos');\n  }\n  atan<T extends Tensor>(x: T): T {\n    return notYetImplemented('atan');\n  }\n  atan2<T extends Tensor>(a: T, b: T): T {\n    return notYetImplemented('atan2');\n  }\n\n  sinh<T extends Tensor>(x: T): T {\n    return notYetImplemented('sinh');\n  }\n  cosh<T extends Tensor>(x: T): T {\n    return notYetImplemented('cosh');\n  }\n  tanh<T extends Tensor>(x: T): T {\n    return notYetImplemented('tanh');\n  }\n\n  asinh<T extends Tensor>(x: T): T {\n    return notYetImplemented('asinh');\n  }\n  acosh<T extends Tensor>(x: T): T {\n    return notYetImplemented('acosh');\n  }\n  atanh<T extends Tensor>(x: T): T {\n    return notYetImplemented('atanh');\n  }\n\n  erf<T extends Tensor>(x: T): T {\n    return notYetImplemented('erf');\n  }\n\n  step<T extends Tensor>(x: T, alpha: number): T {\n    return notYetImplemented('step');\n  }\n\n  fusedConv2d(\n      {input, filter, convInfo, bias, activation, preluActivationWeights}:\n          FusedConv2DConfig): Tensor4D {\n    return notYetImplemented('fusedConv2d');\n  }\n\n  conv2d(x: Tensor4D, filter: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    return notYetImplemented('conv2d');\n  }\n  conv2dDerInput(dy: Tensor4D, filter: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    return notYetImplemented('conv2dDerInput');\n  }\n  conv2dDerFilter(x: Tensor4D, dY: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    return notYetImplemented('conv2dDerFilter');\n  }\n\n  fusedDepthwiseConv2D(\n      {input, filter, convInfo, bias, activation, preluActivationWeights}:\n          FusedConv2DConfig): Tensor4D {\n    return notYetImplemented('fusedDepthwiseConv2D');\n  }\n\n  depthwiseConv2D(input: Tensor4D, filter: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    return notYetImplemented('depthwiseConv2D');\n  }\n  depthwiseConv2DDerInput(dy: Tensor4D, filter: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    return notYetImplemented('depthwiseConv2DDerInput');\n  }\n  depthwiseConv2DDerFilter(x: Tensor4D, dY: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    return notYetImplemented('depthwiseConv2DDerFilter');\n  }\n  conv3d(x: Tensor5D, filter: Tensor5D, convInfo: Conv3DInfo): Tensor5D {\n    return notYetImplemented('conv3d');\n  }\n  conv3dDerInput(dy: Tensor5D, filter: Tensor5D, convInfo: Conv3DInfo):\n      Tensor5D {\n    return notYetImplemented('conv3dDerInput');\n  }\n  conv3dDerFilter(x: Tensor5D, dY: Tensor5D, convInfo: Conv3DInfo): Tensor5D {\n    return notYetImplemented('conv3dDerFilter');\n  }\n  maxPool(x: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    return notYetImplemented('maxPool');\n  }\n  maxPoolBackprop(dy: Tensor4D, x: Tensor4D, y: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    return notYetImplemented('maxPoolBackprop');\n  }\n  avgPool(x: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    return notYetImplemented('avgPool');\n  }\n  avgPoolBackprop(dy: Tensor4D, x: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    return notYetImplemented('avgPoolBackprop');\n  }\n  avgPool3d(x: Tensor5D, convInfo: Conv3DInfo): Tensor5D {\n    return notYetImplemented('avgPool3d');\n  }\n  avgPool3dBackprop(dy: Tensor5D, x: Tensor5D, convInfo: Conv3DInfo): Tensor5D {\n    return notYetImplemented('avgPool3dBackprop');\n  }\n  maxPool3d(x: Tensor5D, convInfo: Conv3DInfo): Tensor5D {\n    return notYetImplemented('maxPool3d');\n  }\n  maxPool3dBackprop(\n      dy: Tensor5D, x: Tensor5D, y: Tensor5D, convInfo: Conv3DInfo): Tensor5D {\n    return notYetImplemented('maxPool3dBackprop');\n  }\n\n  reshape<T extends Tensor, R extends Rank>(x: T, shape: ShapeMap[R]):\n      Tensor<R> {\n    return notYetImplemented('reshape');\n  }\n  cast<T extends Tensor>(x: T, dtype: DataType): T {\n    return notYetImplemented('cast');\n  }\n\n  tile<T extends Tensor>(x: T, reps: number[]): T {\n    return notYetImplemented('tile');\n  }\n\n  pad<T extends Tensor>(\n      x: T, paddings: Array<[number, number]>, constantValue: number): T {\n    return notYetImplemented('pad');\n  }\n\n  transpose<T extends Tensor>(x: T, perm: number[]): T {\n    return notYetImplemented('transpose');\n  }\n\n  gather<T extends Tensor>(x: T, indices: Tensor, axis: number, batchDims = 0):\n      T {\n    return notYetImplemented('gather');\n  }\n\n  gatherND(x: Tensor, indices: Tensor): Tensor {\n    return notYetImplemented('gatherND');\n  }\n\n  scatterND<R extends Rank>(\n      indices: Tensor, updates: Tensor, shape: ShapeMap[R]): Tensor<R> {\n    return notYetImplemented('scatterND');\n  }\n\n  batchToSpaceND<T extends Tensor>(\n      x: T, blockShape: number[], crops: number[][]): T {\n    return notYetImplemented('batchToSpaceND');\n  }\n\n  spaceToBatchND<T extends Tensor>(\n      x: T, blockShape: number[], paddings: number[][]): T {\n    return notYetImplemented('spaceToBatchND');\n  }\n\n  resizeBilinear(\n      x: Tensor4D, newHeight: number, newWidth: number, alignCorners: boolean,\n      halfPixelCenters: boolean): Tensor4D {\n    return notYetImplemented('resizeBilinear');\n  }\n\n  resizeBilinearBackprop(dy: Tensor4D, x: Tensor4D, alignCorners: boolean):\n      Tensor4D {\n    return notYetImplemented('resizeBilinearBackprop');\n  }\n\n  resizeNearestNeighbor(\n      x: Tensor4D, newHEight: number, newWidth: number, alignCorners: boolean,\n      halfPixelCenters: boolean): Tensor4D {\n    return notYetImplemented('resizeNearestNeighbor');\n  }\n\n  resizeNearestNeighborBackprop(\n      dy: Tensor4D, x: Tensor4D, alignCorners: boolean): Tensor4D {\n    return notYetImplemented('resizeNearestNeighborBackprop');\n  }\n\n  batchNorm(\n      x: Tensor4D, mean: Tensor4D|Tensor1D, variance: Tensor4D|Tensor1D,\n      offset?: Tensor4D|Tensor1D, scale?: Tensor4D|Tensor1D,\n      varianceEpsilon?: number): Tensor4D {\n    return notYetImplemented('batchNorm');\n  }\n\n  localResponseNormalization4D(\n      x: Tensor4D, radius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    return notYetImplemented('localResponseNormalization4D');\n  }\n\n  LRNGrad(\n      dy: Tensor4D, inputImage: Tensor4D, outputImage: Tensor4D, radius: number,\n      bias: number, alpha: number, beta: number): Tensor4D {\n    return notYetImplemented('LRNGrad');\n  }\n\n  multinomial(\n      logits: Tensor2D, normalized: boolean, numSamples: number,\n      seed: number): Tensor2D {\n    return notYetImplemented('multinomial');\n  }\n\n  oneHot(indices: Tensor1D, depth: number, onValue: number, offValue: number):\n      Tensor2D {\n    return notYetImplemented('oneHot');\n  }\n\n  cumsum(x: Tensor, axis: number, exclusive: boolean, reverse: boolean):\n      Tensor {\n    return notYetImplemented('cumsum');\n  }\n\n  nonMaxSuppression(\n      boxes: Tensor2D, scores: Tensor1D, maxOutputSize: number,\n      iouThreshold: number, scoreThreshold?: number): Tensor1D {\n    return notYetImplemented('nonMaxSuppression');\n  }\n\n  fft(x: Tensor2D): Tensor2D {\n    return notYetImplemented('fft');\n  }\n  ifft(x: Tensor2D): Tensor2D {\n    return notYetImplemented('ifft');\n  }\n  complex<T extends Tensor>(real: T, imag: T): T {\n    return notYetImplemented('complex');\n  }\n  real<T extends Tensor>(input: T): T {\n    return notYetImplemented('real');\n  }\n  imag<T extends Tensor>(input: T): T {\n    return notYetImplemented('imag');\n  }\n\n  cropAndResize(\n      image: Tensor4D, boxes: Tensor2D, boxIndex: Tensor1D,\n      cropSize: [number, number], method: 'bilinear'|'nearest',\n      extrapolationValue: number): Tensor4D {\n    return notYetImplemented('cropAndResize');\n  }\n\n  depthToSpace(x: Tensor4D, blockSize: number, dataFormat: string): Tensor4D {\n    return notYetImplemented('depthToSpace');\n  }\n\n  // Aligns with the \"SplitV\" kernel in TensorFlow.\n  split<T extends Tensor>(value: T, sizeSplits: number[], axis: number): T[] {\n    return notYetImplemented('split');\n  }\n\n  sparseToDense<R extends Rank>(\n      sparseIndices: Tensor, sparseValues: Tensor, outputShape: ShapeMap[R],\n      defaultValue: Scalar): Tensor<R> {\n    return notYetImplemented('sparseToDense');\n  }\n\n  diag(x: Tensor): Tensor {\n    return notYetImplemented('diag');\n  }\n\n  fill<R extends Rank>(\n      shape: ShapeMap[R], value: number|string, dtype?: DataType): Tensor<R> {\n    return notYetImplemented('fill');\n  }\n\n  onesLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    return notYetImplemented('onesLike');\n  }\n\n  zerosLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    return notYetImplemented('zerosLike');\n  }\n\n  linspace(start: number, stop: number, num: number): Tensor1D {\n    return notYetImplemented('linspace');\n  }\n\n  dispose(): void {\n    return notYetImplemented('dispose');\n  }\n}\n\nfunction notYetImplemented(kernelName: string): never {\n  throw new Error(\n      `'${kernelName}' not yet implemented or not found in the registry. ` +\n      `This kernel may not be supported by the tfjs backend you have chosen`);\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAsBA,OAAO,MAAMA,eAAe,GAAG,IAAI;AACnC,OAAO,MAAMC,eAAe,GAAG,IAAI;AAqBnC;AACA,OAAM,MAAOC,WAAW;EAItBC,YAAoBC,OAAsB,EAAUC,SAAoB;IAApD,KAAAD,OAAO,GAAPA,OAAO;IAAyB,KAAAC,SAAS,GAATA,SAAS;IAHrD,KAAAC,IAAI,GAAG,IAAIC,OAAO,EAAa;IAC/B,KAAAC,YAAY,GAAG,CAAC;EAEmD;EAE3EC,GAAGA,CAACC,MAAc;IAChB,IAAI,CAAC,IAAI,CAACJ,IAAI,CAACK,GAAG,CAACD,MAAM,CAAC,EAAE;MAC1B,IAAI,CAACL,SAAS,CAACO,QAAQ,CAAC,IAAI,CAACR,OAAO,EAAEM,MAAM,CAAC;;IAE/C,OAAO,IAAI,CAACJ,IAAI,CAACG,GAAG,CAACC,MAAM,CAAC;EAC9B;EAEAG,GAAGA,CAACH,MAAc,EAAEI,KAAQ;IAC1B,IAAI,CAACN,YAAY,EAAE;IACnB,IAAI,CAACF,IAAI,CAACO,GAAG,CAACH,MAAM,EAAEI,KAAK,CAAC;EAC9B;EAEAH,GAAGA,CAACD,MAAc;IAChB,OAAO,IAAI,CAACJ,IAAI,CAACK,GAAG,CAACD,MAAM,CAAC;EAC9B;EAEAK,MAAMA,CAACL,MAAc;IACnB,IAAI,CAACF,YAAY,EAAE;IACnB,OAAO,IAAI,CAACF,IAAI,CAACS,MAAM,CAACL,MAAM,CAAC;EACjC;EAEAM,UAAUA,CAAA;IACR,OAAO,IAAI,CAACR,YAAY;EAC1B;;AAgBF;;;;;;AAMA,OAAM,MAAOS,aAAa;EACxB;;;;;;;EAOAC,aAAaA,CAACR,MAAc;IAC1B;EACF;EACAS,IAAIA,CAACC,CAAa;IAChB,OAAOC,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAC,IAAIA,CAACZ,MAAc;IACjB,OAAOW,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAE,QAAQA,CAACb,MAAc;IACrB,OAAOW,iBAAiB,CAAC,UAAU,CAAC;EACtC;EACAL,UAAUA,CAAA;IACR,OAAOK,iBAAiB,CAAC,YAAY,CAAC;EACxC;EACAG,WAAWA,CAACd,MAAc;IACxB,OAAOW,iBAAiB,CAAC,aAAa,CAAC;EACzC;EACAI,KAAKA,CAACC,MAAqB,EAAEC,KAAe,EAAEC,KAAe;IAC3D,OAAOP,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAQ,IAAIA,CAACnB,MAAc,EAAEgB,MAAqB,EAAEC,KAAe,EAAEC,KAAe;IAE1E,OAAOP,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAS,MAAMA,CAAA;IACJ,OAAOT,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EACA;EACAU,cAAcA,CAAA;IACZ,OAAOV,iBAAiB,CAAC,gBAAgB,CAAC;EAC5C;EACA;EACAW,OAAOA,CAAA;IACL,OAAO,IAAI,CAACD,cAAc,EAAE,KAAK,EAAE,GAAG/B,eAAe,GAAGC,eAAe;EACzE;EAEAgC,WAAWA,CACPC,CAAW,EAAEC,CAAW,EAAEC,UAAmB,EAC7CC,UAAmB;IACrB,OAAOhB,iBAAiB,CAAC,aAAa,CAAC;EACzC;EAEAiB,gBAAgBA,CAAAC,IAAA,EAEc;IAAA,IAD1B;MAACL,CAAC;MAAEC,CAAC;MAAEC,UAAU;MAAEC,UAAU;MAAEG,IAAI;MAAEC,UAAU;MAAEC;IAAsB,CAC7C,GAAAH,IAAA;IAC5B,OAAOlB,iBAAiB,CAAC,kBAAkB,CAAC;EAC9C;EAEAsB,KAAKA,CAAmBC,CAAI,EAAEC,KAAe,EAAEC,IAAc;IAC3D,OAAOzB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACA0B,YAAYA,CACRH,CAAI,EAAEC,KAAe,EAAEG,GAAa,EAAEC,OAAiB;IACzD,OAAO5B,iBAAiB,CAAC,cAAc,CAAC;EAC1C;EACA6B,OAAOA,CAACN,CAAS,EAAEO,IAAY;IAC7B,OAAO9B,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACA+B,OAAOA,CAAmBlB,CAAI,EAAEiB,IAAc;IAC5C,OAAO9B,iBAAiB,CAAC,SAAS,CAAC;EACrC;EAEAgC,MAAMA,CAACC,OAAiB,EAAEH,IAAY;IACpC,OAAO9B,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EAEAkC,GAAGA,CAAmBrB,CAAI;IACxB,OAAOb,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEAmC,GAAGA,CAACtB,CAAS,EAAEC,CAAS;IACtB,OAAOd,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAoC,IAAIA,CAAmBH,OAAY;IACjC,OAAOjC,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAqC,QAAQA,CAACxB,CAAS,EAAEC,CAAS;IAC3B,OAAOd,iBAAiB,CAAC,UAAU,CAAC;EACtC;EACAsC,QAAQA,CAACzB,CAAS,EAAEC,CAAS;IAC3B,OAAOd,iBAAiB,CAAC,UAAU,CAAC;EACtC;EACAuC,UAAUA,CAAC1B,CAAS,EAAEC,CAAS;IAC7B,OAAOd,iBAAiB,CAAC,YAAY,CAAC;EACxC;EACAwC,QAAQA,CAAC3B,CAAS,EAAEC,CAAS;IAC3B,OAAOd,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEAyC,GAAGA,CAAClB,CAAS,EAAEmB,IAAc;IAC3B,OAAO1C,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACA2C,IAAIA,CAACpB,CAAS,EAAEmB,IAAc;IAC5B,OAAO1C,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEA4C,kBAAkBA,CACdrB,CAAI,EAAEsB,UAAoB,EAAEC,WAAmB;IACjD,OAAO9C,iBAAiB,CAAC,oBAAoB,CAAC;EAChD;EAEA+C,MAAMA,CAACxB,CAAS,EAAEO,IAAY;IAC5B,OAAO9B,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EACAgD,MAAMA,CAACzB,CAAS,EAAEO,IAAY;IAC5B,OAAO9B,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EAEAiD,KAAKA,CAACpC,CAAS,EAAEC,CAAS;IACxB,OAAOd,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAkD,QAAQA,CAACrC,CAAS,EAAEC,CAAS;IAC3B,OAAOd,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEAmD,IAAIA,CAACtC,CAAS,EAAEC,CAAS;IACvB,OAAOd,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAoD,SAASA,CAACvC,CAAS,EAAEC,CAAS;IAC5B,OAAOd,iBAAiB,CAAC,WAAW,CAAC;EACvC;EAEAqD,OAAOA,CAACxC,CAAS,EAAEC,CAAS;IAC1B,OAAOd,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACAsD,YAAYA,CAACzC,CAAS,EAAEC,CAAS;IAC/B,OAAOd,iBAAiB,CAAC,cAAc,CAAC;EAC1C;EAEAuD,UAAUA,CAAmB1C,CAAI;IAC/B,OAAOb,iBAAiB,CAAC,YAAY,CAAC;EACxC;EACAwD,UAAUA,CAAC3C,CAAS,EAAEC,CAAS;IAC7B,OAAOd,iBAAiB,CAAC,YAAY,CAAC;EACxC;EACAyD,SAASA,CAAC5C,CAAS,EAAEC,CAAS;IAC5B,OAAOd,iBAAiB,CAAC,WAAW,CAAC;EACvC;EAEA0D,KAAKA,CAACC,SAAiB;IACrB,OAAO3D,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACA4D,MAAMA,CAACD,SAAiB,EAAE9C,CAAS,EAAEC,CAAS;IAC5C,OAAOd,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EAEA6D,IAAIA,CAAmBtC,CAAI,EAAEuC,CAAS,EAAEC,MAAe;IACrD,OAAO/D,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAgE,GAAGA,CAACzC,CAAS,EAAEmB,IAAc;IAC3B,OAAO1C,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAiE,OAAOA,CAACpD,CAAS,EAAEC,CAAS;IAC1B,OAAOd,iBAAiB,CAAC,SAAS,CAAC;EACrC;EAEAkE,GAAGA,CAACrD,CAAS,EAAEC,CAAS;IACtB,OAAOd,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEAmE,GAAGA,CAAC5C,CAAS,EAAEmB,IAAc;IAC3B,OAAO1C,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAoE,OAAOA,CAACvD,CAAS,EAAEC,CAAS;IAC1B,OAAOd,iBAAiB,CAAC,SAAS,CAAC;EACrC;EAEAqE,GAAGA,CAAC9C,CAAS,EAAEmB,IAAc;IAC3B,OAAO1C,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAsE,GAAGA,CAAC/C,CAAS,EAAEmB,IAAc;IAC3B,OAAO1C,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEAuE,iBAAiBA,CAAC1D,CAAS,EAAEC,CAAS;IACpC,OAAOd,iBAAiB,CAAC,mBAAmB,CAAC;EAC/C;EAEAwE,IAAIA,CAAmBjD,CAAI;IACzB,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAyE,KAAKA,CAAmBlD,CAAI;IAC1B,OAAOvB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACA0E,KAAKA,CAAmBnD,CAAI;IAC1B,OAAOvB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EAEA2E,IAAIA,CAAmBpD,CAAI;IACzB,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEA4E,KAAKA,CAAmBrD,CAAI;IAC1B,OAAOvB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACA6E,KAAKA,CAAmBtD,CAAI;IAC1B,OAAOvB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACA8E,QAAQA,CAAmBvD,CAAI;IAC7B,OAAOvB,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEA+E,GAAGA,CAAmBlE,CAAI,EAAEC,CAAS;IACnC,OAAOd,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAgF,GAAGA,CAAmBzD,CAAI;IACxB,OAAOvB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAiF,KAAKA,CAAmB1D,CAAI;IAC1B,OAAOvB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAkF,OAAOA,CAAmB3D,CAAI,EAAE4D,GAAW;IACzC,OAAOnF,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACAoF,GAAGA,CAAmB7D,CAAI;IACxB,OAAOvB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAqF,KAAKA,CAAmB9D,CAAI;IAC1B,OAAOvB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAsF,IAAIA,CAAmB/D,CAAI;IACzB,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAuF,KAAKA,CAAmBhE,CAAI;IAC1B,OAAOvB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAwF,MAAMA,CAAmBjE,CAAI;IAC3B,OAAOvB,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EACAyF,UAAUA,CAAmBlE,CAAI;IAC/B,OAAOvB,iBAAiB,CAAC,YAAY,CAAC;EACxC;EACA0F,IAAIA,CAAmBnE,CAAI;IACzB,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACA2F,KAAKA,CAAmBpE,CAAI;IAC1B,OAAOvB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACA4F,KAAKA,CAAmBrE,CAAI,EAAEV,CAAI;IAChC,OAAOb,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACA6F,GAAGA,CAAmBtE,CAAI;IACxB,OAAOvB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACA8F,MAAMA,CAAmBC,EAAK,EAAEC,CAAI;IAClC,OAAOhG,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EACAiG,IAAIA,CAAmB1E,CAAI;IACzB,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAkG,GAAGA,CAAmB3E,CAAI;IACxB,OAAOvB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEAmG,IAAIA,CAAmB5E,CAAI,EAAEyC,GAAW,EAAEG,GAAW;IACnD,OAAOnE,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAoG,GAAGA,CAAmB7E,CAAI;IACxB,OAAOvB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAqG,UAAUA,CAAmB9E,CAAI;IAC/B,OAAOvB,iBAAiB,CAAC,YAAY,CAAC;EACxC;EAEAsG,OAAOA,CAAmB/E,CAAI;IAC5B,OAAOvB,iBAAiB,CAAC,SAAS,CAAC;EACrC;EAEAuG,QAAQA,CAAmBhF,CAAI;IAC7B,OAAOvB,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEAwG,GAAGA,CAAmBjF,CAAI;IACxB,OAAOvB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAyG,GAAGA,CAAmBlF,CAAI;IACxB,OAAOvB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACA0G,GAAGA,CAAmBnF,CAAI;IACxB,OAAOvB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEA2G,IAAIA,CAAmBpF,CAAI;IACzB,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACA4G,IAAIA,CAAmBrF,CAAI;IACzB,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACA6G,IAAIA,CAAmBtF,CAAI;IACzB,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACA8G,KAAKA,CAAmBjG,CAAI,EAAEC,CAAI;IAChC,OAAOd,iBAAiB,CAAC,OAAO,CAAC;EACnC;EAEA+G,IAAIA,CAAmBxF,CAAI;IACzB,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAgH,IAAIA,CAAmBzF,CAAI;IACzB,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAiH,IAAIA,CAAmB1F,CAAI;IACzB,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAkH,KAAKA,CAAmB3F,CAAI;IAC1B,OAAOvB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAmH,KAAKA,CAAmB5F,CAAI;IAC1B,OAAOvB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAoH,KAAKA,CAAmB7F,CAAI;IAC1B,OAAOvB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EAEAqH,GAAGA,CAAmB9F,CAAI;IACxB,OAAOvB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEAsH,IAAIA,CAAmB/F,CAAI,EAAEgG,KAAa;IACxC,OAAOvH,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAwH,WAAWA,CAAAC,KAAA,EAEc;IAAA,IADrB;MAACC,KAAK;MAAEC,MAAM;MAAEC,QAAQ;MAAEzG,IAAI;MAAEC,UAAU;MAAEC;IAAsB,CAC7C,GAAAoG,KAAA;IACvB,OAAOzH,iBAAiB,CAAC,aAAa,CAAC;EACzC;EAEA6H,MAAMA,CAACtG,CAAW,EAAEoG,MAAgB,EAAEC,QAAoB;IACxD,OAAO5H,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EACA8H,cAAcA,CAAC/B,EAAY,EAAE4B,MAAgB,EAAEC,QAAoB;IAEjE,OAAO5H,iBAAiB,CAAC,gBAAgB,CAAC;EAC5C;EACA+H,eAAeA,CAACxG,CAAW,EAAEyG,EAAY,EAAEJ,QAAoB;IAC7D,OAAO5H,iBAAiB,CAAC,iBAAiB,CAAC;EAC7C;EAEAiI,oBAAoBA,CAAAC,KAAA,EAEK;IAAA,IADrB;MAACR,KAAK;MAAEC,MAAM;MAAEC,QAAQ;MAAEzG,IAAI;MAAEC,UAAU;MAAEC;IAAsB,CAC7C,GAAA6G,KAAA;IACvB,OAAOlI,iBAAiB,CAAC,sBAAsB,CAAC;EAClD;EAEAmI,eAAeA,CAACT,KAAe,EAAEC,MAAgB,EAAEC,QAAoB;IAErE,OAAO5H,iBAAiB,CAAC,iBAAiB,CAAC;EAC7C;EACAoI,uBAAuBA,CAACrC,EAAY,EAAE4B,MAAgB,EAAEC,QAAoB;IAE1E,OAAO5H,iBAAiB,CAAC,yBAAyB,CAAC;EACrD;EACAqI,wBAAwBA,CAAC9G,CAAW,EAAEyG,EAAY,EAAEJ,QAAoB;IAEtE,OAAO5H,iBAAiB,CAAC,0BAA0B,CAAC;EACtD;EACAsI,MAAMA,CAAC/G,CAAW,EAAEoG,MAAgB,EAAEC,QAAoB;IACxD,OAAO5H,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EACAuI,cAAcA,CAACxC,EAAY,EAAE4B,MAAgB,EAAEC,QAAoB;IAEjE,OAAO5H,iBAAiB,CAAC,gBAAgB,CAAC;EAC5C;EACAwI,eAAeA,CAACjH,CAAW,EAAEyG,EAAY,EAAEJ,QAAoB;IAC7D,OAAO5H,iBAAiB,CAAC,iBAAiB,CAAC;EAC7C;EACAyI,OAAOA,CAAClH,CAAW,EAAEqG,QAAoB;IACvC,OAAO5H,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACA0I,eAAeA,CAAC3C,EAAY,EAAExE,CAAW,EAAEyE,CAAW,EAAE4B,QAAoB;IAE1E,OAAO5H,iBAAiB,CAAC,iBAAiB,CAAC;EAC7C;EACA2I,OAAOA,CAACpH,CAAW,EAAEqG,QAAoB;IACvC,OAAO5H,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACA4I,eAAeA,CAAC7C,EAAY,EAAExE,CAAW,EAAEqG,QAAoB;IAC7D,OAAO5H,iBAAiB,CAAC,iBAAiB,CAAC;EAC7C;EACA6I,SAASA,CAACtH,CAAW,EAAEqG,QAAoB;IACzC,OAAO5H,iBAAiB,CAAC,WAAW,CAAC;EACvC;EACA8I,iBAAiBA,CAAC/C,EAAY,EAAExE,CAAW,EAAEqG,QAAoB;IAC/D,OAAO5H,iBAAiB,CAAC,mBAAmB,CAAC;EAC/C;EACA+I,SAASA,CAACxH,CAAW,EAAEqG,QAAoB;IACzC,OAAO5H,iBAAiB,CAAC,WAAW,CAAC;EACvC;EACAgJ,iBAAiBA,CACbjD,EAAY,EAAExE,CAAW,EAAEyE,CAAW,EAAE4B,QAAoB;IAC9D,OAAO5H,iBAAiB,CAAC,mBAAmB,CAAC;EAC/C;EAEAiJ,OAAOA,CAAmC1H,CAAI,EAAEjB,KAAkB;IAEhE,OAAON,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACAkJ,IAAIA,CAAmB3H,CAAI,EAAEhB,KAAe;IAC1C,OAAOP,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAmJ,IAAIA,CAAmB5H,CAAI,EAAE6H,IAAc;IACzC,OAAOpJ,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAqJ,GAAGA,CACC9H,CAAI,EAAE+H,QAAiC,EAAEC,aAAqB;IAChE,OAAOvJ,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEAwJ,SAASA,CAAmBjI,CAAI,EAAEkI,IAAc;IAC9C,OAAOzJ,iBAAiB,CAAC,WAAW,CAAC;EACvC;EAEA0J,MAAMA,CAAmBnI,CAAI,EAAEoI,OAAe,EAAE7H,IAAY,EAAe;IAAA,IAAb8H,SAAS,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC;IAEzE,OAAO7J,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EAEAgK,QAAQA,CAACzI,CAAS,EAAEoI,OAAe;IACjC,OAAO3J,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEAiK,SAASA,CACLN,OAAe,EAAEO,OAAe,EAAE5J,KAAkB;IACtD,OAAON,iBAAiB,CAAC,WAAW,CAAC;EACvC;EAEAmK,cAAcA,CACV5I,CAAI,EAAE6I,UAAoB,EAAEC,KAAiB;IAC/C,OAAOrK,iBAAiB,CAAC,gBAAgB,CAAC;EAC5C;EAEAsK,cAAcA,CACV/I,CAAI,EAAE6I,UAAoB,EAAEd,QAAoB;IAClD,OAAOtJ,iBAAiB,CAAC,gBAAgB,CAAC;EAC5C;EAEAuK,cAAcA,CACVhJ,CAAW,EAAEiJ,SAAiB,EAAEC,QAAgB,EAAEC,YAAqB,EACvEC,gBAAyB;IAC3B,OAAO3K,iBAAiB,CAAC,gBAAgB,CAAC;EAC5C;EAEA4K,sBAAsBA,CAAC7E,EAAY,EAAExE,CAAW,EAAEmJ,YAAqB;IAErE,OAAO1K,iBAAiB,CAAC,wBAAwB,CAAC;EACpD;EAEA6K,qBAAqBA,CACjBtJ,CAAW,EAAEuJ,SAAiB,EAAEL,QAAgB,EAAEC,YAAqB,EACvEC,gBAAyB;IAC3B,OAAO3K,iBAAiB,CAAC,uBAAuB,CAAC;EACnD;EAEA+K,6BAA6BA,CACzBhF,EAAY,EAAExE,CAAW,EAAEmJ,YAAqB;IAClD,OAAO1K,iBAAiB,CAAC,+BAA+B,CAAC;EAC3D;EAEAgL,SAASA,CACLzJ,CAAW,EAAE0J,IAAuB,EAAEC,QAA2B,EACjEC,MAA0B,EAAEC,KAAyB,EACrDC,eAAwB;IAC1B,OAAOrL,iBAAiB,CAAC,WAAW,CAAC;EACvC;EAEAsL,4BAA4BA,CACxB/J,CAAW,EAAEgK,MAAc,EAAEpK,IAAY,EAAEoG,KAAa,EACxDiE,IAAY;IACd,OAAOxL,iBAAiB,CAAC,8BAA8B,CAAC;EAC1D;EAEAyL,OAAOA,CACH1F,EAAY,EAAE2F,UAAoB,EAAEC,WAAqB,EAAEJ,MAAc,EACzEpK,IAAY,EAAEoG,KAAa,EAAEiE,IAAY;IAC3C,OAAOxL,iBAAiB,CAAC,SAAS,CAAC;EACrC;EAEA4L,WAAWA,CACPC,MAAgB,EAAEC,UAAmB,EAAEC,UAAkB,EACzDC,IAAY;IACd,OAAOhM,iBAAiB,CAAC,aAAa,CAAC;EACzC;EAEAiM,MAAMA,CAACtC,OAAiB,EAAEuC,KAAa,EAAEC,OAAe,EAAEC,QAAgB;IAExE,OAAOpM,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EAEAqM,MAAMA,CAAC9K,CAAS,EAAEO,IAAY,EAAEwK,SAAkB,EAAEvK,OAAgB;IAElE,OAAO/B,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EAEAuM,iBAAiBA,CACbC,KAAe,EAAEC,MAAgB,EAAEC,aAAqB,EACxDC,YAAoB,EAAEC,cAAuB;IAC/C,OAAO5M,iBAAiB,CAAC,mBAAmB,CAAC;EAC/C;EAEA6M,GAAGA,CAACtL,CAAW;IACb,OAAOvB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACA8M,IAAIA,CAACvL,CAAW;IACd,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACA+M,OAAOA,CAAmBC,IAAO,EAAEC,IAAO;IACxC,OAAOjN,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACAgN,IAAIA,CAAmBtF,KAAQ;IAC7B,OAAO1H,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAiN,IAAIA,CAAmBvF,KAAQ;IAC7B,OAAO1H,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAkN,aAAaA,CACTC,KAAe,EAAEX,KAAe,EAAEY,QAAkB,EACpDC,QAA0B,EAAEC,MAA4B,EACxDC,kBAA0B;IAC5B,OAAOvN,iBAAiB,CAAC,eAAe,CAAC;EAC3C;EAEAwN,YAAYA,CAACjM,CAAW,EAAEkM,SAAiB,EAAEC,UAAkB;IAC7D,OAAO1N,iBAAiB,CAAC,cAAc,CAAC;EAC1C;EAEA;EACA2N,KAAKA,CAAmBlO,KAAQ,EAAEmO,UAAoB,EAAE9L,IAAY;IAClE,OAAO9B,iBAAiB,CAAC,OAAO,CAAC;EACnC;EAEA6N,aAAaA,CACTC,aAAqB,EAAEC,YAAoB,EAAEC,WAAwB,EACrEC,YAAoB;IACtB,OAAOjO,iBAAiB,CAAC,eAAe,CAAC;EAC3C;EAEAkO,IAAIA,CAAC3M,CAAS;IACZ,OAAOvB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAmO,IAAIA,CACA7N,KAAkB,EAAEb,KAAoB,EAAEc,KAAgB;IAC5D,OAAOP,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAoO,QAAQA,CAAiB7M,CAAY;IACnC,OAAOvB,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEAqO,SAASA,CAAiB9M,CAAY;IACpC,OAAOvB,iBAAiB,CAAC,WAAW,CAAC;EACvC;EAEAsO,QAAQA,CAACC,KAAa,EAAEC,IAAY,EAAEC,GAAW;IAC/C,OAAOzO,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEA0O,OAAOA,CAAA;IACL,OAAO1O,iBAAiB,CAAC,SAAS,CAAC;EACrC;;AAGF,SAASA,iBAAiBA,CAAC2O,UAAkB;EAC3C,MAAM,IAAIC,KAAK,CACX,IAAA5M,MAAA,CAAI2M,UAAU,kIACwD,CAAC;AAC7E"},"metadata":{},"sourceType":"module","externalDependencies":[]}