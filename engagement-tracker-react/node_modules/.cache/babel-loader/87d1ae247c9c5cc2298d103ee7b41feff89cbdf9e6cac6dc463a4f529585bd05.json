{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tidy, util } from '@tensorflow/tfjs-core';\nimport { getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName } from '../operations/executors/utils';\nimport { executeOp } from '../operations/operation_executor';\nimport { ExecutionContext } from './execution_context';\nimport { getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow } from './model_analysis';\nexport class GraphExecutor {\n  /**\n   *\n   * @param graph Graph the model or function graph to be executed.\n   * @param parent When building function exector you need to set the parent\n   * executor. Since the weights and function executor maps are set at parant\n   * level, that function executor can access the function maps and weight maps\n   * through the parent.\n   */\n  constructor(graph, parent) {\n    this.graph = graph;\n    this.parent = parent;\n    this.compiledMap = new Map();\n    this._weightMap = {};\n    this.SEPERATOR = ',';\n    this._functions = {};\n    this._functionExecutorMap = {};\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._initNodes = graph.initNodes;\n    this._signature = graph.signature;\n    this._functions = graph.functions;\n    // create sub-graph executors\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(name => {\n        this._functionExecutorMap[name] = new GraphExecutor(graph.functions[name], this);\n      });\n    }\n  }\n  get weightIds() {\n    return this.parent ? this.parent.weightIds : this._weightIds;\n  }\n  get functionExecutorMap() {\n    return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;\n  }\n  get weightMap() {\n    return this.parent ? this.parent.weightMap : this._weightMap;\n  }\n  set weightMap(weightMap) {\n    const weightIds = Object.keys(weightMap).map(key => weightMap[key].map(tensor => tensor.id));\n    this._weightIds = [].concat(...weightIds);\n    this._weightMap = weightMap;\n  }\n  /**\n   * Set `ResourceManager` shared by executors of a model.\n   * @param resourceManager: `ResourceManager` of the `GraphModel`.\n   */\n  set resourceManager(resourceManager) {\n    this._resourceManager = resourceManager;\n  }\n  get inputs() {\n    return this._inputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n        dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n      };\n    });\n  }\n  get outputs() {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n        dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n      };\n    });\n  }\n  get inputNodes() {\n    return this._inputs.map(node => node.signatureKey || node.name);\n  }\n  get outputNodes() {\n    return this._outputs.map(node => {\n      const name = node.signatureKey || node.name;\n      return node.defaultOutput ? \"\".concat(name, \":\").concat(node.defaultOutput) : name;\n    });\n  }\n  get functions() {\n    return Object.keys(this._functions).reduce((map, key) => {\n      map[key] = this._functions[key].signature;\n      return map;\n    }, {});\n  }\n  getCompilationKey(inputs, outputs) {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPERATOR) + '--' + sortedOutputs.join(this.SEPERATOR);\n  }\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   */\n  compile(inputs, outputs) {\n    const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n    const {\n      missingInputs,\n      dynamicNode,\n      syncInputs\n    } = executionInfo;\n    if (dynamicNode != null) {\n      throw new Error(\"This execution contains the node '\".concat(dynamicNode.name, \"', which has \") + \"the dynamic op '\".concat(dynamicNode.op, \"'. Please use \") + \"model.executeAsync() instead. Alternatively, to avoid the \" + \"dynamic ops, specify the inputs [\".concat(syncInputs, \"]\"));\n    }\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(\"Cannot compute the outputs [\".concat(outNames, \"] from the provided inputs \") + \"[\".concat(inNames, \"]. Missing the following inputs: [\").concat(missingInputs, \"]\"));\n    }\n    return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);\n  }\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model, if\n   * no outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   */\n  execute(inputs, outputs) {\n    inputs = this.mapInputs(inputs);\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n    // Do nothing if the compiled graph cache contains the input.\n    let orderedNodes = this.compiledMap.get(compilationKey);\n    if (orderedNodes == null) {\n      orderedNodes = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, orderedNodes);\n    }\n    const tensorArrayMap = {};\n    const tensorListMap = {};\n    return tidy(() => {\n      const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n      const tensorsMap = Object.assign({}, this.weightMap);\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name);\n        const tensors = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n      });\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const intermediateTensorConsumerCount = {};\n      for (let i = 0; i < orderedNodes.length; i++) {\n        const node = orderedNodes[i];\n        if (!tensorsMap[node.name]) {\n          const tensors = executeOp(node, tensorsMap, context, this._resourceManager);\n          if (util.isPromise(tensors)) {\n            throw new Error(\"The execution of the op '\".concat(node.op, \"' returned a promise. \") + \"Please use model.executeAsync() instead.\");\n          }\n          tensorsMap[node.name] = tensors;\n          this.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount);\n        }\n      }\n      // dispose the context for the root executor\n      if (this.parent == null) {\n        context.dispose(tensorsToKeep);\n      }\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n  getFrozenTensorIds(tensorMap) {\n    const ids = [].concat.apply([], Object.keys(tensorMap).map(key => tensorMap[key]).map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n  checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n      return;\n    }\n    tensorMap[nodeName].forEach(tensor => {\n      if (tensor != null) {\n        intermediateTensorConsumerCount[tensor.id] = (intermediateTensorConsumerCount[tensor.id] || 0) + node.children.length;\n      }\n    });\n    node.inputs.forEach(input => {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (input.category !== 'control') {\n        const tensors = getTensorsForCurrentContenxt(input.name, tensorMap, context);\n        if (tensors != null) {\n          tensors.forEach(tensor => {\n            if (tensor && !tensorsToKeep.has(tensor.id)) {\n              const count = intermediateTensorConsumerCount[tensor.id];\n              if (count === 1) {\n                tensor.dispose();\n                delete intermediateTensorConsumerCount[tensor.id];\n              } else if (count != null) {\n                // only intermediate nodes has count set, inputs and weights are\n                // not.\n                intermediateTensorConsumerCount[tensor.id]--;\n              }\n            }\n          });\n        }\n      }\n    });\n  }\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  async executeAsync(inputs, outputs) {\n    return this._executeAsync(inputs, outputs);\n  }\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Optional. Flag for executing a function.\n   * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n   * function execution.\n   * @param tensorArrayMap Optinal global TensorList map by id. Used for\n   * function execution.\n   */\n  async _executeAsync(inputs, outputs) {\n    let isFunctionExecution = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n    let tensorArrayMap = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n    let tensorListMap = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : {};\n    if (!isFunctionExecution) {\n      inputs = this.mapInputs(inputs);\n      this.checkInputs(inputs);\n      this.checkInputShapeAndType(inputs);\n      outputs = this.mapOutputs(outputs);\n      this.checkOutputs(outputs);\n    }\n    const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n    // Graph with control flow op requires runtime evaluation of the execution\n    // order, while without control flow the execution order is pre-determined\n    // in the compile method.\n    const tensorMap = await this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);\n    const results = outputs.map(name => getTensor(name, tensorMap, context));\n    // dispose all the intermediate tensors\n    const outputIds = results.map(t => t.id);\n    const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n    const keepIds = new Set([...outputIds, ...inputIds, ...this.weightIds]);\n    Object.keys(tensorMap).forEach(key => {\n      const tensorArray = tensorMap[key];\n      tensorArray.forEach(tensor => {\n        if (tensor && !tensor.isDisposed && !keepIds.has(tensor.id)) {\n          tensor.dispose();\n        }\n      });\n    });\n    // dispose the context for the root executor\n    if (this.parent == null) {\n      context.dispose(keepIds);\n    }\n    return results;\n  }\n  async executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {\n    const mappedInputs = inputs.reduce((map, tensor, index) => {\n      map[this.inputs[index].name] = tensor;\n      return map;\n    }, {});\n    return this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n  }\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   * @param outputNames Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Flag for executing a function.\n   */\n  async executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {\n    const names = Object.keys(inputs);\n    const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n    const {\n      usedNodes,\n      missingInputs,\n      dynamicNode,\n      syncInputs\n    } = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes);\n    // First nodes to execute include inputNodes, weights, and initNodes.\n    const stack = [...inputNodes, ...this.graph.weights, ...(this._initNodes || [])].map(node => {\n      return {\n        node,\n        contexts: context.currentContext\n      };\n    });\n    const tensorsMap = Object.assign({}, this.weightMap);\n    Object.keys(inputs).forEach(name => {\n      const [nodeName, index] = parseNodeName(name);\n      const tensors = [];\n      tensors[index] = inputs[name];\n      tensorsMap[nodeName] = tensors;\n    });\n    const intermediateTensorConsumerCount = {};\n    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n    const added = {};\n    while (stack.length > 0) {\n      const promises = this.processStack(inputNodes, stack, context, tensorsMap, added, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n      await Promise.all(promises);\n    }\n    if (dynamicNode == null && !isFunctionExecution) {\n      console.warn(\"This model execution did not contain any nodes with control flow \" + \"or dynamic output shapes. You can use model.execute() instead.\");\n    }\n    const missingOutputs = outputNodes.filter(node => !isControlFlow(node) && !getTensor(node.name, tensorsMap, context)).map(node => node.name);\n    if (missingOutputs.length > 0) {\n      let alternativeMsg = '';\n      if (dynamicNode != null) {\n        alternativeMsg = \"Alternatively, to avoid the dynamic ops, use model.execute() \" + \"and specify the inputs [\".concat(syncInputs, \"]\");\n      }\n      throw new Error(\"Cannot compute the outputs [\".concat(missingOutputs, \"] from the provided \") + \"inputs [\".concat(names, \"]. Consider providing the following inputs: \") + \"[\".concat(missingInputs, \"]. \").concat(alternativeMsg));\n    }\n    return tensorsMap;\n  }\n  processStack(inputNodes, stack, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {\n    const promises = [];\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = '';\n      // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n      if (item.node.op === 'Enter' && getParamValue('isConstant', item.node, tensorMap, context)) {\n        [nodeName] = getNodeNameAndIndex(item.node.name, context);\n      }\n      // only process nodes that are not in the tensorMap yet, this include\n      // inputNodes and internal initNodes.\n      if (tensorMap[item.node.name] == null) {\n        const tensors = executeOp(item.node, tensorMap, context, this._resourceManager);\n        if (!nodeName) {\n          [nodeName] = getNodeNameAndIndex(item.node.name, context);\n        }\n        const currentContext = context.currentContext;\n        if (util.isPromise(tensors)) {\n          promises.push(tensors.then(t => {\n            tensorMap[nodeName] = t;\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n            this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors;\n          this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n          this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n    return promises;\n  }\n  processChildNodes(node, stack, context, tensorMap, added, usedNodes) {\n    node.children.forEach(childNode => {\n      const [nodeName] = getNodeNameAndIndex(childNode.name, context);\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      }\n      // Merge op can be pushed if any of its inputs has value.\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n          return !!getTensor(name, tensorMap, context);\n        })) {\n          added[nodeName] = true;\n          stack.push({\n            contexts: context.currentContext,\n            node: childNode\n          });\n        }\n      } else\n        // Otherwise all inputs must to have value.\n        if (childNode.inputNames.every(name => {\n          return !!getTensor(name, tensorMap, context);\n        })) {\n          added[nodeName] = true;\n          stack.push({\n            contexts: context.currentContext,\n            node: childNode\n          });\n        }\n    });\n  }\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  dispose() {\n    Object.keys(this.weightMap).forEach(key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n  checkInputShapeAndType(inputs) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n      const [nodeName] = parseNodeName(name);\n      const node = this.graph.nodes[nodeName];\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value;\n        const match = shape.length === input.shape.length && input.shape.every((dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(match, () => \"The shape of dict['\".concat(node.name, \"'] provided in \") + \"model.execute(dict) must be [\".concat(shape, \"], but was \") + \"[\".concat(input.shape, \"]\"));\n      }\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(input.dtype === node.attrParams['dtype'].value, () => \"The dtype of dict['\".concat(node.name, \"'] provided in \") + \"model.execute(dict) must be \" + \"\".concat(node.attrParams['dtype'].value, \", but was \").concat(input.dtype));\n      }\n    });\n  }\n  mapInputs(inputs) {\n    const result = {};\n    for (const inputName in inputs) {\n      if (this._signature != null && this._signature.inputs != null && this._signature.inputs[inputName] != null) {\n        const tensor = this._signature.inputs[inputName];\n        result[tensor.name] = inputs[inputName];\n      } else {\n        result[inputName] = inputs[inputName];\n      }\n    }\n    return result;\n  }\n  checkInputs(inputs) {\n    const notInGraph = Object.keys(inputs).filter(name => {\n      const [nodeName] = parseNodeName(name);\n      return this.graph.nodes[nodeName] == null;\n    });\n    if (notInGraph.length > 0) {\n      throw new Error(\"The dict provided in model.execute(dict) has \" + \"keys: [\".concat(notInGraph, \"] that are not part of graph\"));\n    }\n  }\n  mapOutputs(outputs) {\n    return outputs.map(name => {\n      if (this._signature != null && this._signature.outputs != null && this._signature.outputs[name] != null) {\n        const tensor = this._signature.outputs[name];\n        return tensor.name;\n      }\n      return name;\n    }, {});\n  }\n  checkOutputs(outputs) {\n    outputs.forEach(name => {\n      const [normalizedName] = parseNodeName(name);\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(\"The output '\".concat(name, \"' is not found in the graph\"));\n      }\n    });\n  }\n}","map":{"version":3,"names":["tidy","util","getNodeNameAndIndex","getParamValue","getTensor","getTensorsForCurrentContenxt","parseNodeName","executeOp","ExecutionContext","getExecutionSubgraph","getNodesInTopologicalOrder","isControlFlow","GraphExecutor","constructor","graph","parent","compiledMap","Map","_weightMap","SEPERATOR","_functions","_functionExecutorMap","_outputs","outputs","_inputs","inputs","_initNodes","initNodes","_signature","signature","functions","Object","keys","forEach","name","weightIds","_weightIds","functionExecutorMap","weightMap","map","key","tensor","id","concat","resourceManager","_resourceManager","node","shape","attrParams","value","undefined","dtype","inputNodes","signatureKey","outputNodes","defaultOutput","reduce","getCompilationKey","sortedInputs","sort","sortedOutputs","join","compile","executionInfo","missingInputs","dynamicNode","syncInputs","Error","op","length","outNames","n","inNames","execute","mapInputs","names","checkInputs","checkInputShapeAndType","mapOutputs","checkOutputs","nodes","outputNodeNames","compilationKey","orderedNodes","get","set","tensorArrayMap","tensorListMap","context","tensorsMap","assign","nodeName","index","tensors","tensorsToKeep","getFrozenTensorIds","intermediateTensorConsumerCount","i","isPromise","checkTensorForDisposal","dispose","tensorMap","ids","apply","Set","outputNames","category","indexOf","children","input","has","count","executeAsync","_executeAsync","isFunctionExecution","arguments","executeWithControlFlow","results","outputIds","t","inputIds","keepIds","tensorArray","isDisposed","executeFunctionAsync","mappedInputs","usedNodes","stack","weights","contexts","currentContext","added","promises","processStack","Promise","all","console","warn","missingOutputs","filter","alternativeMsg","item","pop","push","then","processChildNodes","childNode","inputNames","some","every","match","dim","assert","result","inputName","notInGraph","normalizedName"],"sources":["C:\\Users\\reddy\\Documents\\Projects\\Engagement Tracker\\engagement-tracker-react\\node_modules\\@tensorflow\\tfjs-converter\\src\\executor\\graph_executor.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NamedTensorMap, Tensor, tidy, util} from '@tensorflow/tfjs-core';\n\nimport {ISignatureDef} from '../data/compiled_api';\nimport {NamedTensorsMap, TensorArrayMap, TensorInfo, TensorListMap} from '../data/types';\nimport {getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName} from '../operations/executors/utils';\nimport {executeOp} from '../operations/operation_executor';\nimport {Graph, Node} from '../operations/types';\n\nimport {ExecutionContext, ExecutionContextInfo} from './execution_context';\nimport {getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow} from './model_analysis';\nimport {ResourceManager} from './resource_manager';\nimport {FunctionExecutor} from './types';\n\ninterface NodeWithContexts {\n  contexts: ExecutionContextInfo[];\n  node: Node;\n}\n\nexport class GraphExecutor implements FunctionExecutor {\n  private compiledMap: Map<string, Node[]> = new Map();\n  private _weightMap: NamedTensorsMap = {};\n  private _weightIds: number[];\n  private _signature: ISignatureDef;\n  private _inputs: Node[];\n  private _outputs: Node[];\n  private _initNodes: Node[];  // Internal init nodes to start initialization.\n  private SEPERATOR = ',';\n  private _functions: {[key: string]: Graph} = {};\n  private _functionExecutorMap: {[key: string]: FunctionExecutor} = {};\n  private _resourceManager: ResourceManager;\n\n  get weightIds(): number[] {\n    return this.parent ? this.parent.weightIds : this._weightIds;\n  }\n\n  get functionExecutorMap(): {[key: string]: FunctionExecutor} {\n    return this.parent ? this.parent.functionExecutorMap :\n                         this._functionExecutorMap;\n  }\n\n  get weightMap(): NamedTensorsMap {\n    return this.parent ? this.parent.weightMap : this._weightMap;\n  }\n\n  set weightMap(weightMap: NamedTensorsMap) {\n    const weightIds = Object.keys(weightMap).map(\n        key => weightMap[key].map(tensor => tensor.id));\n    this._weightIds = [].concat(...weightIds);\n    this._weightMap = weightMap;\n  }\n\n  /**\n   * Set `ResourceManager` shared by executors of a model.\n   * @param resourceManager: `ResourceManager` of the `GraphModel`.\n   */\n  set resourceManager(resourceManager: ResourceManager) {\n    this._resourceManager = resourceManager;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this._inputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get outputs(): TensorInfo[] {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get inputNodes(): string[] {\n    return this._inputs.map(node => node.signatureKey || node.name);\n  }\n\n  get outputNodes(): string[] {\n    return this._outputs.map((node) => {\n      const name = node.signatureKey || node.name;\n      return node.defaultOutput ? (`${name}:${node.defaultOutput}`) : name;\n    });\n  }\n\n  get functions(): {[key: string]: ISignatureDef} {\n    return Object.keys(this._functions).reduce((map, key) => {\n      map[key] = this._functions[key].signature;\n      return map;\n    }, {} as {[key: string]: ISignatureDef});\n  }\n\n  /**\n   *\n   * @param graph Graph the model or function graph to be executed.\n   * @param parent When building function exector you need to set the parent\n   * executor. Since the weights and function executor maps are set at parant\n   * level, that function executor can access the function maps and weight maps\n   * through the parent.\n   */\n  constructor(private graph: Graph, private parent?: GraphExecutor) {\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._initNodes = graph.initNodes;\n    this._signature = graph.signature;\n    this._functions = graph.functions;\n    // create sub-graph executors\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(name => {\n        this._functionExecutorMap[name] =\n            new GraphExecutor(graph.functions[name], this);\n      });\n    }\n  }\n\n  private getCompilationKey(inputs: Node[], outputs: Node[]): string {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPERATOR) + '--' +\n        sortedOutputs.join(this.SEPERATOR);\n  }\n\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   */\n  private compile(inputs: NamedTensorMap, outputs: Node[]): Node[] {\n    const executionInfo =\n        getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n    const {missingInputs, dynamicNode, syncInputs} = executionInfo;\n    if (dynamicNode != null) {\n      throw new Error(\n          `This execution contains the node '${dynamicNode.name}', which has ` +\n          `the dynamic op '${dynamicNode.op}'. Please use ` +\n          `model.executeAsync() instead. Alternatively, to avoid the ` +\n          `dynamic ops, specify the inputs [${syncInputs}]`);\n    }\n\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(\n          `Cannot compute the outputs [${outNames}] from the provided inputs ` +\n          `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n    }\n\n    return getNodesInTopologicalOrder(\n        this.graph, this.weightMap, executionInfo);\n  }\n\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model, if\n   * no outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   */\n  execute(inputs: NamedTensorMap, outputs?: string[]): Tensor[] {\n    inputs = this.mapInputs(inputs);\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n\n    // Do nothing if the compiled graph cache contains the input.\n    let orderedNodes = this.compiledMap.get(compilationKey);\n    if (orderedNodes == null) {\n      orderedNodes = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, orderedNodes);\n    }\n\n    const tensorArrayMap: TensorArrayMap = {};\n    const tensorListMap: TensorListMap = {};\n\n    return tidy(() => {\n      const context = new ExecutionContext(\n          this.weightMap, tensorArrayMap, tensorListMap,\n          this.functionExecutorMap);\n      const tensorsMap: NamedTensorsMap = {...this.weightMap};\n\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name);\n        const tensors: Tensor[] = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n      });\n\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const intermediateTensorConsumerCount: {[key: number]: number} = {};\n      for (let i = 0; i < orderedNodes.length; i++) {\n        const node = orderedNodes[i];\n        if (!tensorsMap[node.name]) {\n          const tensors =\n              executeOp(node, tensorsMap, context, this._resourceManager) as\n              Tensor[];\n          if (util.isPromise(tensors)) {\n            throw new Error(\n                `The execution of the op '${node.op}' returned a promise. ` +\n                `Please use model.executeAsync() instead.`);\n          }\n          tensorsMap[node.name] = tensors;\n          this.checkTensorForDisposal(\n              node.name, node, tensorsMap, context, tensorsToKeep,\n              outputNodeNames, intermediateTensorConsumerCount);\n        }\n      }\n      // dispose the context for the root executor\n      if (this.parent == null) {\n        context.dispose(tensorsToKeep);\n      }\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n\n  private getFrozenTensorIds(tensorMap: NamedTensorsMap): Set<number> {\n    const ids = [].concat.apply(\n        [],\n        Object.keys(tensorMap)\n            .map(key => tensorMap[key])\n            .map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n  private checkTensorForDisposal(\n      nodeName: string, node: Node, tensorMap: NamedTensorsMap,\n      context: ExecutionContext, tensorsToKeep: Set<number>,\n      outputNames: string[],\n      intermediateTensorConsumerCount: {[key: string]: number}) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n      return;\n    }\n\n    tensorMap[nodeName].forEach(tensor => {\n      if (tensor != null) {\n        intermediateTensorConsumerCount[tensor.id] =\n            (intermediateTensorConsumerCount[tensor.id] || 0) +\n            node.children.length;\n      }\n    });\n    node.inputs.forEach(input => {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (input.category !== 'control') {\n        const tensors =\n            getTensorsForCurrentContenxt(input.name, tensorMap, context);\n        if (tensors != null) {\n          tensors.forEach(tensor => {\n            if (tensor && !tensorsToKeep.has(tensor.id)) {\n              const count = intermediateTensorConsumerCount[tensor.id];\n              if (count === 1) {\n                tensor.dispose();\n                delete intermediateTensorConsumerCount[tensor.id];\n              } else if (count != null) {\n                // only intermediate nodes has count set, inputs and weights are\n                // not.\n                intermediateTensorConsumerCount[tensor.id]--;\n              }\n            }\n          });\n        }\n      }\n    });\n  }\n\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  async executeAsync(inputs: NamedTensorMap, outputs?: string[]):\n      Promise<Tensor[]> {\n    return this._executeAsync(inputs, outputs);\n  }\n\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Optional. Flag for executing a function.\n   * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n   * function execution.\n   * @param tensorArrayMap Optinal global TensorList map by id. Used for\n   * function execution.\n   */\n  private async _executeAsync(\n      inputs: NamedTensorMap, outputs?: string[], isFunctionExecution = false,\n      tensorArrayMap: TensorArrayMap = {},\n      tensorListMap: TensorListMap = {}): Promise<Tensor[]> {\n    if (!isFunctionExecution) {\n      inputs = this.mapInputs(inputs);\n      this.checkInputs(inputs);\n      this.checkInputShapeAndType(inputs);\n      outputs = this.mapOutputs(outputs);\n      this.checkOutputs(outputs);\n    }\n\n    const context = new ExecutionContext(\n        this.weightMap, tensorArrayMap, tensorListMap,\n        this.functionExecutorMap);\n\n    // Graph with control flow op requires runtime evaluation of the execution\n    // order, while without control flow the execution order is pre-determined\n    // in the compile method.\n    const tensorMap = await this.executeWithControlFlow(\n        inputs, context, outputs, isFunctionExecution);\n    const results = outputs.map(name => getTensor(name, tensorMap, context));\n\n    // dispose all the intermediate tensors\n    const outputIds = results.map(t => t.id);\n    const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n    const keepIds =\n        new Set<number>([...outputIds, ...inputIds, ...this.weightIds]);\n    Object.keys(tensorMap).forEach(key => {\n      const tensorArray = tensorMap[key];\n      tensorArray.forEach(tensor => {\n        if (tensor && !tensor.isDisposed && !keepIds.has(tensor.id)) {\n          tensor.dispose();\n        }\n      });\n    });\n    // dispose the context for the root executor\n    if (this.parent == null) {\n      context.dispose(keepIds);\n    }\n\n    return results;\n  }\n\n  async executeFunctionAsync(\n      inputs: Tensor[], tensorArrayMap: TensorArrayMap,\n      tensorListMap: TensorListMap): Promise<Tensor[]> {\n    const mappedInputs = inputs.reduce((map, tensor, index) => {\n      map[this.inputs[index].name] = tensor;\n      return map;\n    }, {} as NamedTensorMap);\n\n    return this._executeAsync(\n        mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n  }\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   * @param outputNames Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Flag for executing a function.\n   */\n  private async executeWithControlFlow(\n      inputs: NamedTensorMap, context: ExecutionContext, outputNames?: string[],\n      isFunctionExecution?: boolean): Promise<NamedTensorsMap> {\n    const names = Object.keys(inputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n\n    const {usedNodes, missingInputs, dynamicNode, syncInputs} =\n        getExecutionSubgraph(\n            inputs, outputNodes, this.weightMap, this._initNodes);\n\n    // First nodes to execute include inputNodes, weights, and initNodes.\n    const stack: NodeWithContexts[] = [\n      ...inputNodes, ...this.graph.weights, ...(this._initNodes || [])\n    ].map(node => {\n      return {node, contexts: context.currentContext};\n    });\n    const tensorsMap: NamedTensorsMap = {...this.weightMap};\n    Object.keys(inputs).forEach(name => {\n      const [nodeName, index] = parseNodeName(name);\n      const tensors: Tensor[] = [];\n      tensors[index] = inputs[name];\n      tensorsMap[nodeName] = tensors;\n    });\n    const intermediateTensorConsumerCount: {[key: number]: number} = {};\n    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n    const added: {[key: string]: boolean} = {};\n    while (stack.length > 0) {\n      const promises = this.processStack(\n          inputNodes, stack, context, tensorsMap, added, tensorsToKeep,\n          outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n      await Promise.all(promises);\n    }\n    if (dynamicNode == null && !isFunctionExecution) {\n      console.warn(\n          `This model execution did not contain any nodes with control flow ` +\n          `or dynamic output shapes. You can use model.execute() instead.`);\n    }\n    const missingOutputs =\n        outputNodes\n            .filter(\n                node => !isControlFlow(node) &&\n                    !getTensor(node.name, tensorsMap, context))\n            .map(node => node.name);\n    if (missingOutputs.length > 0) {\n      let alternativeMsg = '';\n      if (dynamicNode != null) {\n        alternativeMsg =\n            `Alternatively, to avoid the dynamic ops, use model.execute() ` +\n            `and specify the inputs [${syncInputs}]`;\n      }\n      throw new Error(\n          `Cannot compute the outputs [${missingOutputs}] from the provided ` +\n          `inputs [${names}]. Consider providing the following inputs: ` +\n          `[${missingInputs}]. ${alternativeMsg}`);\n    }\n    return tensorsMap;\n  }\n\n  private processStack(\n      inputNodes: Node[], stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      tensorsToKeep: Set<number>, outputNames: string[],\n      intermediateTensorConsumerCount: {[key: number]: number},\n      usedNodes: Set<string>) {\n    const promises: Array<Promise<Tensor[]>> = [];\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = '';\n      // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n      if (item.node.op === 'Enter' &&\n          getParamValue('isConstant', item.node, tensorMap, context)) {\n        [nodeName] = getNodeNameAndIndex(item.node.name, context);\n      }\n\n      // only process nodes that are not in the tensorMap yet, this include\n      // inputNodes and internal initNodes.\n      if (tensorMap[item.node.name] == null) {\n        const tensors =\n            executeOp(item.node, tensorMap, context, this._resourceManager);\n        if (!nodeName) {\n          [nodeName] = getNodeNameAndIndex(item.node.name, context);\n        }\n        const currentContext = context.currentContext;\n        if (util.isPromise(tensors)) {\n          promises.push((tensors as Promise<Tensor[]>).then(t => {\n            tensorMap[nodeName] = t;\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(\n                nodeName, item.node, tensorMap, context, tensorsToKeep,\n                outputNames, intermediateTensorConsumerCount);\n            this.processChildNodes(\n                item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors as Tensor[];\n          this.checkTensorForDisposal(\n              nodeName, item.node, tensorMap, context, tensorsToKeep,\n              outputNames, intermediateTensorConsumerCount);\n          this.processChildNodes(\n              item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(\n            item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n    return promises;\n  }\n\n  private processChildNodes(\n      node: Node, stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      usedNodes: Set<string>) {\n    node.children.forEach((childNode) => {\n      const [nodeName, ] = getNodeNameAndIndex(childNode.name, context);\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      }\n      // Merge op can be pushed if any of its inputs has value.\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n              return !!getTensor(name, tensorMap, context);\n            })) {\n          added[nodeName] = true;\n          stack.push({contexts: context.currentContext, node: childNode});\n        }\n      } else  // Otherwise all inputs must to have value.\n          if (childNode.inputNames.every(name => {\n                return !!getTensor(name, tensorMap, context);\n              })) {\n        added[nodeName] = true;\n        stack.push({contexts: context.currentContext, node: childNode});\n      }\n    });\n  }\n\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  dispose() {\n    Object.keys(this.weightMap)\n        .forEach(\n            key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n\n  private checkInputShapeAndType(inputs: NamedTensorMap) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n      const [nodeName, ] = parseNodeName(name);\n      const node = this.graph.nodes[nodeName];\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value as number[];\n        const match = shape.length === input.shape.length &&\n            input.shape.every(\n                (dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(\n            match,\n            () => `The shape of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be [${shape}], but was ` +\n                `[${input.shape}]`);\n      }\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(\n            input.dtype === node.attrParams['dtype'].value as string,\n            () => `The dtype of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be ` +\n                `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n      }\n    });\n  }\n\n  private mapInputs(inputs: NamedTensorMap) {\n    const result: NamedTensorMap = {};\n    for (const inputName in inputs) {\n      if (this._signature != null && this._signature.inputs != null &&\n          this._signature.inputs[inputName] != null) {\n        const tensor = this._signature.inputs[inputName];\n        result[tensor.name] = inputs[inputName];\n      } else {\n        result[inputName] = inputs[inputName];\n      }\n    }\n    return result;\n  }\n\n  private checkInputs(inputs: NamedTensorMap) {\n    const notInGraph = Object.keys(inputs).filter(name => {\n      const [nodeName] = parseNodeName(name);\n      return this.graph.nodes[nodeName] == null;\n    });\n    if (notInGraph.length > 0) {\n      throw new Error(\n          `The dict provided in model.execute(dict) has ` +\n          `keys: [${notInGraph}] that are not part of graph`);\n    }\n  }\n\n  private mapOutputs(outputs: string[]) {\n    return outputs.map(name => {\n      if (this._signature != null && this._signature.outputs != null &&\n          this._signature.outputs[name] != null) {\n        const tensor = this._signature.outputs[name];\n        return tensor.name;\n      }\n      return name;\n    }, {});\n  }\n\n  private checkOutputs(outputs: string[]): void {\n    outputs.forEach(name => {\n      const [normalizedName] = parseNodeName(name);\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(`The output '${name}' is not found in the graph`);\n      }\n    });\n  }\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAA0CA,IAAI,EAAEC,IAAI,QAAO,uBAAuB;AAIlF,SAAQC,mBAAmB,EAAEC,aAAa,EAAEC,SAAS,EAAEC,4BAA4B,EAAEC,aAAa,QAAO,+BAA+B;AACxI,SAAQC,SAAS,QAAO,kCAAkC;AAG1D,SAAQC,gBAAgB,QAA6B,qBAAqB;AAC1E,SAAQC,oBAAoB,EAAEC,0BAA0B,EAAEC,aAAa,QAAO,kBAAkB;AAShG,OAAM,MAAOC,aAAa;EAuFxB;;;;;;;;EAQAC,YAAoBC,KAAY,EAAUC,MAAsB;IAA5C,KAAAD,KAAK,GAALA,KAAK;IAAiB,KAAAC,MAAM,GAANA,MAAM;IA9FxC,KAAAC,WAAW,GAAwB,IAAIC,GAAG,EAAE;IAC5C,KAAAC,UAAU,GAAoB,EAAE;IAMhC,KAAAC,SAAS,GAAG,GAAG;IACf,KAAAC,UAAU,GAA2B,EAAE;IACvC,KAAAC,oBAAoB,GAAsC,EAAE;IAsFlE,IAAI,CAACC,QAAQ,GAAGR,KAAK,CAACS,OAAO;IAC7B,IAAI,CAACC,OAAO,GAAGV,KAAK,CAACW,MAAM;IAC3B,IAAI,CAACC,UAAU,GAAGZ,KAAK,CAACa,SAAS;IACjC,IAAI,CAACC,UAAU,GAAGd,KAAK,CAACe,SAAS;IACjC,IAAI,CAACT,UAAU,GAAGN,KAAK,CAACgB,SAAS;IACjC;IACA,IAAIhB,KAAK,CAACgB,SAAS,IAAI,IAAI,EAAE;MAC3BC,MAAM,CAACC,IAAI,CAAClB,KAAK,CAACgB,SAAS,CAAC,CAACG,OAAO,CAACC,IAAI,IAAG;QAC1C,IAAI,CAACb,oBAAoB,CAACa,IAAI,CAAC,GAC3B,IAAItB,aAAa,CAACE,KAAK,CAACgB,SAAS,CAACI,IAAI,CAAC,EAAE,IAAI,CAAC;MACpD,CAAC,CAAC;;EAEN;EA/FA,IAAIC,SAASA,CAAA;IACX,OAAO,IAAI,CAACpB,MAAM,GAAG,IAAI,CAACA,MAAM,CAACoB,SAAS,GAAG,IAAI,CAACC,UAAU;EAC9D;EAEA,IAAIC,mBAAmBA,CAAA;IACrB,OAAO,IAAI,CAACtB,MAAM,GAAG,IAAI,CAACA,MAAM,CAACsB,mBAAmB,GAC/B,IAAI,CAAChB,oBAAoB;EAChD;EAEA,IAAIiB,SAASA,CAAA;IACX,OAAO,IAAI,CAACvB,MAAM,GAAG,IAAI,CAACA,MAAM,CAACuB,SAAS,GAAG,IAAI,CAACpB,UAAU;EAC9D;EAEA,IAAIoB,SAASA,CAACA,SAA0B;IACtC,MAAMH,SAAS,GAAGJ,MAAM,CAACC,IAAI,CAACM,SAAS,CAAC,CAACC,GAAG,CACxCC,GAAG,IAAIF,SAAS,CAACE,GAAG,CAAC,CAACD,GAAG,CAACE,MAAM,IAAIA,MAAM,CAACC,EAAE,CAAC,CAAC;IACnD,IAAI,CAACN,UAAU,GAAG,EAAE,CAACO,MAAM,CAAC,GAAGR,SAAS,CAAC;IACzC,IAAI,CAACjB,UAAU,GAAGoB,SAAS;EAC7B;EAEA;;;;EAIA,IAAIM,eAAeA,CAACA,eAAgC;IAClD,IAAI,CAACC,gBAAgB,GAAGD,eAAe;EACzC;EAEA,IAAInB,MAAMA,CAAA;IACR,OAAO,IAAI,CAACD,OAAO,CAACe,GAAG,CAACO,IAAI,IAAG;MAC7B,OAAO;QACLZ,IAAI,EAAEY,IAAI,CAACZ,IAAI;QACfa,KAAK,EAAED,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,GAC3BF,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,CAACC,KAAiB,GAC1CC,SAAS;QACbC,KAAK,EAAEL,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,GAC3BF,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,CAACC,KAAiB,GAC1CC;OACL;IACH,CAAC,CAAC;EACJ;EAEA,IAAI3B,OAAOA,CAAA;IACT,OAAO,IAAI,CAACD,QAAQ,CAACiB,GAAG,CAACO,IAAI,IAAG;MAC9B,OAAO;QACLZ,IAAI,EAAEY,IAAI,CAACZ,IAAI;QACfa,KAAK,EAAED,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,GAC3BF,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,CAACC,KAAiB,GAC1CC,SAAS;QACbC,KAAK,EAAEL,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,GAC3BF,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,CAACC,KAAiB,GAC1CC;OACL;IACH,CAAC,CAAC;EACJ;EAEA,IAAIE,UAAUA,CAAA;IACZ,OAAO,IAAI,CAAC5B,OAAO,CAACe,GAAG,CAACO,IAAI,IAAIA,IAAI,CAACO,YAAY,IAAIP,IAAI,CAACZ,IAAI,CAAC;EACjE;EAEA,IAAIoB,WAAWA,CAAA;IACb,OAAO,IAAI,CAAChC,QAAQ,CAACiB,GAAG,CAAEO,IAAI,IAAI;MAChC,MAAMZ,IAAI,GAAGY,IAAI,CAACO,YAAY,IAAIP,IAAI,CAACZ,IAAI;MAC3C,OAAOY,IAAI,CAACS,aAAa,MAAAZ,MAAA,CAAOT,IAAI,OAAAS,MAAA,CAAIG,IAAI,CAACS,aAAa,IAAMrB,IAAI;IACtE,CAAC,CAAC;EACJ;EAEA,IAAIJ,SAASA,CAAA;IACX,OAAOC,MAAM,CAACC,IAAI,CAAC,IAAI,CAACZ,UAAU,CAAC,CAACoC,MAAM,CAAC,CAACjB,GAAG,EAAEC,GAAG,KAAI;MACtDD,GAAG,CAACC,GAAG,CAAC,GAAG,IAAI,CAACpB,UAAU,CAACoB,GAAG,CAAC,CAACX,SAAS;MACzC,OAAOU,GAAG;IACZ,CAAC,EAAE,EAAoC,CAAC;EAC1C;EAyBQkB,iBAAiBA,CAAChC,MAAc,EAAEF,OAAe;IACvD,MAAMmC,YAAY,GAAGjC,MAAM,CAACc,GAAG,CAACO,IAAI,IAAIA,IAAI,CAACZ,IAAI,CAAC,CAACyB,IAAI,EAAE;IACzD,MAAMC,aAAa,GAAGrC,OAAO,CAACgB,GAAG,CAACO,IAAI,IAAIA,IAAI,CAACZ,IAAI,CAAC,CAACyB,IAAI,EAAE;IAC3D,OAAOD,YAAY,CAACG,IAAI,CAAC,IAAI,CAAC1C,SAAS,CAAC,GAAG,IAAI,GAC3CyC,aAAa,CAACC,IAAI,CAAC,IAAI,CAAC1C,SAAS,CAAC;EACxC;EAEA;;;;EAIQ2C,OAAOA,CAACrC,MAAsB,EAAEF,OAAe;IACrD,MAAMwC,aAAa,GACftD,oBAAoB,CAACgB,MAAM,EAAEF,OAAO,EAAE,IAAI,CAACe,SAAS,EAAE,IAAI,CAACZ,UAAU,CAAC;IAC1E,MAAM;MAACsC,aAAa;MAAEC,WAAW;MAAEC;IAAU,CAAC,GAAGH,aAAa;IAC9D,IAAIE,WAAW,IAAI,IAAI,EAAE;MACvB,MAAM,IAAIE,KAAK,CACX,qCAAAxB,MAAA,CAAqCsB,WAAW,CAAC/B,IAAI,wCAAAS,MAAA,CAClCsB,WAAW,CAACG,EAAE,mBAAgB,+DACW,uCAAAzB,MAAA,CACxBuB,UAAU,MAAG,CAAC;;IAGxD,IAAIF,aAAa,CAACK,MAAM,GAAG,CAAC,EAAE;MAC5B,MAAMC,QAAQ,GAAG/C,OAAO,CAACgB,GAAG,CAACgC,CAAC,IAAIA,CAAC,CAACrC,IAAI,CAAC;MACzC,MAAMsC,OAAO,GAAGzC,MAAM,CAACC,IAAI,CAACP,MAAM,CAAC;MACnC,MAAM,IAAI0C,KAAK,CACX,+BAAAxB,MAAA,CAA+B2B,QAAQ,uCAAA3B,MAAA,CACnC6B,OAAO,wCAAA7B,MAAA,CAAqCqB,aAAa,MAAG,CAAC;;IAGvE,OAAOtD,0BAA0B,CAC7B,IAAI,CAACI,KAAK,EAAE,IAAI,CAACwB,SAAS,EAAEyB,aAAa,CAAC;EAChD;EAEA;;;;;;;;;EASAU,OAAOA,CAAChD,MAAsB,EAAEF,OAAkB;IAChDE,MAAM,GAAG,IAAI,CAACiD,SAAS,CAACjD,MAAM,CAAC;IAC/B,MAAMkD,KAAK,GAAG5C,MAAM,CAACC,IAAI,CAACP,MAAM,CAAC,CAACkC,IAAI,EAAE;IACxC,IAAI,CAACiB,WAAW,CAACnD,MAAM,CAAC;IACxB,IAAI,CAACoD,sBAAsB,CAACpD,MAAM,CAAC;IACnCF,OAAO,GAAG,IAAI,CAACuD,UAAU,CAACvD,OAAO,CAAC;IAClC,IAAI,CAACwD,YAAY,CAACxD,OAAO,CAAC;IAC1B,MAAM6B,UAAU,GACZuB,KAAK,CAACpC,GAAG,CAACL,IAAI,IAAI,IAAI,CAACpB,KAAK,CAACkE,KAAK,CAAC1E,aAAa,CAAC4B,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAC/D,MAAM+C,eAAe,GAAG1D,OAAO,CAACgB,GAAG,CAACL,IAAI,IAAI5B,aAAa,CAAC4B,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;IACnE,IAAIoB,WAAW,GAAG2B,eAAe,CAAC1C,GAAG,CAACL,IAAI,IAAI,IAAI,CAACpB,KAAK,CAACkE,KAAK,CAAC9C,IAAI,CAAC,CAAC;IAErE;IACA,IAAIoB,WAAW,CAACe,MAAM,KAAK,CAAC,EAAE;MAC5Bf,WAAW,GAAG,IAAI,CAAChC,QAAQ;;IAG7B,MAAM4D,cAAc,GAAG,IAAI,CAACzB,iBAAiB,CAACL,UAAU,EAAEE,WAAW,CAAC;IAEtE;IACA,IAAI6B,YAAY,GAAG,IAAI,CAACnE,WAAW,CAACoE,GAAG,CAACF,cAAc,CAAC;IACvD,IAAIC,YAAY,IAAI,IAAI,EAAE;MACxBA,YAAY,GAAG,IAAI,CAACrB,OAAO,CAACrC,MAAM,EAAE6B,WAAW,CAAC;MAChD,IAAI,CAACtC,WAAW,CAACqE,GAAG,CAACH,cAAc,EAAEC,YAAY,CAAC;;IAGpD,MAAMG,cAAc,GAAmB,EAAE;IACzC,MAAMC,aAAa,GAAkB,EAAE;IAEvC,OAAOvF,IAAI,CAAC,MAAK;MACf,MAAMwF,OAAO,GAAG,IAAIhF,gBAAgB,CAChC,IAAI,CAAC8B,SAAS,EAAEgD,cAAc,EAAEC,aAAa,EAC7C,IAAI,CAAClD,mBAAmB,CAAC;MAC7B,MAAMoD,UAAU,GAAA1D,MAAA,CAAA2D,MAAA,KAAwB,IAAI,CAACpD,SAAS,CAAC;MAEvDP,MAAM,CAACC,IAAI,CAACP,MAAM,CAAC,CAACQ,OAAO,CAACC,IAAI,IAAG;QACjC,MAAM,CAACyD,QAAQ,EAAEC,KAAK,CAAC,GAAGtF,aAAa,CAAC4B,IAAI,CAAC;QAC7C,MAAM2D,OAAO,GAAa,EAAE;QAC5BA,OAAO,CAACD,KAAK,CAAC,GAAGnE,MAAM,CAACS,IAAI,CAAC;QAC7BuD,UAAU,CAACE,QAAQ,CAAC,GAAGE,OAAO;MAChC,CAAC,CAAC;MAEF,MAAMC,aAAa,GAAG,IAAI,CAACC,kBAAkB,CAACN,UAAU,CAAC;MACzD,MAAMO,+BAA+B,GAA4B,EAAE;MACnE,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGd,YAAY,CAACd,MAAM,EAAE4B,CAAC,EAAE,EAAE;QAC5C,MAAMnD,IAAI,GAAGqC,YAAY,CAACc,CAAC,CAAC;QAC5B,IAAI,CAACR,UAAU,CAAC3C,IAAI,CAACZ,IAAI,CAAC,EAAE;UAC1B,MAAM2D,OAAO,GACTtF,SAAS,CAACuC,IAAI,EAAE2C,UAAU,EAAED,OAAO,EAAE,IAAI,CAAC3C,gBAAgB,CAClD;UACZ,IAAI5C,IAAI,CAACiG,SAAS,CAACL,OAAO,CAAC,EAAE;YAC3B,MAAM,IAAI1B,KAAK,CACX,4BAAAxB,MAAA,CAA4BG,IAAI,CAACsB,EAAE,wEACO,CAAC;;UAEjDqB,UAAU,CAAC3C,IAAI,CAACZ,IAAI,CAAC,GAAG2D,OAAO;UAC/B,IAAI,CAACM,sBAAsB,CACvBrD,IAAI,CAACZ,IAAI,EAAEY,IAAI,EAAE2C,UAAU,EAAED,OAAO,EAAEM,aAAa,EACnDb,eAAe,EAAEe,+BAA+B,CAAC;;;MAGzD;MACA,IAAI,IAAI,CAACjF,MAAM,IAAI,IAAI,EAAE;QACvByE,OAAO,CAACY,OAAO,CAACN,aAAa,CAAC;;MAEhC,OAAOvE,OAAO,CAACgB,GAAG,CAACL,IAAI,IAAI9B,SAAS,CAAC8B,IAAI,EAAEuD,UAAU,EAAED,OAAO,CAAC,CAAC;IAClE,CAAC,CAAC;EACJ;EAEQO,kBAAkBA,CAACM,SAA0B;IACnD,MAAMC,GAAG,GAAG,EAAE,CAAC3D,MAAM,CAAC4D,KAAK,CACvB,EAAE,EACFxE,MAAM,CAACC,IAAI,CAACqE,SAAS,CAAC,CACjB9D,GAAG,CAACC,GAAG,IAAI6D,SAAS,CAAC7D,GAAG,CAAC,CAAC,CAC1BD,GAAG,CAACsD,OAAO,IAAIA,OAAO,CAACtD,GAAG,CAACE,MAAM,IAAIA,MAAM,CAACC,EAAE,CAAC,CAAC,CAAC;IAC1D,OAAO,IAAI8D,GAAG,CAACF,GAAG,CAAC;EACrB;EACQH,sBAAsBA,CAC1BR,QAAgB,EAAE7C,IAAU,EAAEuD,SAA0B,EACxDb,OAAyB,EAAEM,aAA0B,EACrDW,WAAqB,EACrBT,+BAAwD;IAC1D;IACA;IACA,IAAIlD,IAAI,CAAC4D,QAAQ,KAAK,SAAS,IAAID,WAAW,CAACE,OAAO,CAAChB,QAAQ,CAAC,KAAK,CAAC,CAAC,EAAE;MACvE;;IAGFU,SAAS,CAACV,QAAQ,CAAC,CAAC1D,OAAO,CAACQ,MAAM,IAAG;MACnC,IAAIA,MAAM,IAAI,IAAI,EAAE;QAClBuD,+BAA+B,CAACvD,MAAM,CAACC,EAAE,CAAC,GACtC,CAACsD,+BAA+B,CAACvD,MAAM,CAACC,EAAE,CAAC,IAAI,CAAC,IAChDI,IAAI,CAAC8D,QAAQ,CAACvC,MAAM;;IAE5B,CAAC,CAAC;IACFvB,IAAI,CAACrB,MAAM,CAACQ,OAAO,CAAC4E,KAAK,IAAG;MAC1B;MACA;MACA,IAAIA,KAAK,CAACH,QAAQ,KAAK,SAAS,EAAE;QAChC,MAAMb,OAAO,GACTxF,4BAA4B,CAACwG,KAAK,CAAC3E,IAAI,EAAEmE,SAAS,EAAEb,OAAO,CAAC;QAChE,IAAIK,OAAO,IAAI,IAAI,EAAE;UACnBA,OAAO,CAAC5D,OAAO,CAACQ,MAAM,IAAG;YACvB,IAAIA,MAAM,IAAI,CAACqD,aAAa,CAACgB,GAAG,CAACrE,MAAM,CAACC,EAAE,CAAC,EAAE;cAC3C,MAAMqE,KAAK,GAAGf,+BAA+B,CAACvD,MAAM,CAACC,EAAE,CAAC;cACxD,IAAIqE,KAAK,KAAK,CAAC,EAAE;gBACftE,MAAM,CAAC2D,OAAO,EAAE;gBAChB,OAAOJ,+BAA+B,CAACvD,MAAM,CAACC,EAAE,CAAC;eAClD,MAAM,IAAIqE,KAAK,IAAI,IAAI,EAAE;gBACxB;gBACA;gBACAf,+BAA+B,CAACvD,MAAM,CAACC,EAAE,CAAC,EAAE;;;UAGlD,CAAC,CAAC;;;IAGR,CAAC,CAAC;EACJ;EAEA;;;;;;;;;EASA,MAAMsE,YAAYA,CAACvF,MAAsB,EAAEF,OAAkB;IAE3D,OAAO,IAAI,CAAC0F,aAAa,CAACxF,MAAM,EAAEF,OAAO,CAAC;EAC5C;EAEA;;;;;;;;;;;;;;EAcQ,MAAM0F,aAAaA,CACvBxF,MAAsB,EAAEF,OAAkB,EAET;IAAA,IAFW2F,mBAAmB,GAAAC,SAAA,CAAA9C,MAAA,QAAA8C,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAG,KAAK;IAAA,IACvE7B,cAAA,GAAA6B,SAAA,CAAA9C,MAAA,QAAA8C,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAAiC,EAAE;IAAA,IACnC5B,aAAA,GAAA4B,SAAA,CAAA9C,MAAA,QAAA8C,SAAA,QAAAjE,SAAA,GAAAiE,SAAA,MAA+B,EAAE;IACnC,IAAI,CAACD,mBAAmB,EAAE;MACxBzF,MAAM,GAAG,IAAI,CAACiD,SAAS,CAACjD,MAAM,CAAC;MAC/B,IAAI,CAACmD,WAAW,CAACnD,MAAM,CAAC;MACxB,IAAI,CAACoD,sBAAsB,CAACpD,MAAM,CAAC;MACnCF,OAAO,GAAG,IAAI,CAACuD,UAAU,CAACvD,OAAO,CAAC;MAClC,IAAI,CAACwD,YAAY,CAACxD,OAAO,CAAC;;IAG5B,MAAMiE,OAAO,GAAG,IAAIhF,gBAAgB,CAChC,IAAI,CAAC8B,SAAS,EAAEgD,cAAc,EAAEC,aAAa,EAC7C,IAAI,CAAClD,mBAAmB,CAAC;IAE7B;IACA;IACA;IACA,MAAMgE,SAAS,GAAG,MAAM,IAAI,CAACe,sBAAsB,CAC/C3F,MAAM,EAAE+D,OAAO,EAAEjE,OAAO,EAAE2F,mBAAmB,CAAC;IAClD,MAAMG,OAAO,GAAG9F,OAAO,CAACgB,GAAG,CAACL,IAAI,IAAI9B,SAAS,CAAC8B,IAAI,EAAEmE,SAAS,EAAEb,OAAO,CAAC,CAAC;IAExE;IACA,MAAM8B,SAAS,GAAGD,OAAO,CAAC9E,GAAG,CAACgF,CAAC,IAAIA,CAAC,CAAC7E,EAAE,CAAC;IACxC,MAAM8E,QAAQ,GAAGzF,MAAM,CAACC,IAAI,CAACP,MAAM,CAAC,CAACc,GAAG,CAACL,IAAI,IAAIT,MAAM,CAACS,IAAI,CAAC,CAACQ,EAAE,CAAC;IACjE,MAAM+E,OAAO,GACT,IAAIjB,GAAG,CAAS,CAAC,GAAGc,SAAS,EAAE,GAAGE,QAAQ,EAAE,GAAG,IAAI,CAACrF,SAAS,CAAC,CAAC;IACnEJ,MAAM,CAACC,IAAI,CAACqE,SAAS,CAAC,CAACpE,OAAO,CAACO,GAAG,IAAG;MACnC,MAAMkF,WAAW,GAAGrB,SAAS,CAAC7D,GAAG,CAAC;MAClCkF,WAAW,CAACzF,OAAO,CAACQ,MAAM,IAAG;QAC3B,IAAIA,MAAM,IAAI,CAACA,MAAM,CAACkF,UAAU,IAAI,CAACF,OAAO,CAACX,GAAG,CAACrE,MAAM,CAACC,EAAE,CAAC,EAAE;UAC3DD,MAAM,CAAC2D,OAAO,EAAE;;MAEpB,CAAC,CAAC;IACJ,CAAC,CAAC;IACF;IACA,IAAI,IAAI,CAACrF,MAAM,IAAI,IAAI,EAAE;MACvByE,OAAO,CAACY,OAAO,CAACqB,OAAO,CAAC;;IAG1B,OAAOJ,OAAO;EAChB;EAEA,MAAMO,oBAAoBA,CACtBnG,MAAgB,EAAE6D,cAA8B,EAChDC,aAA4B;IAC9B,MAAMsC,YAAY,GAAGpG,MAAM,CAAC+B,MAAM,CAAC,CAACjB,GAAG,EAAEE,MAAM,EAAEmD,KAAK,KAAI;MACxDrD,GAAG,CAAC,IAAI,CAACd,MAAM,CAACmE,KAAK,CAAC,CAAC1D,IAAI,CAAC,GAAGO,MAAM;MACrC,OAAOF,GAAG;IACZ,CAAC,EAAE,EAAoB,CAAC;IAExB,OAAO,IAAI,CAAC0E,aAAa,CACrBY,YAAY,EAAE,IAAI,CAACvE,WAAW,EAAE,IAAI,EAAEgC,cAAc,EAAEC,aAAa,CAAC;EAC1E;EACA;;;;;;;;;;;EAWQ,MAAM6B,sBAAsBA,CAChC3F,MAAsB,EAAE+D,OAAyB,EAAEiB,WAAsB,EACzES,mBAA6B;IAC/B,MAAMvC,KAAK,GAAG5C,MAAM,CAACC,IAAI,CAACP,MAAM,CAAC;IACjC,MAAM2B,UAAU,GACZuB,KAAK,CAACpC,GAAG,CAACL,IAAI,IAAI,IAAI,CAACpB,KAAK,CAACkE,KAAK,CAAC1E,aAAa,CAAC4B,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAC/D,MAAM+C,eAAe,GAAGwB,WAAW,CAAClE,GAAG,CAACL,IAAI,IAAI5B,aAAa,CAAC4B,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;IACvE,IAAIoB,WAAW,GAAG2B,eAAe,CAAC1C,GAAG,CAACL,IAAI,IAAI,IAAI,CAACpB,KAAK,CAACkE,KAAK,CAAC9C,IAAI,CAAC,CAAC;IAErE;IACA,IAAIoB,WAAW,CAACe,MAAM,KAAK,CAAC,EAAE;MAC5Bf,WAAW,GAAG,IAAI,CAAChC,QAAQ;;IAG7B,MAAM;MAACwG,SAAS;MAAE9D,aAAa;MAAEC,WAAW;MAAEC;IAAU,CAAC,GACrDzD,oBAAoB,CAChBgB,MAAM,EAAE6B,WAAW,EAAE,IAAI,CAAChB,SAAS,EAAE,IAAI,CAACZ,UAAU,CAAC;IAE7D;IACA,MAAMqG,KAAK,GAAuB,CAChC,GAAG3E,UAAU,EAAE,GAAG,IAAI,CAACtC,KAAK,CAACkH,OAAO,EAAE,IAAI,IAAI,CAACtG,UAAU,IAAI,EAAE,CAAC,CACjE,CAACa,GAAG,CAACO,IAAI,IAAG;MACX,OAAO;QAACA,IAAI;QAAEmF,QAAQ,EAAEzC,OAAO,CAAC0C;MAAc,CAAC;IACjD,CAAC,CAAC;IACF,MAAMzC,UAAU,GAAA1D,MAAA,CAAA2D,MAAA,KAAwB,IAAI,CAACpD,SAAS,CAAC;IACvDP,MAAM,CAACC,IAAI,CAACP,MAAM,CAAC,CAACQ,OAAO,CAACC,IAAI,IAAG;MACjC,MAAM,CAACyD,QAAQ,EAAEC,KAAK,CAAC,GAAGtF,aAAa,CAAC4B,IAAI,CAAC;MAC7C,MAAM2D,OAAO,GAAa,EAAE;MAC5BA,OAAO,CAACD,KAAK,CAAC,GAAGnE,MAAM,CAACS,IAAI,CAAC;MAC7BuD,UAAU,CAACE,QAAQ,CAAC,GAAGE,OAAO;IAChC,CAAC,CAAC;IACF,MAAMG,+BAA+B,GAA4B,EAAE;IACnE,MAAMF,aAAa,GAAG,IAAI,CAACC,kBAAkB,CAACN,UAAU,CAAC;IACzD,MAAM0C,KAAK,GAA6B,EAAE;IAC1C,OAAOJ,KAAK,CAAC1D,MAAM,GAAG,CAAC,EAAE;MACvB,MAAM+D,QAAQ,GAAG,IAAI,CAACC,YAAY,CAC9BjF,UAAU,EAAE2E,KAAK,EAAEvC,OAAO,EAAEC,UAAU,EAAE0C,KAAK,EAAErC,aAAa,EAC5Db,eAAe,EAAEe,+BAA+B,EAAE8B,SAAS,CAAC;MAChE,MAAMQ,OAAO,CAACC,GAAG,CAACH,QAAQ,CAAC;;IAE7B,IAAInE,WAAW,IAAI,IAAI,IAAI,CAACiD,mBAAmB,EAAE;MAC/CsB,OAAO,CAACC,IAAI,CACR,sIACgE,CAAC;;IAEvE,MAAMC,cAAc,GAChBpF,WAAW,CACNqF,MAAM,CACH7F,IAAI,IAAI,CAACnC,aAAa,CAACmC,IAAI,CAAC,IACxB,CAAC1C,SAAS,CAAC0C,IAAI,CAACZ,IAAI,EAAEuD,UAAU,EAAED,OAAO,CAAC,CAAC,CAClDjD,GAAG,CAACO,IAAI,IAAIA,IAAI,CAACZ,IAAI,CAAC;IAC/B,IAAIwG,cAAc,CAACrE,MAAM,GAAG,CAAC,EAAE;MAC7B,IAAIuE,cAAc,GAAG,EAAE;MACvB,IAAI3E,WAAW,IAAI,IAAI,EAAE;QACvB2E,cAAc,GACV,6FAAAjG,MAAA,CAC2BuB,UAAU,MAAG;;MAE9C,MAAM,IAAIC,KAAK,CACX,+BAAAxB,MAAA,CAA+B+F,cAAc,uCAAA/F,MAAA,CAClCgC,KAAK,iDAA8C,OAAAhC,MAAA,CAC1DqB,aAAa,SAAArB,MAAA,CAAMiG,cAAc,CAAE,CAAC;;IAE9C,OAAOnD,UAAU;EACnB;EAEQ4C,YAAYA,CAChBjF,UAAkB,EAAE2E,KAAyB,EAAEvC,OAAyB,EACxEa,SAA0B,EAAE8B,KAA+B,EAC3DrC,aAA0B,EAAEW,WAAqB,EACjDT,+BAAwD,EACxD8B,SAAsB;IACxB,MAAMM,QAAQ,GAA6B,EAAE;IAC7C,OAAOL,KAAK,CAAC1D,MAAM,GAAG,CAAC,EAAE;MACvB,MAAMwE,IAAI,GAAGd,KAAK,CAACe,GAAG,EAAE;MACxBtD,OAAO,CAAC0C,cAAc,GAAGW,IAAI,CAACZ,QAAQ;MACtC,IAAItC,QAAQ,GAAG,EAAE;MACjB;MACA;MACA;MACA,IAAIkD,IAAI,CAAC/F,IAAI,CAACsB,EAAE,KAAK,OAAO,IACxBjE,aAAa,CAAC,YAAY,EAAE0I,IAAI,CAAC/F,IAAI,EAAEuD,SAAS,EAAEb,OAAO,CAAC,EAAE;QAC9D,CAACG,QAAQ,CAAC,GAAGzF,mBAAmB,CAAC2I,IAAI,CAAC/F,IAAI,CAACZ,IAAI,EAAEsD,OAAO,CAAC;;MAG3D;MACA;MACA,IAAIa,SAAS,CAACwC,IAAI,CAAC/F,IAAI,CAACZ,IAAI,CAAC,IAAI,IAAI,EAAE;QACrC,MAAM2D,OAAO,GACTtF,SAAS,CAACsI,IAAI,CAAC/F,IAAI,EAAEuD,SAAS,EAAEb,OAAO,EAAE,IAAI,CAAC3C,gBAAgB,CAAC;QACnE,IAAI,CAAC8C,QAAQ,EAAE;UACb,CAACA,QAAQ,CAAC,GAAGzF,mBAAmB,CAAC2I,IAAI,CAAC/F,IAAI,CAACZ,IAAI,EAAEsD,OAAO,CAAC;;QAE3D,MAAM0C,cAAc,GAAG1C,OAAO,CAAC0C,cAAc;QAC7C,IAAIjI,IAAI,CAACiG,SAAS,CAACL,OAAO,CAAC,EAAE;UAC3BuC,QAAQ,CAACW,IAAI,CAAElD,OAA6B,CAACmD,IAAI,CAACzB,CAAC,IAAG;YACpDlB,SAAS,CAACV,QAAQ,CAAC,GAAG4B,CAAC;YACvB/B,OAAO,CAAC0C,cAAc,GAAGA,cAAc;YACvC,IAAI,CAAC/B,sBAAsB,CACvBR,QAAQ,EAAEkD,IAAI,CAAC/F,IAAI,EAAEuD,SAAS,EAAEb,OAAO,EAAEM,aAAa,EACtDW,WAAW,EAAET,+BAA+B,CAAC;YACjD,IAAI,CAACiD,iBAAiB,CAClBJ,IAAI,CAAC/F,IAAI,EAAEiF,KAAK,EAAEvC,OAAO,EAAEa,SAAS,EAAE8B,KAAK,EAAEL,SAAS,CAAC;YAC3D,OAAOP,CAAC;UACV,CAAC,CAAC,CAAC;SACJ,MAAM;UACLlB,SAAS,CAACV,QAAQ,CAAC,GAAGE,OAAmB;UACzC,IAAI,CAACM,sBAAsB,CACvBR,QAAQ,EAAEkD,IAAI,CAAC/F,IAAI,EAAEuD,SAAS,EAAEb,OAAO,EAAEM,aAAa,EACtDW,WAAW,EAAET,+BAA+B,CAAC;UACjD,IAAI,CAACiD,iBAAiB,CAClBJ,IAAI,CAAC/F,IAAI,EAAEiF,KAAK,EAAEvC,OAAO,EAAEa,SAAS,EAAE8B,KAAK,EAAEL,SAAS,CAAC;;OAE9D,MAAM;QACL,IAAI,CAACmB,iBAAiB,CAClBJ,IAAI,CAAC/F,IAAI,EAAEiF,KAAK,EAAEvC,OAAO,EAAEa,SAAS,EAAE8B,KAAK,EAAEL,SAAS,CAAC;;;IAG/D,OAAOM,QAAQ;EACjB;EAEQa,iBAAiBA,CACrBnG,IAAU,EAAEiF,KAAyB,EAAEvC,OAAyB,EAChEa,SAA0B,EAAE8B,KAA+B,EAC3DL,SAAsB;IACxBhF,IAAI,CAAC8D,QAAQ,CAAC3E,OAAO,CAAEiH,SAAS,IAAI;MAClC,MAAM,CAACvD,QAAQ,CAAG,GAAGzF,mBAAmB,CAACgJ,SAAS,CAAChH,IAAI,EAAEsD,OAAO,CAAC;MACjE,IAAI2C,KAAK,CAACxC,QAAQ,CAAC,IAAI,CAACmC,SAAS,CAAChB,GAAG,CAACoC,SAAS,CAAChH,IAAI,CAAC,EAAE;QACrD;;MAEF;MACA,IAAIgH,SAAS,CAAC9E,EAAE,KAAK,OAAO,EAAE;QAC5B,IAAI8E,SAAS,CAACC,UAAU,CAACC,IAAI,CAAClH,IAAI,IAAG;UAC/B,OAAO,CAAC,CAAC9B,SAAS,CAAC8B,IAAI,EAAEmE,SAAS,EAAEb,OAAO,CAAC;QAC9C,CAAC,CAAC,EAAE;UACN2C,KAAK,CAACxC,QAAQ,CAAC,GAAG,IAAI;UACtBoC,KAAK,CAACgB,IAAI,CAAC;YAACd,QAAQ,EAAEzC,OAAO,CAAC0C,cAAc;YAAEpF,IAAI,EAAEoG;UAAS,CAAC,CAAC;;OAElE;QAAO;QACJ,IAAIA,SAAS,CAACC,UAAU,CAACE,KAAK,CAACnH,IAAI,IAAG;UAChC,OAAO,CAAC,CAAC9B,SAAS,CAAC8B,IAAI,EAAEmE,SAAS,EAAEb,OAAO,CAAC;QAC9C,CAAC,CAAC,EAAE;UACV2C,KAAK,CAACxC,QAAQ,CAAC,GAAG,IAAI;UACtBoC,KAAK,CAACgB,IAAI,CAAC;YAACd,QAAQ,EAAEzC,OAAO,CAAC0C,cAAc;YAAEpF,IAAI,EAAEoG;UAAS,CAAC,CAAC;;IAEnE,CAAC,CAAC;EACJ;EAEA;;;EAGA9C,OAAOA,CAAA;IACLrE,MAAM,CAACC,IAAI,CAAC,IAAI,CAACM,SAAS,CAAC,CACtBL,OAAO,CACJO,GAAG,IAAI,IAAI,CAACF,SAAS,CAACE,GAAG,CAAC,CAACP,OAAO,CAACQ,MAAM,IAAIA,MAAM,CAAC2D,OAAO,EAAE,CAAC,CAAC;EACzE;EAEQvB,sBAAsBA,CAACpD,MAAsB;IACnDM,MAAM,CAACC,IAAI,CAACP,MAAM,CAAC,CAACQ,OAAO,CAACC,IAAI,IAAG;MACjC,MAAM2E,KAAK,GAAGpF,MAAM,CAACS,IAAI,CAAC;MAC1B,MAAM,CAACyD,QAAQ,CAAG,GAAGrF,aAAa,CAAC4B,IAAI,CAAC;MACxC,MAAMY,IAAI,GAAG,IAAI,CAAChC,KAAK,CAACkE,KAAK,CAACW,QAAQ,CAAC;MACvC,IAAI7C,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,IAAIF,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,CAACC,KAAK,EAAE;QAC9D,MAAMF,KAAK,GAAGD,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,CAACC,KAAiB;QACxD,MAAMqG,KAAK,GAAGvG,KAAK,CAACsB,MAAM,KAAKwC,KAAK,CAAC9D,KAAK,CAACsB,MAAM,IAC7CwC,KAAK,CAAC9D,KAAK,CAACsG,KAAK,CACb,CAACE,GAAG,EAAE3D,KAAK,KAAK7C,KAAK,CAAC6C,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI7C,KAAK,CAAC6C,KAAK,CAAC,KAAK2D,GAAG,CAAC;QACpEtJ,IAAI,CAACuJ,MAAM,CACPF,KAAK,EACL,MAAM,sBAAA3G,MAAA,CAAsBG,IAAI,CAACZ,IAAI,uDAAAS,MAAA,CACDI,KAAK,gBAAa,OAAAJ,MAAA,CAC9CkE,KAAK,CAAC9D,KAAK,MAAG,CAAC;;MAE7B,IAAID,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,IAAIF,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,CAACC,KAAK,EAAE;QAC9DhD,IAAI,CAACuJ,MAAM,CACP3C,KAAK,CAAC1D,KAAK,KAAKL,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,CAACC,KAAe,EACxD,MAAM,sBAAAN,MAAA,CAAsBG,IAAI,CAACZ,IAAI,qDACH,MAAAS,MAAA,CAC3BG,IAAI,CAACE,UAAU,CAAC,OAAO,CAAC,CAACC,KAAK,gBAAAN,MAAA,CAAakE,KAAK,CAAC1D,KAAK,CAAE,CAAC;;IAExE,CAAC,CAAC;EACJ;EAEQuB,SAASA,CAACjD,MAAsB;IACtC,MAAMgI,MAAM,GAAmB,EAAE;IACjC,KAAK,MAAMC,SAAS,IAAIjI,MAAM,EAAE;MAC9B,IAAI,IAAI,CAACG,UAAU,IAAI,IAAI,IAAI,IAAI,CAACA,UAAU,CAACH,MAAM,IAAI,IAAI,IACzD,IAAI,CAACG,UAAU,CAACH,MAAM,CAACiI,SAAS,CAAC,IAAI,IAAI,EAAE;QAC7C,MAAMjH,MAAM,GAAG,IAAI,CAACb,UAAU,CAACH,MAAM,CAACiI,SAAS,CAAC;QAChDD,MAAM,CAAChH,MAAM,CAACP,IAAI,CAAC,GAAGT,MAAM,CAACiI,SAAS,CAAC;OACxC,MAAM;QACLD,MAAM,CAACC,SAAS,CAAC,GAAGjI,MAAM,CAACiI,SAAS,CAAC;;;IAGzC,OAAOD,MAAM;EACf;EAEQ7E,WAAWA,CAACnD,MAAsB;IACxC,MAAMkI,UAAU,GAAG5H,MAAM,CAACC,IAAI,CAACP,MAAM,CAAC,CAACkH,MAAM,CAACzG,IAAI,IAAG;MACnD,MAAM,CAACyD,QAAQ,CAAC,GAAGrF,aAAa,CAAC4B,IAAI,CAAC;MACtC,OAAO,IAAI,CAACpB,KAAK,CAACkE,KAAK,CAACW,QAAQ,CAAC,IAAI,IAAI;IAC3C,CAAC,CAAC;IACF,IAAIgE,UAAU,CAACtF,MAAM,GAAG,CAAC,EAAE;MACzB,MAAM,IAAIF,KAAK,CACX,4DAAAxB,MAAA,CACUgH,UAAU,iCAA8B,CAAC;;EAE3D;EAEQ7E,UAAUA,CAACvD,OAAiB;IAClC,OAAOA,OAAO,CAACgB,GAAG,CAACL,IAAI,IAAG;MACxB,IAAI,IAAI,CAACN,UAAU,IAAI,IAAI,IAAI,IAAI,CAACA,UAAU,CAACL,OAAO,IAAI,IAAI,IAC1D,IAAI,CAACK,UAAU,CAACL,OAAO,CAACW,IAAI,CAAC,IAAI,IAAI,EAAE;QACzC,MAAMO,MAAM,GAAG,IAAI,CAACb,UAAU,CAACL,OAAO,CAACW,IAAI,CAAC;QAC5C,OAAOO,MAAM,CAACP,IAAI;;MAEpB,OAAOA,IAAI;IACb,CAAC,EAAE,EAAE,CAAC;EACR;EAEQ6C,YAAYA,CAACxD,OAAiB;IACpCA,OAAO,CAACU,OAAO,CAACC,IAAI,IAAG;MACrB,MAAM,CAAC0H,cAAc,CAAC,GAAGtJ,aAAa,CAAC4B,IAAI,CAAC;MAC5C,IAAI,CAAC,IAAI,CAACpB,KAAK,CAACkE,KAAK,CAAC4E,cAAc,CAAC,EAAE;QACrC,MAAM,IAAIzF,KAAK,gBAAAxB,MAAA,CAAgBT,IAAI,gCAA6B,CAAC;;IAErE,CAAC,CAAC;EACJ"},"metadata":{},"sourceType":"module","externalDependencies":[]}