{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const EPSILON_FLOAT32 = 1e-7;\nexport const EPSILON_FLOAT16 = 1e-4;\n/** Convenient class for storing tensor-related data. */\nexport class DataStorage {\n  constructor(backend, dataMover) {\n    this.backend = backend;\n    this.dataMover = dataMover;\n    this.data = new WeakMap();\n    this.dataIdsCount = 0;\n  }\n  get(dataId) {\n    if (!this.data.has(dataId)) {\n      this.dataMover.moveData(this.backend, dataId);\n    }\n    return this.data.get(dataId);\n  }\n  set(dataId, value) {\n    this.dataIdsCount++;\n    this.data.set(dataId, value);\n  }\n  has(dataId) {\n    return this.data.has(dataId);\n  }\n  delete(dataId) {\n    this.dataIdsCount--;\n    return this.data.delete(dataId);\n  }\n  numDataIds() {\n    return this.dataIdsCount;\n  }\n}\n/**\n * The interface that defines the kernels that should be implemented when\n * adding a new backend. New backends don't need to implement every one of the\n * methods, this can be done gradually (throw an error for unimplemented\n * methods).\n */\nexport class KernelBackend {\n  /**\n   * Decrease the complex ref count for the dataId, this is useful for WebGL\n   * backend to keep the real and imag components of the complex tensor in sync\n   * with the engine. WASM and node do not have internal ref count, they will\n   * use on the default implementation.\n   * @param dataId\n   */\n  decComplexRef(dataId) {\n    return;\n  }\n  time(f) {\n    return notYetImplemented('time');\n  }\n  read(dataId) {\n    return notYetImplemented('read');\n  }\n  readSync(dataId) {\n    return notYetImplemented('readSync');\n  }\n  numDataIds() {\n    return notYetImplemented('numDataIds');\n  }\n  disposeData(dataId) {\n    return notYetImplemented('disposeData');\n  }\n  write(values, shape, dtype) {\n    return notYetImplemented('write');\n  }\n  move(dataId, values, shape, dtype) {\n    return notYetImplemented('move');\n  }\n  memory() {\n    return notYetImplemented('memory');\n  }\n  /** Returns the highest precision for floats in bits (e.g. 16 or 32) */\n  floatPrecision() {\n    return notYetImplemented('floatPrecision');\n  }\n  /** Returns the smallest representable number.  */\n  epsilon() {\n    return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;\n  }\n  batchMatMul(a, b, transposeA, transposeB) {\n    return notYetImplemented('batchMatMul');\n  }\n  fusedBatchMatMul({\n    a,\n    b,\n    transposeA,\n    transposeB,\n    bias,\n    activation,\n    preluActivationWeights\n  }) {\n    return notYetImplemented('fusedBatchMatMul');\n  }\n  slice(x, begin, size) {\n    return notYetImplemented('slice');\n  }\n  stridedSlice(x, begin, end, strides) {\n    return notYetImplemented('stridedSlice');\n  }\n  unstack(x, axis) {\n    return notYetImplemented('unstack');\n  }\n  reverse(a, axis) {\n    return notYetImplemented('reverse');\n  }\n  concat(tensors, axis) {\n    return notYetImplemented('concat');\n  }\n  neg(a) {\n    return notYetImplemented('neg');\n  }\n  add(a, b) {\n    return notYetImplemented('add');\n  }\n  addN(tensors) {\n    return notYetImplemented('addN');\n  }\n  subtract(a, b) {\n    return notYetImplemented('subtract');\n  }\n  multiply(a, b) {\n    return notYetImplemented('multiply');\n  }\n  realDivide(a, b) {\n    return notYetImplemented('realDivide');\n  }\n  floorDiv(a, b) {\n    return notYetImplemented('floorDiv');\n  }\n  sum(x, axes) {\n    return notYetImplemented('sum');\n  }\n  prod(x, axes) {\n    return notYetImplemented('prod');\n  }\n  unsortedSegmentSum(x, segmentIds, numSegments) {\n    return notYetImplemented('unsortedSegmentSum');\n  }\n  argMin(x, axis) {\n    return notYetImplemented('argMin');\n  }\n  argMax(x, axis) {\n    return notYetImplemented('argMax');\n  }\n  equal(a, b) {\n    return notYetImplemented('equal');\n  }\n  notEqual(a, b) {\n    return notYetImplemented('notEqual');\n  }\n  less(a, b) {\n    return notYetImplemented('less');\n  }\n  lessEqual(a, b) {\n    return notYetImplemented('lessEqual');\n  }\n  greater(a, b) {\n    return notYetImplemented('greater');\n  }\n  greaterEqual(a, b) {\n    return notYetImplemented('greaterEqual');\n  }\n  logicalNot(a) {\n    return notYetImplemented('logicalNot');\n  }\n  logicalAnd(a, b) {\n    return notYetImplemented('logicalAnd');\n  }\n  logicalOr(a, b) {\n    return notYetImplemented('logicalOr');\n  }\n  where(condition) {\n    return notYetImplemented('where');\n  }\n  select(condition, a, b) {\n    return notYetImplemented('select');\n  }\n  topk(x, k, sorted) {\n    return notYetImplemented('topk');\n  }\n  min(x, axes) {\n    return notYetImplemented('min');\n  }\n  minimum(a, b) {\n    return notYetImplemented('minimum');\n  }\n  mod(a, b) {\n    return notYetImplemented('mod');\n  }\n  max(x, axes) {\n    return notYetImplemented('max');\n  }\n  maximum(a, b) {\n    return notYetImplemented('maximum');\n  }\n  all(x, axes) {\n    return notYetImplemented('all');\n  }\n  any(x, axes) {\n    return notYetImplemented('any');\n  }\n  squaredDifference(a, b) {\n    return notYetImplemented('squaredDifference');\n  }\n  ceil(x) {\n    return notYetImplemented('ceil');\n  }\n  floor(x) {\n    return notYetImplemented('floor');\n  }\n  round(x) {\n    return notYetImplemented('round');\n  }\n  sign(x) {\n    return notYetImplemented('sign');\n  }\n  isNaN(x) {\n    return notYetImplemented('isNaN');\n  }\n  isInf(x) {\n    return notYetImplemented('isInf');\n  }\n  isFinite(x) {\n    return notYetImplemented('isFinite');\n  }\n  pow(a, b) {\n    return notYetImplemented('pow');\n  }\n  exp(x) {\n    return notYetImplemented('exp');\n  }\n  expm1(x) {\n    return notYetImplemented('expm1');\n  }\n  softmax(x, dim) {\n    return notYetImplemented('softmax');\n  }\n  log(x) {\n    return notYetImplemented('log');\n  }\n  log1p(x) {\n    return notYetImplemented('log1p');\n  }\n  sqrt(x) {\n    return notYetImplemented('sqrt');\n  }\n  rsqrt(x) {\n    return notYetImplemented('rsqrt');\n  }\n  square(x) {\n    return notYetImplemented('square');\n  }\n  reciprocal(x) {\n    return notYetImplemented('reciprocal');\n  }\n  relu(x) {\n    return notYetImplemented('relu');\n  }\n  relu6(x) {\n    return notYetImplemented('relu6');\n  }\n  prelu(x, a) {\n    return notYetImplemented('prelu');\n  }\n  elu(x) {\n    return notYetImplemented('elu');\n  }\n  eluDer(dy, y) {\n    return notYetImplemented('eluDer');\n  }\n  selu(x) {\n    return notYetImplemented('selu');\n  }\n  int(x) {\n    return notYetImplemented('int');\n  }\n  clip(x, min, max) {\n    return notYetImplemented('clip');\n  }\n  abs(x) {\n    return notYetImplemented('abs');\n  }\n  complexAbs(x) {\n    return notYetImplemented('complexAbs');\n  }\n  sigmoid(x) {\n    return notYetImplemented('sigmoid');\n  }\n  softplus(x) {\n    return notYetImplemented('softplus');\n  }\n  sin(x) {\n    return notYetImplemented('sin');\n  }\n  cos(x) {\n    return notYetImplemented('cos');\n  }\n  tan(x) {\n    return notYetImplemented('tan');\n  }\n  asin(x) {\n    return notYetImplemented('asin');\n  }\n  acos(x) {\n    return notYetImplemented('acos');\n  }\n  atan(x) {\n    return notYetImplemented('atan');\n  }\n  atan2(a, b) {\n    return notYetImplemented('atan2');\n  }\n  sinh(x) {\n    return notYetImplemented('sinh');\n  }\n  cosh(x) {\n    return notYetImplemented('cosh');\n  }\n  tanh(x) {\n    return notYetImplemented('tanh');\n  }\n  asinh(x) {\n    return notYetImplemented('asinh');\n  }\n  acosh(x) {\n    return notYetImplemented('acosh');\n  }\n  atanh(x) {\n    return notYetImplemented('atanh');\n  }\n  erf(x) {\n    return notYetImplemented('erf');\n  }\n  step(x, alpha) {\n    return notYetImplemented('step');\n  }\n  fusedConv2d({\n    input,\n    filter,\n    convInfo,\n    bias,\n    activation,\n    preluActivationWeights\n  }) {\n    return notYetImplemented('fusedConv2d');\n  }\n  conv2d(x, filter, convInfo) {\n    return notYetImplemented('conv2d');\n  }\n  conv2dDerInput(dy, filter, convInfo) {\n    return notYetImplemented('conv2dDerInput');\n  }\n  conv2dDerFilter(x, dY, convInfo) {\n    return notYetImplemented('conv2dDerFilter');\n  }\n  fusedDepthwiseConv2D({\n    input,\n    filter,\n    convInfo,\n    bias,\n    activation,\n    preluActivationWeights\n  }) {\n    return notYetImplemented('fusedDepthwiseConv2D');\n  }\n  depthwiseConv2D(input, filter, convInfo) {\n    return notYetImplemented('depthwiseConv2D');\n  }\n  depthwiseConv2DDerInput(dy, filter, convInfo) {\n    return notYetImplemented('depthwiseConv2DDerInput');\n  }\n  depthwiseConv2DDerFilter(x, dY, convInfo) {\n    return notYetImplemented('depthwiseConv2DDerFilter');\n  }\n  conv3d(x, filter, convInfo) {\n    return notYetImplemented('conv3d');\n  }\n  conv3dDerInput(dy, filter, convInfo) {\n    return notYetImplemented('conv3dDerInput');\n  }\n  conv3dDerFilter(x, dY, convInfo) {\n    return notYetImplemented('conv3dDerFilter');\n  }\n  maxPool(x, convInfo) {\n    return notYetImplemented('maxPool');\n  }\n  maxPoolBackprop(dy, x, y, convInfo) {\n    return notYetImplemented('maxPoolBackprop');\n  }\n  avgPool(x, convInfo) {\n    return notYetImplemented('avgPool');\n  }\n  avgPoolBackprop(dy, x, convInfo) {\n    return notYetImplemented('avgPoolBackprop');\n  }\n  avgPool3d(x, convInfo) {\n    return notYetImplemented('avgPool3d');\n  }\n  avgPool3dBackprop(dy, x, convInfo) {\n    return notYetImplemented('avgPool3dBackprop');\n  }\n  maxPool3d(x, convInfo) {\n    return notYetImplemented('maxPool3d');\n  }\n  maxPool3dBackprop(dy, x, y, convInfo) {\n    return notYetImplemented('maxPool3dBackprop');\n  }\n  reshape(x, shape) {\n    return notYetImplemented('reshape');\n  }\n  cast(x, dtype) {\n    return notYetImplemented('cast');\n  }\n  tile(x, reps) {\n    return notYetImplemented('tile');\n  }\n  pad(x, paddings, constantValue) {\n    return notYetImplemented('pad');\n  }\n  transpose(x, perm) {\n    return notYetImplemented('transpose');\n  }\n  gather(x, indices, axis, batchDims = 0) {\n    return notYetImplemented('gather');\n  }\n  gatherND(x, indices) {\n    return notYetImplemented('gatherND');\n  }\n  scatterND(indices, updates, shape) {\n    return notYetImplemented('scatterND');\n  }\n  batchToSpaceND(x, blockShape, crops) {\n    return notYetImplemented('batchToSpaceND');\n  }\n  spaceToBatchND(x, blockShape, paddings) {\n    return notYetImplemented('spaceToBatchND');\n  }\n  resizeBilinear(x, newHeight, newWidth, alignCorners, halfPixelCenters) {\n    return notYetImplemented('resizeBilinear');\n  }\n  resizeBilinearBackprop(dy, x, alignCorners) {\n    return notYetImplemented('resizeBilinearBackprop');\n  }\n  resizeNearestNeighbor(x, newHEight, newWidth, alignCorners, halfPixelCenters) {\n    return notYetImplemented('resizeNearestNeighbor');\n  }\n  resizeNearestNeighborBackprop(dy, x, alignCorners) {\n    return notYetImplemented('resizeNearestNeighborBackprop');\n  }\n  batchNorm(x, mean, variance, offset, scale, varianceEpsilon) {\n    return notYetImplemented('batchNorm');\n  }\n  localResponseNormalization4D(x, radius, bias, alpha, beta) {\n    return notYetImplemented('localResponseNormalization4D');\n  }\n  LRNGrad(dy, inputImage, outputImage, radius, bias, alpha, beta) {\n    return notYetImplemented('LRNGrad');\n  }\n  multinomial(logits, normalized, numSamples, seed) {\n    return notYetImplemented('multinomial');\n  }\n  oneHot(indices, depth, onValue, offValue) {\n    return notYetImplemented('oneHot');\n  }\n  cumsum(x, axis, exclusive, reverse) {\n    return notYetImplemented('cumsum');\n  }\n  nonMaxSuppression(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n    return notYetImplemented('nonMaxSuppression');\n  }\n  fft(x) {\n    return notYetImplemented('fft');\n  }\n  ifft(x) {\n    return notYetImplemented('ifft');\n  }\n  complex(real, imag) {\n    return notYetImplemented('complex');\n  }\n  real(input) {\n    return notYetImplemented('real');\n  }\n  imag(input) {\n    return notYetImplemented('imag');\n  }\n  cropAndResize(image, boxes, boxIndex, cropSize, method, extrapolationValue) {\n    return notYetImplemented('cropAndResize');\n  }\n  depthToSpace(x, blockSize, dataFormat) {\n    return notYetImplemented('depthToSpace');\n  }\n  // Aligns with the \"SplitV\" kernel in TensorFlow.\n  split(value, sizeSplits, axis) {\n    return notYetImplemented('split');\n  }\n  sparseToDense(sparseIndices, sparseValues, outputShape, defaultValue) {\n    return notYetImplemented('sparseToDense');\n  }\n  diag(x) {\n    return notYetImplemented('diag');\n  }\n  fill(shape, value, dtype) {\n    return notYetImplemented('fill');\n  }\n  onesLike(x) {\n    return notYetImplemented('onesLike');\n  }\n  zerosLike(x) {\n    return notYetImplemented('zerosLike');\n  }\n  linspace(start, stop, num) {\n    return notYetImplemented('linspace');\n  }\n  dispose() {\n    return notYetImplemented('dispose');\n  }\n}\nfunction notYetImplemented(kernelName) {\n  throw new Error(`'${kernelName}' not yet implemented or not found in the registry. ` + `This kernel may not be supported by the tfjs backend you have chosen`);\n}","map":{"version":3,"names":["EPSILON_FLOAT32","EPSILON_FLOAT16","DataStorage","constructor","backend","dataMover","data","WeakMap","dataIdsCount","get","dataId","has","moveData","set","value","delete","numDataIds","KernelBackend","decComplexRef","time","f","notYetImplemented","read","readSync","disposeData","write","values","shape","dtype","move","memory","floatPrecision","epsilon","batchMatMul","a","b","transposeA","transposeB","fusedBatchMatMul","bias","activation","preluActivationWeights","slice","x","begin","size","stridedSlice","end","strides","unstack","axis","reverse","concat","tensors","neg","add","addN","subtract","multiply","realDivide","floorDiv","sum","axes","prod","unsortedSegmentSum","segmentIds","numSegments","argMin","argMax","equal","notEqual","less","lessEqual","greater","greaterEqual","logicalNot","logicalAnd","logicalOr","where","condition","select","topk","k","sorted","min","minimum","mod","max","maximum","all","any","squaredDifference","ceil","floor","round","sign","isNaN","isInf","isFinite","pow","exp","expm1","softmax","dim","log","log1p","sqrt","rsqrt","square","reciprocal","relu","relu6","prelu","elu","eluDer","dy","y","selu","int","clip","abs","complexAbs","sigmoid","softplus","sin","cos","tan","asin","acos","atan","atan2","sinh","cosh","tanh","asinh","acosh","atanh","erf","step","alpha","fusedConv2d","input","filter","convInfo","conv2d","conv2dDerInput","conv2dDerFilter","dY","fusedDepthwiseConv2D","depthwiseConv2D","depthwiseConv2DDerInput","depthwiseConv2DDerFilter","conv3d","conv3dDerInput","conv3dDerFilter","maxPool","maxPoolBackprop","avgPool","avgPoolBackprop","avgPool3d","avgPool3dBackprop","maxPool3d","maxPool3dBackprop","reshape","cast","tile","reps","pad","paddings","constantValue","transpose","perm","gather","indices","batchDims","gatherND","scatterND","updates","batchToSpaceND","blockShape","crops","spaceToBatchND","resizeBilinear","newHeight","newWidth","alignCorners","halfPixelCenters","resizeBilinearBackprop","resizeNearestNeighbor","newHEight","resizeNearestNeighborBackprop","batchNorm","mean","variance","offset","scale","varianceEpsilon","localResponseNormalization4D","radius","beta","LRNGrad","inputImage","outputImage","multinomial","logits","normalized","numSamples","seed","oneHot","depth","onValue","offValue","cumsum","exclusive","nonMaxSuppression","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","fft","ifft","complex","real","imag","cropAndResize","image","boxIndex","cropSize","method","extrapolationValue","depthToSpace","blockSize","dataFormat","split","sizeSplits","sparseToDense","sparseIndices","sparseValues","outputShape","defaultValue","diag","fill","onesLike","zerosLike","linspace","start","stop","num","dispose","kernelName","Error"],"sources":["C:\\Users\\reddy\\Documents\\Projects\\Engagement Tracker\\engagement-tracker-react\\node_modules\\@tensorflow\\tfjs-core\\src\\backends\\backend.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Conv2DInfo, Conv3DInfo} from '../ops/conv_util';\nimport {FusedBatchMatMulConfig, FusedConv2DConfig} from '../ops/fused_types';\nimport {Backend, DataId, Scalar, Tensor, Tensor1D, Tensor2D, Tensor3D, Tensor4D, Tensor5D} from '../tensor';\nimport {BackendValues, DataType, Rank, ShapeMap} from '../types';\n\nexport const EPSILON_FLOAT32 = 1e-7;\nexport const EPSILON_FLOAT16 = 1e-4;\n\n// Required information for all backends.\nexport interface BackendTimingInfo {\n  kernelMs: number|{error: string};\n  getExtraProfileInfo?(): string;  // a field for additional timing information\n                                   // e.g. packing / unpacking for WebGL backend\n}\n\nexport interface TensorStorage {\n  read(dataId: DataId): Promise<BackendValues>;\n  readSync(dataId: DataId): BackendValues;\n  disposeData(dataId: DataId): void;\n  write(values: BackendValues, shape: number[], dtype: DataType): DataId;\n  move(dataId: DataId, values: BackendValues, shape: number[], dtype: DataType):\n      void;\n  memory(): {unreliable: boolean;};  // Backend-specific information.\n  /** Returns number of data ids currently in the storage. */\n  numDataIds(): number;\n}\n\n/** Convenient class for storing tensor-related data. */\nexport class DataStorage<T> {\n  private data = new WeakMap<DataId, T>();\n  private dataIdsCount = 0;\n\n  constructor(private backend: KernelBackend, private dataMover: DataMover) {}\n\n  get(dataId: DataId) {\n    if (!this.data.has(dataId)) {\n      this.dataMover.moveData(this.backend, dataId);\n    }\n    return this.data.get(dataId);\n  }\n\n  set(dataId: DataId, value: T): void {\n    this.dataIdsCount++;\n    this.data.set(dataId, value);\n  }\n\n  has(dataId: DataId): boolean {\n    return this.data.has(dataId);\n  }\n\n  delete(dataId: DataId): boolean {\n    this.dataIdsCount--;\n    return this.data.delete(dataId);\n  }\n\n  numDataIds(): number {\n    return this.dataIdsCount;\n  }\n}\n\nexport interface DataMover {\n  /**\n   * To be called by backends whenever they see a dataId that they don't own.\n   * Upon calling this method, the mover will fetch the tensor from another\n   * backend and register it with the current active backend.\n   */\n  moveData(backend: KernelBackend, dataId: DataId): void;\n}\n\nexport interface BackendTimer {\n  time(f: () => void): Promise<BackendTimingInfo>;\n}\n\n/**\n * The interface that defines the kernels that should be implemented when\n * adding a new backend. New backends don't need to implement every one of the\n * methods, this can be done gradually (throw an error for unimplemented\n * methods).\n */\nexport class KernelBackend implements TensorStorage, Backend, BackendTimer {\n  /**\n   * Decrease the complex ref count for the dataId, this is useful for WebGL\n   * backend to keep the real and imag components of the complex tensor in sync\n   * with the engine. WASM and node do not have internal ref count, they will\n   * use on the default implementation.\n   * @param dataId\n   */\n  decComplexRef(dataId: DataId): void {\n    return;\n  }\n  time(f: () => void): Promise<BackendTimingInfo> {\n    return notYetImplemented('time');\n  }\n  read(dataId: object): Promise<BackendValues> {\n    return notYetImplemented('read');\n  }\n  readSync(dataId: object): BackendValues {\n    return notYetImplemented('readSync');\n  }\n  numDataIds(): number {\n    return notYetImplemented('numDataIds');\n  }\n  disposeData(dataId: object): void {\n    return notYetImplemented('disposeData');\n  }\n  write(values: BackendValues, shape: number[], dtype: DataType): DataId {\n    return notYetImplemented('write');\n  }\n  move(dataId: DataId, values: BackendValues, shape: number[], dtype: DataType):\n      void {\n    return notYetImplemented('move');\n  }\n  memory(): {unreliable: boolean; reasons?: string[]} {\n    return notYetImplemented('memory');\n  }\n  /** Returns the highest precision for floats in bits (e.g. 16 or 32) */\n  floatPrecision(): 16|32 {\n    return notYetImplemented('floatPrecision');\n  }\n  /** Returns the smallest representable number.  */\n  epsilon(): number {\n    return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;\n  }\n\n  batchMatMul(\n      a: Tensor3D, b: Tensor3D, transposeA: boolean,\n      transposeB: boolean): Tensor3D {\n    return notYetImplemented('batchMatMul');\n  }\n\n  fusedBatchMatMul(\n      {a, b, transposeA, transposeB, bias, activation, preluActivationWeights}:\n          FusedBatchMatMulConfig): Tensor3D {\n    return notYetImplemented('fusedBatchMatMul');\n  }\n\n  slice<T extends Tensor>(x: T, begin: number[], size: number[]): T {\n    return notYetImplemented('slice');\n  }\n  stridedSlice<T extends Tensor>(\n      x: T, begin: number[], end: number[], strides: number[]): T {\n    return notYetImplemented('stridedSlice');\n  }\n  unstack(x: Tensor, axis: number): Tensor[] {\n    return notYetImplemented('unstack');\n  }\n  reverse<T extends Tensor>(a: T, axis: number[]): T {\n    return notYetImplemented('reverse');\n  }\n\n  concat(tensors: Tensor[], axis: number): Tensor {\n    return notYetImplemented('concat');\n  }\n\n  neg<T extends Tensor>(a: T): T {\n    return notYetImplemented('neg');\n  }\n\n  add(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('add');\n  }\n  addN<T extends Tensor>(tensors: T[]): T {\n    return notYetImplemented('addN');\n  }\n  subtract(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('subtract');\n  }\n  multiply(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('multiply');\n  }\n  realDivide(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('realDivide');\n  }\n  floorDiv(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('floorDiv');\n  }\n\n  sum(x: Tensor, axes: number[]): Tensor {\n    return notYetImplemented('sum');\n  }\n  prod(x: Tensor, axes: number[]): Tensor {\n    return notYetImplemented('prod');\n  }\n\n  unsortedSegmentSum<T extends Tensor>(\n      x: T, segmentIds: Tensor1D, numSegments: number): Tensor {\n    return notYetImplemented('unsortedSegmentSum');\n  }\n\n  argMin(x: Tensor, axis: number): Tensor {\n    return notYetImplemented('argMin');\n  }\n  argMax(x: Tensor, axis: number): Tensor {\n    return notYetImplemented('argMax');\n  }\n\n  equal(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('equal');\n  }\n  notEqual(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('notEqual');\n  }\n\n  less(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('less');\n  }\n  lessEqual(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('lessEqual');\n  }\n\n  greater(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('greater');\n  }\n  greaterEqual(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('greaterEqual');\n  }\n\n  logicalNot<T extends Tensor>(a: T): T {\n    return notYetImplemented('logicalNot');\n  }\n  logicalAnd(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('logicalAnd');\n  }\n  logicalOr(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('logicalOr');\n  }\n\n  where(condition: Tensor): Tensor2D {\n    return notYetImplemented('where');\n  }\n  select(condition: Tensor, a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('select');\n  }\n\n  topk<T extends Tensor>(x: T, k: number, sorted: boolean): [T, T] {\n    return notYetImplemented('topk');\n  }\n\n  min(x: Tensor, axes: number[]): Tensor {\n    return notYetImplemented('min');\n  }\n  minimum(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('minimum');\n  }\n\n  mod(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('mod');\n  }\n\n  max(x: Tensor, axes: number[]): Tensor {\n    return notYetImplemented('max');\n  }\n  maximum(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('maximum');\n  }\n\n  all(x: Tensor, axes: number[]): Tensor {\n    return notYetImplemented('all');\n  }\n  any(x: Tensor, axes: number[]): Tensor {\n    return notYetImplemented('any');\n  }\n\n  squaredDifference(a: Tensor, b: Tensor): Tensor {\n    return notYetImplemented('squaredDifference');\n  }\n\n  ceil<T extends Tensor>(x: T): T {\n    return notYetImplemented('ceil');\n  }\n  floor<T extends Tensor>(x: T): T {\n    return notYetImplemented('floor');\n  }\n  round<T extends Tensor>(x: T): T {\n    return notYetImplemented('round');\n  }\n\n  sign<T extends Tensor>(x: T): T {\n    return notYetImplemented('sign');\n  }\n\n  isNaN<T extends Tensor>(x: T): T {\n    return notYetImplemented('isNaN');\n  }\n  isInf<T extends Tensor>(x: T): T {\n    return notYetImplemented('isInf');\n  }\n  isFinite<T extends Tensor>(x: T): T {\n    return notYetImplemented('isFinite');\n  }\n\n  pow<T extends Tensor>(a: T, b: Tensor): T {\n    return notYetImplemented('pow');\n  }\n  exp<T extends Tensor>(x: T): T {\n    return notYetImplemented('exp');\n  }\n  expm1<T extends Tensor>(x: T): T {\n    return notYetImplemented('expm1');\n  }\n  softmax<T extends Tensor>(x: T, dim: number): T {\n    return notYetImplemented('softmax');\n  }\n  log<T extends Tensor>(x: T): T {\n    return notYetImplemented('log');\n  }\n  log1p<T extends Tensor>(x: T): T {\n    return notYetImplemented('log1p');\n  }\n  sqrt<T extends Tensor>(x: T): T {\n    return notYetImplemented('sqrt');\n  }\n  rsqrt<T extends Tensor>(x: T): T {\n    return notYetImplemented('rsqrt');\n  }\n  square<T extends Tensor>(x: T): T {\n    return notYetImplemented('square');\n  }\n  reciprocal<T extends Tensor>(x: T): T {\n    return notYetImplemented('reciprocal');\n  }\n  relu<T extends Tensor>(x: T): T {\n    return notYetImplemented('relu');\n  }\n  relu6<T extends Tensor>(x: T): T {\n    return notYetImplemented('relu6');\n  }\n  prelu<T extends Tensor>(x: T, a: T): T {\n    return notYetImplemented('prelu');\n  }\n  elu<T extends Tensor>(x: T): T {\n    return notYetImplemented('elu');\n  }\n  eluDer<T extends Tensor>(dy: T, y: T): T {\n    return notYetImplemented('eluDer');\n  }\n  selu<T extends Tensor>(x: T): T {\n    return notYetImplemented('selu');\n  }\n  int<T extends Tensor>(x: T): T {\n    return notYetImplemented('int');\n  }\n\n  clip<T extends Tensor>(x: T, min: number, max: number): T {\n    return notYetImplemented('clip');\n  }\n\n  abs<T extends Tensor>(x: T): T {\n    return notYetImplemented('abs');\n  }\n  complexAbs<T extends Tensor>(x: T): T {\n    return notYetImplemented('complexAbs');\n  }\n\n  sigmoid<T extends Tensor>(x: T): T {\n    return notYetImplemented('sigmoid');\n  }\n\n  softplus<T extends Tensor>(x: T): T {\n    return notYetImplemented('softplus');\n  }\n\n  sin<T extends Tensor>(x: T): T {\n    return notYetImplemented('sin');\n  }\n  cos<T extends Tensor>(x: T): T {\n    return notYetImplemented('cos');\n  }\n  tan<T extends Tensor>(x: T): T {\n    return notYetImplemented('tan');\n  }\n\n  asin<T extends Tensor>(x: T): T {\n    return notYetImplemented('asin');\n  }\n  acos<T extends Tensor>(x: T): T {\n    return notYetImplemented('acos');\n  }\n  atan<T extends Tensor>(x: T): T {\n    return notYetImplemented('atan');\n  }\n  atan2<T extends Tensor>(a: T, b: T): T {\n    return notYetImplemented('atan2');\n  }\n\n  sinh<T extends Tensor>(x: T): T {\n    return notYetImplemented('sinh');\n  }\n  cosh<T extends Tensor>(x: T): T {\n    return notYetImplemented('cosh');\n  }\n  tanh<T extends Tensor>(x: T): T {\n    return notYetImplemented('tanh');\n  }\n\n  asinh<T extends Tensor>(x: T): T {\n    return notYetImplemented('asinh');\n  }\n  acosh<T extends Tensor>(x: T): T {\n    return notYetImplemented('acosh');\n  }\n  atanh<T extends Tensor>(x: T): T {\n    return notYetImplemented('atanh');\n  }\n\n  erf<T extends Tensor>(x: T): T {\n    return notYetImplemented('erf');\n  }\n\n  step<T extends Tensor>(x: T, alpha: number): T {\n    return notYetImplemented('step');\n  }\n\n  fusedConv2d(\n      {input, filter, convInfo, bias, activation, preluActivationWeights}:\n          FusedConv2DConfig): Tensor4D {\n    return notYetImplemented('fusedConv2d');\n  }\n\n  conv2d(x: Tensor4D, filter: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    return notYetImplemented('conv2d');\n  }\n  conv2dDerInput(dy: Tensor4D, filter: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    return notYetImplemented('conv2dDerInput');\n  }\n  conv2dDerFilter(x: Tensor4D, dY: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    return notYetImplemented('conv2dDerFilter');\n  }\n\n  fusedDepthwiseConv2D(\n      {input, filter, convInfo, bias, activation, preluActivationWeights}:\n          FusedConv2DConfig): Tensor4D {\n    return notYetImplemented('fusedDepthwiseConv2D');\n  }\n\n  depthwiseConv2D(input: Tensor4D, filter: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    return notYetImplemented('depthwiseConv2D');\n  }\n  depthwiseConv2DDerInput(dy: Tensor4D, filter: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    return notYetImplemented('depthwiseConv2DDerInput');\n  }\n  depthwiseConv2DDerFilter(x: Tensor4D, dY: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    return notYetImplemented('depthwiseConv2DDerFilter');\n  }\n  conv3d(x: Tensor5D, filter: Tensor5D, convInfo: Conv3DInfo): Tensor5D {\n    return notYetImplemented('conv3d');\n  }\n  conv3dDerInput(dy: Tensor5D, filter: Tensor5D, convInfo: Conv3DInfo):\n      Tensor5D {\n    return notYetImplemented('conv3dDerInput');\n  }\n  conv3dDerFilter(x: Tensor5D, dY: Tensor5D, convInfo: Conv3DInfo): Tensor5D {\n    return notYetImplemented('conv3dDerFilter');\n  }\n  maxPool(x: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    return notYetImplemented('maxPool');\n  }\n  maxPoolBackprop(dy: Tensor4D, x: Tensor4D, y: Tensor4D, convInfo: Conv2DInfo):\n      Tensor4D {\n    return notYetImplemented('maxPoolBackprop');\n  }\n  avgPool(x: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    return notYetImplemented('avgPool');\n  }\n  avgPoolBackprop(dy: Tensor4D, x: Tensor4D, convInfo: Conv2DInfo): Tensor4D {\n    return notYetImplemented('avgPoolBackprop');\n  }\n  avgPool3d(x: Tensor5D, convInfo: Conv3DInfo): Tensor5D {\n    return notYetImplemented('avgPool3d');\n  }\n  avgPool3dBackprop(dy: Tensor5D, x: Tensor5D, convInfo: Conv3DInfo): Tensor5D {\n    return notYetImplemented('avgPool3dBackprop');\n  }\n  maxPool3d(x: Tensor5D, convInfo: Conv3DInfo): Tensor5D {\n    return notYetImplemented('maxPool3d');\n  }\n  maxPool3dBackprop(\n      dy: Tensor5D, x: Tensor5D, y: Tensor5D, convInfo: Conv3DInfo): Tensor5D {\n    return notYetImplemented('maxPool3dBackprop');\n  }\n\n  reshape<T extends Tensor, R extends Rank>(x: T, shape: ShapeMap[R]):\n      Tensor<R> {\n    return notYetImplemented('reshape');\n  }\n  cast<T extends Tensor>(x: T, dtype: DataType): T {\n    return notYetImplemented('cast');\n  }\n\n  tile<T extends Tensor>(x: T, reps: number[]): T {\n    return notYetImplemented('tile');\n  }\n\n  pad<T extends Tensor>(\n      x: T, paddings: Array<[number, number]>, constantValue: number): T {\n    return notYetImplemented('pad');\n  }\n\n  transpose<T extends Tensor>(x: T, perm: number[]): T {\n    return notYetImplemented('transpose');\n  }\n\n  gather<T extends Tensor>(x: T, indices: Tensor, axis: number, batchDims = 0):\n      T {\n    return notYetImplemented('gather');\n  }\n\n  gatherND(x: Tensor, indices: Tensor): Tensor {\n    return notYetImplemented('gatherND');\n  }\n\n  scatterND<R extends Rank>(\n      indices: Tensor, updates: Tensor, shape: ShapeMap[R]): Tensor<R> {\n    return notYetImplemented('scatterND');\n  }\n\n  batchToSpaceND<T extends Tensor>(\n      x: T, blockShape: number[], crops: number[][]): T {\n    return notYetImplemented('batchToSpaceND');\n  }\n\n  spaceToBatchND<T extends Tensor>(\n      x: T, blockShape: number[], paddings: number[][]): T {\n    return notYetImplemented('spaceToBatchND');\n  }\n\n  resizeBilinear(\n      x: Tensor4D, newHeight: number, newWidth: number, alignCorners: boolean,\n      halfPixelCenters: boolean): Tensor4D {\n    return notYetImplemented('resizeBilinear');\n  }\n\n  resizeBilinearBackprop(dy: Tensor4D, x: Tensor4D, alignCorners: boolean):\n      Tensor4D {\n    return notYetImplemented('resizeBilinearBackprop');\n  }\n\n  resizeNearestNeighbor(\n      x: Tensor4D, newHEight: number, newWidth: number, alignCorners: boolean,\n      halfPixelCenters: boolean): Tensor4D {\n    return notYetImplemented('resizeNearestNeighbor');\n  }\n\n  resizeNearestNeighborBackprop(\n      dy: Tensor4D, x: Tensor4D, alignCorners: boolean): Tensor4D {\n    return notYetImplemented('resizeNearestNeighborBackprop');\n  }\n\n  batchNorm(\n      x: Tensor4D, mean: Tensor4D|Tensor1D, variance: Tensor4D|Tensor1D,\n      offset?: Tensor4D|Tensor1D, scale?: Tensor4D|Tensor1D,\n      varianceEpsilon?: number): Tensor4D {\n    return notYetImplemented('batchNorm');\n  }\n\n  localResponseNormalization4D(\n      x: Tensor4D, radius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    return notYetImplemented('localResponseNormalization4D');\n  }\n\n  LRNGrad(\n      dy: Tensor4D, inputImage: Tensor4D, outputImage: Tensor4D, radius: number,\n      bias: number, alpha: number, beta: number): Tensor4D {\n    return notYetImplemented('LRNGrad');\n  }\n\n  multinomial(\n      logits: Tensor2D, normalized: boolean, numSamples: number,\n      seed: number): Tensor2D {\n    return notYetImplemented('multinomial');\n  }\n\n  oneHot(indices: Tensor1D, depth: number, onValue: number, offValue: number):\n      Tensor2D {\n    return notYetImplemented('oneHot');\n  }\n\n  cumsum(x: Tensor, axis: number, exclusive: boolean, reverse: boolean):\n      Tensor {\n    return notYetImplemented('cumsum');\n  }\n\n  nonMaxSuppression(\n      boxes: Tensor2D, scores: Tensor1D, maxOutputSize: number,\n      iouThreshold: number, scoreThreshold?: number): Tensor1D {\n    return notYetImplemented('nonMaxSuppression');\n  }\n\n  fft(x: Tensor2D): Tensor2D {\n    return notYetImplemented('fft');\n  }\n  ifft(x: Tensor2D): Tensor2D {\n    return notYetImplemented('ifft');\n  }\n  complex<T extends Tensor>(real: T, imag: T): T {\n    return notYetImplemented('complex');\n  }\n  real<T extends Tensor>(input: T): T {\n    return notYetImplemented('real');\n  }\n  imag<T extends Tensor>(input: T): T {\n    return notYetImplemented('imag');\n  }\n\n  cropAndResize(\n      image: Tensor4D, boxes: Tensor2D, boxIndex: Tensor1D,\n      cropSize: [number, number], method: 'bilinear'|'nearest',\n      extrapolationValue: number): Tensor4D {\n    return notYetImplemented('cropAndResize');\n  }\n\n  depthToSpace(x: Tensor4D, blockSize: number, dataFormat: string): Tensor4D {\n    return notYetImplemented('depthToSpace');\n  }\n\n  // Aligns with the \"SplitV\" kernel in TensorFlow.\n  split<T extends Tensor>(value: T, sizeSplits: number[], axis: number): T[] {\n    return notYetImplemented('split');\n  }\n\n  sparseToDense<R extends Rank>(\n      sparseIndices: Tensor, sparseValues: Tensor, outputShape: ShapeMap[R],\n      defaultValue: Scalar): Tensor<R> {\n    return notYetImplemented('sparseToDense');\n  }\n\n  diag(x: Tensor): Tensor {\n    return notYetImplemented('diag');\n  }\n\n  fill<R extends Rank>(\n      shape: ShapeMap[R], value: number|string, dtype?: DataType): Tensor<R> {\n    return notYetImplemented('fill');\n  }\n\n  onesLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    return notYetImplemented('onesLike');\n  }\n\n  zerosLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    return notYetImplemented('zerosLike');\n  }\n\n  linspace(start: number, stop: number, num: number): Tensor1D {\n    return notYetImplemented('linspace');\n  }\n\n  dispose(): void {\n    return notYetImplemented('dispose');\n  }\n}\n\nfunction notYetImplemented(kernelName: string): never {\n  throw new Error(\n      `'${kernelName}' not yet implemented or not found in the registry. ` +\n      `This kernel may not be supported by the tfjs backend you have chosen`);\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAsBA,OAAO,MAAMA,eAAe,GAAG,IAAI;AACnC,OAAO,MAAMC,eAAe,GAAG,IAAI;AAqBnC;AACA,OAAM,MAAOC,WAAW;EAItBC,YAAoBC,OAAsB,EAAUC,SAAoB;IAApD,KAAAD,OAAO,GAAPA,OAAO;IAAyB,KAAAC,SAAS,GAATA,SAAS;IAHrD,KAAAC,IAAI,GAAG,IAAIC,OAAO,EAAa;IAC/B,KAAAC,YAAY,GAAG,CAAC;EAEmD;EAE3EC,GAAGA,CAACC,MAAc;IAChB,IAAI,CAAC,IAAI,CAACJ,IAAI,CAACK,GAAG,CAACD,MAAM,CAAC,EAAE;MAC1B,IAAI,CAACL,SAAS,CAACO,QAAQ,CAAC,IAAI,CAACR,OAAO,EAAEM,MAAM,CAAC;;IAE/C,OAAO,IAAI,CAACJ,IAAI,CAACG,GAAG,CAACC,MAAM,CAAC;EAC9B;EAEAG,GAAGA,CAACH,MAAc,EAAEI,KAAQ;IAC1B,IAAI,CAACN,YAAY,EAAE;IACnB,IAAI,CAACF,IAAI,CAACO,GAAG,CAACH,MAAM,EAAEI,KAAK,CAAC;EAC9B;EAEAH,GAAGA,CAACD,MAAc;IAChB,OAAO,IAAI,CAACJ,IAAI,CAACK,GAAG,CAACD,MAAM,CAAC;EAC9B;EAEAK,MAAMA,CAACL,MAAc;IACnB,IAAI,CAACF,YAAY,EAAE;IACnB,OAAO,IAAI,CAACF,IAAI,CAACS,MAAM,CAACL,MAAM,CAAC;EACjC;EAEAM,UAAUA,CAAA;IACR,OAAO,IAAI,CAACR,YAAY;EAC1B;;AAgBF;;;;;;AAMA,OAAM,MAAOS,aAAa;EACxB;;;;;;;EAOAC,aAAaA,CAACR,MAAc;IAC1B;EACF;EACAS,IAAIA,CAACC,CAAa;IAChB,OAAOC,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAC,IAAIA,CAACZ,MAAc;IACjB,OAAOW,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAE,QAAQA,CAACb,MAAc;IACrB,OAAOW,iBAAiB,CAAC,UAAU,CAAC;EACtC;EACAL,UAAUA,CAAA;IACR,OAAOK,iBAAiB,CAAC,YAAY,CAAC;EACxC;EACAG,WAAWA,CAACd,MAAc;IACxB,OAAOW,iBAAiB,CAAC,aAAa,CAAC;EACzC;EACAI,KAAKA,CAACC,MAAqB,EAAEC,KAAe,EAAEC,KAAe;IAC3D,OAAOP,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAQ,IAAIA,CAACnB,MAAc,EAAEgB,MAAqB,EAAEC,KAAe,EAAEC,KAAe;IAE1E,OAAOP,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAS,MAAMA,CAAA;IACJ,OAAOT,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EACA;EACAU,cAAcA,CAAA;IACZ,OAAOV,iBAAiB,CAAC,gBAAgB,CAAC;EAC5C;EACA;EACAW,OAAOA,CAAA;IACL,OAAO,IAAI,CAACD,cAAc,EAAE,KAAK,EAAE,GAAG/B,eAAe,GAAGC,eAAe;EACzE;EAEAgC,WAAWA,CACPC,CAAW,EAAEC,CAAW,EAAEC,UAAmB,EAC7CC,UAAmB;IACrB,OAAOhB,iBAAiB,CAAC,aAAa,CAAC;EACzC;EAEAiB,gBAAgBA,CACZ;IAACJ,CAAC;IAAEC,CAAC;IAAEC,UAAU;IAAEC,UAAU;IAAEE,IAAI;IAAEC,UAAU;IAAEC;EAAsB,CAC7C;IAC5B,OAAOpB,iBAAiB,CAAC,kBAAkB,CAAC;EAC9C;EAEAqB,KAAKA,CAAmBC,CAAI,EAAEC,KAAe,EAAEC,IAAc;IAC3D,OAAOxB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAyB,YAAYA,CACRH,CAAI,EAAEC,KAAe,EAAEG,GAAa,EAAEC,OAAiB;IACzD,OAAO3B,iBAAiB,CAAC,cAAc,CAAC;EAC1C;EACA4B,OAAOA,CAACN,CAAS,EAAEO,IAAY;IAC7B,OAAO7B,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACA8B,OAAOA,CAAmBjB,CAAI,EAAEgB,IAAc;IAC5C,OAAO7B,iBAAiB,CAAC,SAAS,CAAC;EACrC;EAEA+B,MAAMA,CAACC,OAAiB,EAAEH,IAAY;IACpC,OAAO7B,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EAEAiC,GAAGA,CAAmBpB,CAAI;IACxB,OAAOb,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEAkC,GAAGA,CAACrB,CAAS,EAAEC,CAAS;IACtB,OAAOd,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAmC,IAAIA,CAAmBH,OAAY;IACjC,OAAOhC,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAoC,QAAQA,CAACvB,CAAS,EAAEC,CAAS;IAC3B,OAAOd,iBAAiB,CAAC,UAAU,CAAC;EACtC;EACAqC,QAAQA,CAACxB,CAAS,EAAEC,CAAS;IAC3B,OAAOd,iBAAiB,CAAC,UAAU,CAAC;EACtC;EACAsC,UAAUA,CAACzB,CAAS,EAAEC,CAAS;IAC7B,OAAOd,iBAAiB,CAAC,YAAY,CAAC;EACxC;EACAuC,QAAQA,CAAC1B,CAAS,EAAEC,CAAS;IAC3B,OAAOd,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEAwC,GAAGA,CAAClB,CAAS,EAAEmB,IAAc;IAC3B,OAAOzC,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACA0C,IAAIA,CAACpB,CAAS,EAAEmB,IAAc;IAC5B,OAAOzC,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEA2C,kBAAkBA,CACdrB,CAAI,EAAEsB,UAAoB,EAAEC,WAAmB;IACjD,OAAO7C,iBAAiB,CAAC,oBAAoB,CAAC;EAChD;EAEA8C,MAAMA,CAACxB,CAAS,EAAEO,IAAY;IAC5B,OAAO7B,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EACA+C,MAAMA,CAACzB,CAAS,EAAEO,IAAY;IAC5B,OAAO7B,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EAEAgD,KAAKA,CAACnC,CAAS,EAAEC,CAAS;IACxB,OAAOd,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAiD,QAAQA,CAACpC,CAAS,EAAEC,CAAS;IAC3B,OAAOd,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEAkD,IAAIA,CAACrC,CAAS,EAAEC,CAAS;IACvB,OAAOd,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAmD,SAASA,CAACtC,CAAS,EAAEC,CAAS;IAC5B,OAAOd,iBAAiB,CAAC,WAAW,CAAC;EACvC;EAEAoD,OAAOA,CAACvC,CAAS,EAAEC,CAAS;IAC1B,OAAOd,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACAqD,YAAYA,CAACxC,CAAS,EAAEC,CAAS;IAC/B,OAAOd,iBAAiB,CAAC,cAAc,CAAC;EAC1C;EAEAsD,UAAUA,CAAmBzC,CAAI;IAC/B,OAAOb,iBAAiB,CAAC,YAAY,CAAC;EACxC;EACAuD,UAAUA,CAAC1C,CAAS,EAAEC,CAAS;IAC7B,OAAOd,iBAAiB,CAAC,YAAY,CAAC;EACxC;EACAwD,SAASA,CAAC3C,CAAS,EAAEC,CAAS;IAC5B,OAAOd,iBAAiB,CAAC,WAAW,CAAC;EACvC;EAEAyD,KAAKA,CAACC,SAAiB;IACrB,OAAO1D,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACA2D,MAAMA,CAACD,SAAiB,EAAE7C,CAAS,EAAEC,CAAS;IAC5C,OAAOd,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EAEA4D,IAAIA,CAAmBtC,CAAI,EAAEuC,CAAS,EAAEC,MAAe;IACrD,OAAO9D,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEA+D,GAAGA,CAACzC,CAAS,EAAEmB,IAAc;IAC3B,OAAOzC,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAgE,OAAOA,CAACnD,CAAS,EAAEC,CAAS;IAC1B,OAAOd,iBAAiB,CAAC,SAAS,CAAC;EACrC;EAEAiE,GAAGA,CAACpD,CAAS,EAAEC,CAAS;IACtB,OAAOd,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEAkE,GAAGA,CAAC5C,CAAS,EAAEmB,IAAc;IAC3B,OAAOzC,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAmE,OAAOA,CAACtD,CAAS,EAAEC,CAAS;IAC1B,OAAOd,iBAAiB,CAAC,SAAS,CAAC;EACrC;EAEAoE,GAAGA,CAAC9C,CAAS,EAAEmB,IAAc;IAC3B,OAAOzC,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAqE,GAAGA,CAAC/C,CAAS,EAAEmB,IAAc;IAC3B,OAAOzC,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEAsE,iBAAiBA,CAACzD,CAAS,EAAEC,CAAS;IACpC,OAAOd,iBAAiB,CAAC,mBAAmB,CAAC;EAC/C;EAEAuE,IAAIA,CAAmBjD,CAAI;IACzB,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAwE,KAAKA,CAAmBlD,CAAI;IAC1B,OAAOtB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAyE,KAAKA,CAAmBnD,CAAI;IAC1B,OAAOtB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EAEA0E,IAAIA,CAAmBpD,CAAI;IACzB,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEA2E,KAAKA,CAAmBrD,CAAI;IAC1B,OAAOtB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACA4E,KAAKA,CAAmBtD,CAAI;IAC1B,OAAOtB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACA6E,QAAQA,CAAmBvD,CAAI;IAC7B,OAAOtB,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEA8E,GAAGA,CAAmBjE,CAAI,EAAEC,CAAS;IACnC,OAAOd,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACA+E,GAAGA,CAAmBzD,CAAI;IACxB,OAAOtB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAgF,KAAKA,CAAmB1D,CAAI;IAC1B,OAAOtB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAiF,OAAOA,CAAmB3D,CAAI,EAAE4D,GAAW;IACzC,OAAOlF,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACAmF,GAAGA,CAAmB7D,CAAI;IACxB,OAAOtB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAoF,KAAKA,CAAmB9D,CAAI;IAC1B,OAAOtB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAqF,IAAIA,CAAmB/D,CAAI;IACzB,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAsF,KAAKA,CAAmBhE,CAAI;IAC1B,OAAOtB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAuF,MAAMA,CAAmBjE,CAAI;IAC3B,OAAOtB,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EACAwF,UAAUA,CAAmBlE,CAAI;IAC/B,OAAOtB,iBAAiB,CAAC,YAAY,CAAC;EACxC;EACAyF,IAAIA,CAAmBnE,CAAI;IACzB,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACA0F,KAAKA,CAAmBpE,CAAI;IAC1B,OAAOtB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACA2F,KAAKA,CAAmBrE,CAAI,EAAET,CAAI;IAChC,OAAOb,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACA4F,GAAGA,CAAmBtE,CAAI;IACxB,OAAOtB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACA6F,MAAMA,CAAmBC,EAAK,EAAEC,CAAI;IAClC,OAAO/F,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EACAgG,IAAIA,CAAmB1E,CAAI;IACzB,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAiG,GAAGA,CAAmB3E,CAAI;IACxB,OAAOtB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEAkG,IAAIA,CAAmB5E,CAAI,EAAEyC,GAAW,EAAEG,GAAW;IACnD,OAAOlE,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAmG,GAAGA,CAAmB7E,CAAI;IACxB,OAAOtB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAoG,UAAUA,CAAmB9E,CAAI;IAC/B,OAAOtB,iBAAiB,CAAC,YAAY,CAAC;EACxC;EAEAqG,OAAOA,CAAmB/E,CAAI;IAC5B,OAAOtB,iBAAiB,CAAC,SAAS,CAAC;EACrC;EAEAsG,QAAQA,CAAmBhF,CAAI;IAC7B,OAAOtB,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEAuG,GAAGA,CAAmBjF,CAAI;IACxB,OAAOtB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAwG,GAAGA,CAAmBlF,CAAI;IACxB,OAAOtB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAyG,GAAGA,CAAmBnF,CAAI;IACxB,OAAOtB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEA0G,IAAIA,CAAmBpF,CAAI;IACzB,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACA2G,IAAIA,CAAmBrF,CAAI;IACzB,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACA4G,IAAIA,CAAmBtF,CAAI;IACzB,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACA6G,KAAKA,CAAmBhG,CAAI,EAAEC,CAAI;IAChC,OAAOd,iBAAiB,CAAC,OAAO,CAAC;EACnC;EAEA8G,IAAIA,CAAmBxF,CAAI;IACzB,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACA+G,IAAIA,CAAmBzF,CAAI;IACzB,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAgH,IAAIA,CAAmB1F,CAAI;IACzB,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAiH,KAAKA,CAAmB3F,CAAI;IAC1B,OAAOtB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAkH,KAAKA,CAAmB5F,CAAI;IAC1B,OAAOtB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EACAmH,KAAKA,CAAmB7F,CAAI;IAC1B,OAAOtB,iBAAiB,CAAC,OAAO,CAAC;EACnC;EAEAoH,GAAGA,CAAmB9F,CAAI;IACxB,OAAOtB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEAqH,IAAIA,CAAmB/F,CAAI,EAAEgG,KAAa;IACxC,OAAOtH,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAuH,WAAWA,CACP;IAACC,KAAK;IAAEC,MAAM;IAAEC,QAAQ;IAAExG,IAAI;IAAEC,UAAU;IAAEC;EAAsB,CAC7C;IACvB,OAAOpB,iBAAiB,CAAC,aAAa,CAAC;EACzC;EAEA2H,MAAMA,CAACrG,CAAW,EAAEmG,MAAgB,EAAEC,QAAoB;IACxD,OAAO1H,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EACA4H,cAAcA,CAAC9B,EAAY,EAAE2B,MAAgB,EAAEC,QAAoB;IAEjE,OAAO1H,iBAAiB,CAAC,gBAAgB,CAAC;EAC5C;EACA6H,eAAeA,CAACvG,CAAW,EAAEwG,EAAY,EAAEJ,QAAoB;IAC7D,OAAO1H,iBAAiB,CAAC,iBAAiB,CAAC;EAC7C;EAEA+H,oBAAoBA,CAChB;IAACP,KAAK;IAAEC,MAAM;IAAEC,QAAQ;IAAExG,IAAI;IAAEC,UAAU;IAAEC;EAAsB,CAC7C;IACvB,OAAOpB,iBAAiB,CAAC,sBAAsB,CAAC;EAClD;EAEAgI,eAAeA,CAACR,KAAe,EAAEC,MAAgB,EAAEC,QAAoB;IAErE,OAAO1H,iBAAiB,CAAC,iBAAiB,CAAC;EAC7C;EACAiI,uBAAuBA,CAACnC,EAAY,EAAE2B,MAAgB,EAAEC,QAAoB;IAE1E,OAAO1H,iBAAiB,CAAC,yBAAyB,CAAC;EACrD;EACAkI,wBAAwBA,CAAC5G,CAAW,EAAEwG,EAAY,EAAEJ,QAAoB;IAEtE,OAAO1H,iBAAiB,CAAC,0BAA0B,CAAC;EACtD;EACAmI,MAAMA,CAAC7G,CAAW,EAAEmG,MAAgB,EAAEC,QAAoB;IACxD,OAAO1H,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EACAoI,cAAcA,CAACtC,EAAY,EAAE2B,MAAgB,EAAEC,QAAoB;IAEjE,OAAO1H,iBAAiB,CAAC,gBAAgB,CAAC;EAC5C;EACAqI,eAAeA,CAAC/G,CAAW,EAAEwG,EAAY,EAAEJ,QAAoB;IAC7D,OAAO1H,iBAAiB,CAAC,iBAAiB,CAAC;EAC7C;EACAsI,OAAOA,CAAChH,CAAW,EAAEoG,QAAoB;IACvC,OAAO1H,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACAuI,eAAeA,CAACzC,EAAY,EAAExE,CAAW,EAAEyE,CAAW,EAAE2B,QAAoB;IAE1E,OAAO1H,iBAAiB,CAAC,iBAAiB,CAAC;EAC7C;EACAwI,OAAOA,CAAClH,CAAW,EAAEoG,QAAoB;IACvC,OAAO1H,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACAyI,eAAeA,CAAC3C,EAAY,EAAExE,CAAW,EAAEoG,QAAoB;IAC7D,OAAO1H,iBAAiB,CAAC,iBAAiB,CAAC;EAC7C;EACA0I,SAASA,CAACpH,CAAW,EAAEoG,QAAoB;IACzC,OAAO1H,iBAAiB,CAAC,WAAW,CAAC;EACvC;EACA2I,iBAAiBA,CAAC7C,EAAY,EAAExE,CAAW,EAAEoG,QAAoB;IAC/D,OAAO1H,iBAAiB,CAAC,mBAAmB,CAAC;EAC/C;EACA4I,SAASA,CAACtH,CAAW,EAAEoG,QAAoB;IACzC,OAAO1H,iBAAiB,CAAC,WAAW,CAAC;EACvC;EACA6I,iBAAiBA,CACb/C,EAAY,EAAExE,CAAW,EAAEyE,CAAW,EAAE2B,QAAoB;IAC9D,OAAO1H,iBAAiB,CAAC,mBAAmB,CAAC;EAC/C;EAEA8I,OAAOA,CAAmCxH,CAAI,EAAEhB,KAAkB;IAEhE,OAAON,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACA+I,IAAIA,CAAmBzH,CAAI,EAAEf,KAAe;IAC1C,OAAOP,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAgJ,IAAIA,CAAmB1H,CAAI,EAAE2H,IAAc;IACzC,OAAOjJ,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEAkJ,GAAGA,CACC5H,CAAI,EAAE6H,QAAiC,EAAEC,aAAqB;IAChE,OAAOpJ,iBAAiB,CAAC,KAAK,CAAC;EACjC;EAEAqJ,SAASA,CAAmB/H,CAAI,EAAEgI,IAAc;IAC9C,OAAOtJ,iBAAiB,CAAC,WAAW,CAAC;EACvC;EAEAuJ,MAAMA,CAAmBjI,CAAI,EAAEkI,OAAe,EAAE3H,IAAY,EAAE4H,SAAS,GAAG,CAAC;IAEzE,OAAOzJ,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EAEA0J,QAAQA,CAACpI,CAAS,EAAEkI,OAAe;IACjC,OAAOxJ,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEA2J,SAASA,CACLH,OAAe,EAAEI,OAAe,EAAEtJ,KAAkB;IACtD,OAAON,iBAAiB,CAAC,WAAW,CAAC;EACvC;EAEA6J,cAAcA,CACVvI,CAAI,EAAEwI,UAAoB,EAAEC,KAAiB;IAC/C,OAAO/J,iBAAiB,CAAC,gBAAgB,CAAC;EAC5C;EAEAgK,cAAcA,CACV1I,CAAI,EAAEwI,UAAoB,EAAEX,QAAoB;IAClD,OAAOnJ,iBAAiB,CAAC,gBAAgB,CAAC;EAC5C;EAEAiK,cAAcA,CACV3I,CAAW,EAAE4I,SAAiB,EAAEC,QAAgB,EAAEC,YAAqB,EACvEC,gBAAyB;IAC3B,OAAOrK,iBAAiB,CAAC,gBAAgB,CAAC;EAC5C;EAEAsK,sBAAsBA,CAACxE,EAAY,EAAExE,CAAW,EAAE8I,YAAqB;IAErE,OAAOpK,iBAAiB,CAAC,wBAAwB,CAAC;EACpD;EAEAuK,qBAAqBA,CACjBjJ,CAAW,EAAEkJ,SAAiB,EAAEL,QAAgB,EAAEC,YAAqB,EACvEC,gBAAyB;IAC3B,OAAOrK,iBAAiB,CAAC,uBAAuB,CAAC;EACnD;EAEAyK,6BAA6BA,CACzB3E,EAAY,EAAExE,CAAW,EAAE8I,YAAqB;IAClD,OAAOpK,iBAAiB,CAAC,+BAA+B,CAAC;EAC3D;EAEA0K,SAASA,CACLpJ,CAAW,EAAEqJ,IAAuB,EAAEC,QAA2B,EACjEC,MAA0B,EAAEC,KAAyB,EACrDC,eAAwB;IAC1B,OAAO/K,iBAAiB,CAAC,WAAW,CAAC;EACvC;EAEAgL,4BAA4BA,CACxB1J,CAAW,EAAE2J,MAAc,EAAE/J,IAAY,EAAEoG,KAAa,EACxD4D,IAAY;IACd,OAAOlL,iBAAiB,CAAC,8BAA8B,CAAC;EAC1D;EAEAmL,OAAOA,CACHrF,EAAY,EAAEsF,UAAoB,EAAEC,WAAqB,EAAEJ,MAAc,EACzE/J,IAAY,EAAEoG,KAAa,EAAE4D,IAAY;IAC3C,OAAOlL,iBAAiB,CAAC,SAAS,CAAC;EACrC;EAEAsL,WAAWA,CACPC,MAAgB,EAAEC,UAAmB,EAAEC,UAAkB,EACzDC,IAAY;IACd,OAAO1L,iBAAiB,CAAC,aAAa,CAAC;EACzC;EAEA2L,MAAMA,CAACnC,OAAiB,EAAEoC,KAAa,EAAEC,OAAe,EAAEC,QAAgB;IAExE,OAAO9L,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EAEA+L,MAAMA,CAACzK,CAAS,EAAEO,IAAY,EAAEmK,SAAkB,EAAElK,OAAgB;IAElE,OAAO9B,iBAAiB,CAAC,QAAQ,CAAC;EACpC;EAEAiM,iBAAiBA,CACbC,KAAe,EAAEC,MAAgB,EAAEC,aAAqB,EACxDC,YAAoB,EAAEC,cAAuB;IAC/C,OAAOtM,iBAAiB,CAAC,mBAAmB,CAAC;EAC/C;EAEAuM,GAAGA,CAACjL,CAAW;IACb,OAAOtB,iBAAiB,CAAC,KAAK,CAAC;EACjC;EACAwM,IAAIA,CAAClL,CAAW;IACd,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACAyM,OAAOA,CAAmBC,IAAO,EAAEC,IAAO;IACxC,OAAO3M,iBAAiB,CAAC,SAAS,CAAC;EACrC;EACA0M,IAAIA,CAAmBlF,KAAQ;IAC7B,OAAOxH,iBAAiB,CAAC,MAAM,CAAC;EAClC;EACA2M,IAAIA,CAAmBnF,KAAQ;IAC7B,OAAOxH,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEA4M,aAAaA,CACTC,KAAe,EAAEX,KAAe,EAAEY,QAAkB,EACpDC,QAA0B,EAAEC,MAA4B,EACxDC,kBAA0B;IAC5B,OAAOjN,iBAAiB,CAAC,eAAe,CAAC;EAC3C;EAEAkN,YAAYA,CAAC5L,CAAW,EAAE6L,SAAiB,EAAEC,UAAkB;IAC7D,OAAOpN,iBAAiB,CAAC,cAAc,CAAC;EAC1C;EAEA;EACAqN,KAAKA,CAAmB5N,KAAQ,EAAE6N,UAAoB,EAAEzL,IAAY;IAClE,OAAO7B,iBAAiB,CAAC,OAAO,CAAC;EACnC;EAEAuN,aAAaA,CACTC,aAAqB,EAAEC,YAAoB,EAAEC,WAAwB,EACrEC,YAAoB;IACtB,OAAO3N,iBAAiB,CAAC,eAAe,CAAC;EAC3C;EAEA4N,IAAIA,CAACtM,CAAS;IACZ,OAAOtB,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEA6N,IAAIA,CACAvN,KAAkB,EAAEb,KAAoB,EAAEc,KAAgB;IAC5D,OAAOP,iBAAiB,CAAC,MAAM,CAAC;EAClC;EAEA8N,QAAQA,CAAiBxM,CAAY;IACnC,OAAOtB,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEA+N,SAASA,CAAiBzM,CAAY;IACpC,OAAOtB,iBAAiB,CAAC,WAAW,CAAC;EACvC;EAEAgO,QAAQA,CAACC,KAAa,EAAEC,IAAY,EAAEC,GAAW;IAC/C,OAAOnO,iBAAiB,CAAC,UAAU,CAAC;EACtC;EAEAoO,OAAOA,CAAA;IACL,OAAOpO,iBAAiB,CAAC,SAAS,CAAC;EACrC;;AAGF,SAASA,iBAAiBA,CAACqO,UAAkB;EAC3C,MAAM,IAAIC,KAAK,CACX,IAAID,UAAU,sDAAsD,GACpE,sEAAsE,CAAC;AAC7E"},"metadata":{},"sourceType":"module","externalDependencies":[]}