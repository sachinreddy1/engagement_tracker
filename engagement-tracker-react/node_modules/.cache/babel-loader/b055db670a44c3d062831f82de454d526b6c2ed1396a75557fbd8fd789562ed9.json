{"ast":null,"code":"/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, buffer, DataStorage, engine, env, kernel_impls, KernelBackend, util } from '@tensorflow/tfjs-core';\nconst whereImpl = kernel_impls.whereImpl;\nimport { assertNotComplex } from './cpu_util';\nexport class MathBackendCPU extends KernelBackend {\n  constructor() {\n    super();\n    this.blockSize = 48;\n    this.firstUse = true;\n    this.data = new DataStorage(this, engine());\n  }\n  write(values, shape, dtype) {\n    if (this.firstUse) {\n      this.firstUse = false;\n      if (env().get('IS_NODE')) {\n        backend_util.warn('\\n============================\\n' + 'Hi there ðŸ‘‹. Looks like you are running TensorFlow.js in ' + 'Node.js. To speed things up dramatically, install our node ' + 'backend, which binds to TensorFlow C++, by running ' + 'npm i @tensorflow/tfjs-node, ' + 'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' + 'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' + 'suffix for CUDA) at the start of your program. ' + 'Visit https://github.com/tensorflow/tfjs-node for more details.' + '\\n============================');\n      }\n    }\n    const dataId = {};\n    this.data.set(dataId, {\n      values,\n      dtype,\n      refCount: 1\n    });\n    return dataId;\n  }\n  /**\n   * Create a data bucket in cpu backend.\n   * @param shape Shape of the `TensorInfo`.\n   * @param dtype DType of the `TensorInfo`.\n   * @param values The value of the `TensorInfo` stored as a flattened array.\n   */\n  makeTensorInfo(shape, dtype, values) {\n    let outId;\n    if (dtype === 'string' && values != null && values.length > 0 && util.isString(values[0])) {\n      const encodedValues = values.map(d => util.encodeString(d));\n      outId = this.write(encodedValues, shape, dtype);\n    } else {\n      outId = this.write(values, shape, dtype);\n    }\n    return {\n      dataId: outId,\n      shape,\n      dtype\n    };\n  }\n  /** Increase refCount of a `TensorData`. */\n  incRef(dataId) {\n    const tensorData = this.data.get(dataId);\n    tensorData.refCount++;\n  }\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId) {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n  move(dataId, values, shape, dtype) {\n    this.data.set(dataId, {\n      values,\n      dtype,\n      refCount: 1\n    });\n  }\n  numDataIds() {\n    return this.data.numDataIds();\n  }\n  async read(dataId) {\n    return this.readSync(dataId);\n  }\n  readSync(dataId) {\n    const {\n      dtype,\n      complexTensorInfos\n    } = this.data.get(dataId);\n    if (dtype === 'complex64') {\n      const realValues = this.readSync(complexTensorInfos.real.dataId);\n      const imagValues = this.readSync(complexTensorInfos.imag.dataId);\n      return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    }\n    return this.data.get(dataId).values;\n  }\n  bufferSync(t) {\n    const data = this.readSync(t.dataId);\n    let decodedData = data;\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        decodedData = data.map(d => util.decodeString(d));\n      } catch (_a) {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return buffer(t.shape, t.dtype, decodedData);\n  }\n  makeOutput(values, shape, dtype) {\n    const dataId = this.write(values, shape, dtype);\n    return engine().makeTensorFromDataId(dataId, shape, dtype, this);\n  }\n  disposeData(dataId) {\n    if (this.data.has(dataId)) {\n      const {\n        complexTensorInfos\n      } = this.data.get(dataId);\n      if (complexTensorInfos != null) {\n        this.disposeData(complexTensorInfos.real.dataId);\n        this.disposeData(complexTensorInfos.imag.dataId);\n      }\n      this.data.delete(dataId);\n    }\n  }\n  disposeIntermediateTensorInfo(tensorInfo) {\n    const dataId = tensorInfo.dataId;\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n      if (tensorData.refCount < 1) {\n        this.disposeData(dataId);\n      }\n    }\n  }\n  async time(f) {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {\n      kernelMs\n    };\n  }\n  memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true,\n      reasons: ['The reported memory is an upper bound. Due to automatic garbage ' + 'collection, the true allocated memory may be less.']\n    };\n  }\n  where(condition) {\n    assertNotComplex([condition], 'where');\n    const condVals = this.readSync(condition.dataId);\n    return whereImpl(condition.shape, condVals);\n  }\n  dispose() {}\n  floatPrecision() {\n    return 32;\n  }\n  /** Returns the smallest representable number.  */\n  epsilon() {\n    return super.epsilon();\n  }\n}","map":{"version":3,"names":["backend_util","buffer","DataStorage","engine","env","kernel_impls","KernelBackend","util","whereImpl","assertNotComplex","MathBackendCPU","constructor","blockSize","firstUse","data","write","values","shape","dtype","get","warn","dataId","set","refCount","makeTensorInfo","outId","length","isString","encodedValues","map","d","encodeString","incRef","tensorData","decRef","has","move","numDataIds","read","readSync","complexTensorInfos","realValues","real","imagValues","imag","mergeRealAndImagArrays","bufferSync","t","decodedData","decodeString","_a","Error","makeOutput","makeTensorFromDataId","disposeData","delete","disposeIntermediateTensorInfo","tensorInfo","time","f","start","now","kernelMs","memory","unreliable","reasons","where","condition","condVals","dispose","floatPrecision","epsilon"],"sources":["C:\\Users\\reddy\\Documents\\Projects\\engagement-tracker-react\\node_modules\\@tensorflow\\tfjs-backend-cpu\\src\\backend_cpu.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendTimingInfo, buffer, DataStorage, DataType, DataValues, engine, env, kernel_impls, KernelBackend, Rank, ShapeMap, Tensor, Tensor2D, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nconst whereImpl = kernel_impls.whereImpl;\nimport {assertNotComplex} from './cpu_util';\n\ninterface DataId {}\n\nexport interface TensorData<D extends DataType> {\n  values?: backend_util.BackendValues;\n  dtype: D;\n  // For complex numbers, the real and imaginary parts are stored as their own\n  // individual tensors, with a parent joining the two with the\n  // complexTensorInfos field.\n  complexTensorInfos?: {real: TensorInfo, imag: TensorInfo};\n  // refCount keeps track of how many tensors reference it. Used for memory\n  // management.\n  refCount: number;\n}\n\nexport class MathBackendCPU extends KernelBackend {\n  public blockSize = 48;\n\n  data: DataStorage<TensorData<DataType>>;\n  private firstUse = true;\n\n  constructor() {\n    super();\n    this.data = new DataStorage(this, engine());\n  }\n\n  write(values: backend_util.BackendValues, shape: number[], dtype: DataType):\n      DataId {\n    if (this.firstUse) {\n      this.firstUse = false;\n      if (env().get('IS_NODE')) {\n        backend_util.warn(\n            '\\n============================\\n' +\n            'Hi there ðŸ‘‹. Looks like you are running TensorFlow.js in ' +\n            'Node.js. To speed things up dramatically, install our node ' +\n            'backend, which binds to TensorFlow C++, by running ' +\n            'npm i @tensorflow/tfjs-node, ' +\n            'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' +\n            'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' +\n            'suffix for CUDA) at the start of your program. ' +\n            'Visit https://github.com/tensorflow/tfjs-node for more details.' +\n            '\\n============================');\n      }\n    }\n    const dataId = {};\n\n    this.data.set(dataId, {values, dtype, refCount: 1});\n\n    return dataId;\n  }\n\n  /**\n   * Create a data bucket in cpu backend.\n   * @param shape Shape of the `TensorInfo`.\n   * @param dtype DType of the `TensorInfo`.\n   * @param values The value of the `TensorInfo` stored as a flattened array.\n   */\n  makeTensorInfo(\n      shape: number[], dtype: DataType,\n      values?: backend_util.BackendValues|string[]): TensorInfo {\n    let outId;\n    if (dtype === 'string' && values != null && values.length > 0 &&\n        util.isString(values[0])) {\n      const encodedValues =\n          (values as {} as string[]).map(d => util.encodeString(d));\n\n      outId = this.write(encodedValues, shape, dtype);\n    } else {\n      outId = this.write(values as TypedArray, shape, dtype);\n    }\n\n    return {dataId: outId, shape, dtype};\n  }\n\n  /** Increase refCount of a `TensorData`. */\n  incRef(dataId: DataId): void {\n    const tensorData = this.data.get(dataId);\n    tensorData.refCount++;\n  }\n\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n\n  move(\n      dataId: DataId, values: backend_util.BackendValues, shape: number[],\n      dtype: DataType): void {\n    this.data.set(dataId, {values, dtype, refCount: 1});\n  }\n\n  numDataIds(): number {\n    return this.data.numDataIds();\n  }\n\n  async read(dataId: DataId): Promise<backend_util.BackendValues> {\n    return this.readSync(dataId);\n  }\n  readSync(dataId: DataId): backend_util.BackendValues {\n    const {dtype, complexTensorInfos} = this.data.get(dataId);\n\n    if (dtype === 'complex64') {\n      const realValues =\n          this.readSync(complexTensorInfos.real.dataId) as Float32Array;\n      const imagValues =\n          this.readSync(complexTensorInfos.imag.dataId) as Float32Array;\n      return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    }\n\n    return this.data.get(dataId).values;\n  }\n\n  bufferSync<R extends Rank>(t: TensorInfo): TensorBuffer<R> {\n    const data = this.readSync(t.dataId);\n    let decodedData = data as DataValues;\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        decodedData = (data as Uint8Array[]).map(d => util.decodeString(d));\n      } catch {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return buffer(t.shape as ShapeMap[R], t.dtype, decodedData) as\n        TensorBuffer<R>;\n  }\n\n  makeOutput<T extends Tensor>(\n      values: backend_util.BackendValues, shape: number[], dtype: DataType): T {\n    const dataId = this.write(values, shape, dtype);\n    return engine().makeTensorFromDataId(dataId, shape, dtype, this) as T;\n  }\n\n  disposeData(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const {complexTensorInfos} = this.data.get(dataId);\n\n      if (complexTensorInfos != null) {\n        this.disposeData(complexTensorInfos.real.dataId);\n        this.disposeData(complexTensorInfos.imag.dataId);\n      }\n\n      this.data.delete(dataId);\n    }\n  }\n\n  disposeIntermediateTensorInfo(tensorInfo: TensorInfo): void {\n    const dataId = tensorInfo.dataId;\n\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n\n      tensorData.refCount--;\n\n      if (tensorData.refCount < 1) {\n        this.disposeData(dataId);\n      }\n    }\n  }\n\n  async time(f: () => void): Promise<BackendTimingInfo> {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {kernelMs};\n  }\n\n  memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true,\n      reasons:\n          ['The reported memory is an upper bound. Due to automatic garbage ' +\n           'collection, the true allocated memory may be less.']\n    };\n  }\n\n  where(condition: Tensor): Tensor2D {\n    assertNotComplex([condition], 'where');\n\n    const condVals = this.readSync(condition.dataId) as TypedArray;\n    return whereImpl(condition.shape, condVals);\n  }\n\n  dispose() {}\n\n  floatPrecision(): 16|32 {\n    return 32;\n  }\n\n  /** Returns the smallest representable number.  */\n  epsilon(): number {\n    return super.epsilon();\n  }\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,YAAY,EAAqBC,MAAM,EAAEC,WAAW,EAAwBC,MAAM,EAAEC,GAAG,EAAEC,YAAY,EAAEC,aAAa,EAA0EC,IAAI,QAAO,uBAAuB;AAExO,MAAMC,SAAS,GAAGH,YAAY,CAACG,SAAS;AACxC,SAAQC,gBAAgB,QAAO,YAAY;AAgB3C,OAAM,MAAOC,cAAe,SAAQJ,aAAa;EAM/CK,YAAA;IACE,KAAK,EAAE;IANF,KAAAC,SAAS,GAAG,EAAE;IAGb,KAAAC,QAAQ,GAAG,IAAI;IAIrB,IAAI,CAACC,IAAI,GAAG,IAAIZ,WAAW,CAAC,IAAI,EAAEC,MAAM,EAAE,CAAC;EAC7C;EAEAY,KAAKA,CAACC,MAAkC,EAAEC,KAAe,EAAEC,KAAe;IAExE,IAAI,IAAI,CAACL,QAAQ,EAAE;MACjB,IAAI,CAACA,QAAQ,GAAG,KAAK;MACrB,IAAIT,GAAG,EAAE,CAACe,GAAG,CAAC,SAAS,CAAC,EAAE;QACxBnB,YAAY,CAACoB,IAAI,CACb,kCAAkC,GAClC,2DAA2D,GAC3D,6DAA6D,GAC7D,qDAAqD,GACrD,+BAA+B,GAC/B,uDAAuD,GACvD,sDAAsD,GACtD,iDAAiD,GACjD,iEAAiE,GACjE,gCAAgC,CAAC;;;IAGzC,MAAMC,MAAM,GAAG,EAAE;IAEjB,IAAI,CAACP,IAAI,CAACQ,GAAG,CAACD,MAAM,EAAE;MAACL,MAAM;MAAEE,KAAK;MAAEK,QAAQ,EAAE;IAAC,CAAC,CAAC;IAEnD,OAAOF,MAAM;EACf;EAEA;;;;;;EAMAG,cAAcA,CACVP,KAAe,EAAEC,KAAe,EAChCF,MAA4C;IAC9C,IAAIS,KAAK;IACT,IAAIP,KAAK,KAAK,QAAQ,IAAIF,MAAM,IAAI,IAAI,IAAIA,MAAM,CAACU,MAAM,GAAG,CAAC,IACzDnB,IAAI,CAACoB,QAAQ,CAACX,MAAM,CAAC,CAAC,CAAC,CAAC,EAAE;MAC5B,MAAMY,aAAa,GACdZ,MAAyB,CAACa,GAAG,CAACC,CAAC,IAAIvB,IAAI,CAACwB,YAAY,CAACD,CAAC,CAAC,CAAC;MAE7DL,KAAK,GAAG,IAAI,CAACV,KAAK,CAACa,aAAa,EAAEX,KAAK,EAAEC,KAAK,CAAC;KAChD,MAAM;MACLO,KAAK,GAAG,IAAI,CAACV,KAAK,CAACC,MAAoB,EAAEC,KAAK,EAAEC,KAAK,CAAC;;IAGxD,OAAO;MAACG,MAAM,EAAEI,KAAK;MAAER,KAAK;MAAEC;IAAK,CAAC;EACtC;EAEA;EACAc,MAAMA,CAACX,MAAc;IACnB,MAAMY,UAAU,GAAG,IAAI,CAACnB,IAAI,CAACK,GAAG,CAACE,MAAM,CAAC;IACxCY,UAAU,CAACV,QAAQ,EAAE;EACvB;EAEA;EACAW,MAAMA,CAACb,MAAc;IACnB,IAAI,IAAI,CAACP,IAAI,CAACqB,GAAG,CAACd,MAAM,CAAC,EAAE;MACzB,MAAMY,UAAU,GAAG,IAAI,CAACnB,IAAI,CAACK,GAAG,CAACE,MAAM,CAAC;MACxCY,UAAU,CAACV,QAAQ,EAAE;;EAEzB;EAEAa,IAAIA,CACAf,MAAc,EAAEL,MAAkC,EAAEC,KAAe,EACnEC,KAAe;IACjB,IAAI,CAACJ,IAAI,CAACQ,GAAG,CAACD,MAAM,EAAE;MAACL,MAAM;MAAEE,KAAK;MAAEK,QAAQ,EAAE;IAAC,CAAC,CAAC;EACrD;EAEAc,UAAUA,CAAA;IACR,OAAO,IAAI,CAACvB,IAAI,CAACuB,UAAU,EAAE;EAC/B;EAEA,MAAMC,IAAIA,CAACjB,MAAc;IACvB,OAAO,IAAI,CAACkB,QAAQ,CAAClB,MAAM,CAAC;EAC9B;EACAkB,QAAQA,CAAClB,MAAc;IACrB,MAAM;MAACH,KAAK;MAAEsB;IAAkB,CAAC,GAAG,IAAI,CAAC1B,IAAI,CAACK,GAAG,CAACE,MAAM,CAAC;IAEzD,IAAIH,KAAK,KAAK,WAAW,EAAE;MACzB,MAAMuB,UAAU,GACZ,IAAI,CAACF,QAAQ,CAACC,kBAAkB,CAACE,IAAI,CAACrB,MAAM,CAAiB;MACjE,MAAMsB,UAAU,GACZ,IAAI,CAACJ,QAAQ,CAACC,kBAAkB,CAACI,IAAI,CAACvB,MAAM,CAAiB;MACjE,OAAOrB,YAAY,CAAC6C,sBAAsB,CAACJ,UAAU,EAAEE,UAAU,CAAC;;IAGpE,OAAO,IAAI,CAAC7B,IAAI,CAACK,GAAG,CAACE,MAAM,CAAC,CAACL,MAAM;EACrC;EAEA8B,UAAUA,CAAiBC,CAAa;IACtC,MAAMjC,IAAI,GAAG,IAAI,CAACyB,QAAQ,CAACQ,CAAC,CAAC1B,MAAM,CAAC;IACpC,IAAI2B,WAAW,GAAGlC,IAAkB;IACpC,IAAIiC,CAAC,CAAC7B,KAAK,KAAK,QAAQ,EAAE;MACxB,IAAI;QACF;QACA8B,WAAW,GAAIlC,IAAqB,CAACe,GAAG,CAACC,CAAC,IAAIvB,IAAI,CAAC0C,YAAY,CAACnB,CAAC,CAAC,CAAC;OACpE,CAAC,OAAAoB,EAAA,EAAM;QACN,MAAM,IAAIC,KAAK,CAAC,kDAAkD,CAAC;;;IAGvE,OAAOlD,MAAM,CAAC8C,CAAC,CAAC9B,KAAoB,EAAE8B,CAAC,CAAC7B,KAAK,EAAE8B,WAAW,CACvC;EACrB;EAEAI,UAAUA,CACNpC,MAAkC,EAAEC,KAAe,EAAEC,KAAe;IACtE,MAAMG,MAAM,GAAG,IAAI,CAACN,KAAK,CAACC,MAAM,EAAEC,KAAK,EAAEC,KAAK,CAAC;IAC/C,OAAOf,MAAM,EAAE,CAACkD,oBAAoB,CAAChC,MAAM,EAAEJ,KAAK,EAAEC,KAAK,EAAE,IAAI,CAAM;EACvE;EAEAoC,WAAWA,CAACjC,MAAc;IACxB,IAAI,IAAI,CAACP,IAAI,CAACqB,GAAG,CAACd,MAAM,CAAC,EAAE;MACzB,MAAM;QAACmB;MAAkB,CAAC,GAAG,IAAI,CAAC1B,IAAI,CAACK,GAAG,CAACE,MAAM,CAAC;MAElD,IAAImB,kBAAkB,IAAI,IAAI,EAAE;QAC9B,IAAI,CAACc,WAAW,CAACd,kBAAkB,CAACE,IAAI,CAACrB,MAAM,CAAC;QAChD,IAAI,CAACiC,WAAW,CAACd,kBAAkB,CAACI,IAAI,CAACvB,MAAM,CAAC;;MAGlD,IAAI,CAACP,IAAI,CAACyC,MAAM,CAAClC,MAAM,CAAC;;EAE5B;EAEAmC,6BAA6BA,CAACC,UAAsB;IAClD,MAAMpC,MAAM,GAAGoC,UAAU,CAACpC,MAAM;IAEhC,IAAI,IAAI,CAACP,IAAI,CAACqB,GAAG,CAACd,MAAM,CAAC,EAAE;MACzB,MAAMY,UAAU,GAAG,IAAI,CAACnB,IAAI,CAACK,GAAG,CAACE,MAAM,CAAC;MAExCY,UAAU,CAACV,QAAQ,EAAE;MAErB,IAAIU,UAAU,CAACV,QAAQ,GAAG,CAAC,EAAE;QAC3B,IAAI,CAAC+B,WAAW,CAACjC,MAAM,CAAC;;;EAG9B;EAEA,MAAMqC,IAAIA,CAACC,CAAa;IACtB,MAAMC,KAAK,GAAGrD,IAAI,CAACsD,GAAG,EAAE;IACxBF,CAAC,EAAE;IACH,MAAMG,QAAQ,GAAGvD,IAAI,CAACsD,GAAG,EAAE,GAAGD,KAAK;IACnC,OAAO;MAACE;IAAQ,CAAC;EACnB;EAEAC,MAAMA,CAAA;IACJ,OAAO;MACL;MACAC,UAAU,EAAE,IAAI;MAChBC,OAAO,EACH,CAAC,kEAAkE,GAClE,oDAAoD;KAC1D;EACH;EAEAC,KAAKA,CAACC,SAAiB;IACrB1D,gBAAgB,CAAC,CAAC0D,SAAS,CAAC,EAAE,OAAO,CAAC;IAEtC,MAAMC,QAAQ,GAAG,IAAI,CAAC7B,QAAQ,CAAC4B,SAAS,CAAC9C,MAAM,CAAe;IAC9D,OAAOb,SAAS,CAAC2D,SAAS,CAAClD,KAAK,EAAEmD,QAAQ,CAAC;EAC7C;EAEAC,OAAOA,CAAA,GAAI;EAEXC,cAAcA,CAAA;IACZ,OAAO,EAAE;EACX;EAEA;EACAC,OAAOA,CAAA;IACL,OAAO,KAAK,CAACA,OAAO,EAAE;EACxB"},"metadata":{},"sourceType":"module","externalDependencies":[]}